#    Modelo logístico
```{r preamble7, include=FALSE}
library(MASS)
library(knitr)
library(kableExtra)
library(aod)
library(pROC)
data(birthwt)
```
## Casos de estudio

### Mortalidad de escarabajos
Vamos a trabajar con los datos del estudio sobre los escarabajos:
```{r datosEscarabajos}
logdose <- c(1.6907, 1.7242, 1.7552, 1.7842, 1.8113, 1.8369, 1.8610, 1.8839)
dead <- c(6, 13, 18, 28, 52, 53, 61, 60) 
n <- c(59, 60, 62, 56, 63, 59, 62, 60) 
Datos=data.frame(logdose,n,dead)
```

### Bajo peso al nacer
Con los datos \texttt{birthwt} de la librería \texttt{MASS}, se quiere indentificar factores de riesgo asociados con el nacimiento de niños con bajo peso (es decir, un peso al nacer menor de $2.5$kgs). Se tiene información de 189 recién nacidos y sus madres atendidos en una hospital (Baystate Medical Center, Springfield, Mass en 1986). Los posibles factores que pueden afectar el bajo al peso son:

* ```age```: edad de la madre (años).

* ```lwt```: peso de la madre antes del embarazo (libras).

* ```smoke```: estado de tabaquismo durante el embarazo (0 no, 1 si).

* ```ptl```: historia de parto prematuro (número de casos).

La variable de respuesta es ```low``` (1 si peso $<$ 2.5 kgs, 0 si peso $\geq$ 2.5 kgs).

Para este caso, se puede ajustar modelo logístico. Sea $y_i=1$ si el $i$-ésimo bebé nace con bajo peso, $y_i=0$ si lo contrario. Por lo que la densidad de $y_i$ está definida como:
$$
f(y_i;\pi_i)=\pi_i^{y_i}(1-\pi_i)^{(1-y_i)}.
$$
La función de enlace es:
$$
log\begin{pmatrix} \frac{\pi_i}{1-\pi_i} \end{pmatrix}=\beta_0+\beta_1\text{age}_i+\beta_2\text{lwt}_i+\beta_3\text{smoke}_i+\beta_4\text{ptl}_i.
$$
### Estudio de teratología
Los datos \texttt{lirat} de la librería \texttt{VGAM} son de un estudio para investigar los efectos de unos régimenes alimenticio  en el desarrollo fetal de ratas. En este experimento, 58 ratas hembras con dietas deficientes en hierro se dividieron en cuatro grupos.  Tres grupos recibieron inyecciones semanales de suplementos de hierro, a diferentes dosis, para normalizar sus niveles de hierro. Mientras que, el grupo restante no recibieron ningún suplemento (placebo). Luego, las ratas se preñaron, se sacrificaron 3 semanas después, y se contó el número de fetos muertos en cada camada.

En la Figura \@ref(fig:liratFig) se puede observar la relación entre el número de fetos muertos por tratamiento, y también, la relación con los niveles de hemoglobina de las ratas hembras.

```{r liratFig,  fig.height = 4, fig.width = 6, fig.align='center',fig.cap="Datos teratoligía. Relación entre la proporción de fetos muertos por camada con los tratamientos (izquierda) y los niveles de hemoglobina de la madra (derecha) "}
data(lirat,package = 'VGAM')
par(mfrow=c(1,2))
#Proporcion de fetos muestos vs tratamiento
plot(lirat$grp,lirat$R/lirat$N,xlab="Tratamiento",ylab="Proporción de fetos muertos")
#Proporcion de fetos muestos vs Hemoglobina
plot(lirat$hb,lirat$R/lirat$N,xlab="Hemoglobina",ylab="Proporción de fetos muertos")
```

Si consideramos:
\[
y_{ij} = \begin{cases}
1 & \mbox{ si el feto} j \mbox{ de la camada }i\mbox{ está muerto}, \\
0 & \mbox{ si lo contrario}, \\
 \end{cases}
\]
la variable número de fetos muertos se puede asociar a una distribución binomial:
\[
y_i = \sum_{j=1}^{n_i} y_{ij} \sim \mbox{binomial}(n_i, \pi_i),
\]
donde $n_i$ es el tamaño de la camada y $\pi_i$ es la probabilidad de que el feto muera. Dado que $\pi_i$ depende del tratamiento y de los niveles de hemoglobina de la rata hembra, se propone que:
\[
log\begin{pmatrix} \frac{\pi_i}{1-\pi_i} \end{pmatrix}=\beta_0+\beta_1\text{grp}_{i1}+\beta_2\text{grp}_{i2}+\beta_3\text{grp}_{i3}+\beta_4\text{hb}_i,
\]
donde: ```grp_2```: tratamiento (1: placebo, 2-4: diferentes concentraciones de inyecciones de suplementos de hierro) ```hb```: nivel de hemoglobina.

## Datos agrupados o datos no agrupados
Los datos binarios tienen dos tipos de formatos:

**Datos agrupados:** Hay $n_i$ observaciones que tienen los mismos valores de las covariables $x_i$. Aquí tenemos que para agrupación, $y_i \sim$binomial$(n_i,\pi_i)$.

**Datos no agrupados:** Hay $n_i=1$ (o muy pocas) observaciones por cada $x_i$. Es decir que, cada $y_i$ sigue una distribución Bernoulli$(\pi_i)$.

Las propiedades asintóticas de las inferencias para los datos no agrupados aplican cuando $N \to \infty$. Mientras que para datos agrupados, aplican cuando $\sum_{i=1}^nn_i\to\infty$.

### Datos agrupados
Para datos agrupados, $D$ y $X^2$ sirven para evaluar si el ajuste del modelo es bueno o no. Aquí podemos plantear las siguientes hipótesis: $H_0$ indica que el modelo se ajusta bien a los datos, $H_1$ lo contrario.

Si $H_0$ es cierta (y $\sum_{i=1}^nn_i\to\infty$), entonces $D$ y $X^2$ siguen una distribución $\chi^2$ con $(n-p)$ grados de libertad.

### Datos no agrupados
Las distribuciones límite para $D$ y $X^2$  no aplican para datos no agrupados. Tampoco para datos agrupados con $N$ grande y algunos $n_i$ muy pequeños. Se puede aproximar $D$ y $X^2$ agrupando $(\bx_i,\hat{\by})$ por particiones del espacio de covariables o por particiones de $\hat{\pi}$. En estos casos, es preferible evaluar la falta de ajuste comparando el modelo propuesto contra modelos más generales.

## Funciones de enlace
En los modelos anteriores hemos propuesto funciones de enlace logit: $log\begin{pmatrix} \frac{\pi_i}{1-\pi_i} \end{pmatrix}=\bx_i\bbeta$.Lo que implica que:

$$
\pi_i=g^{-1}(\bx_i,\bbeta)=\frac{exp(\bx_i'\bbeta)}{1+exp(\bx_i'\bbeta)}=\frac{1}{1+exp(-\bx_i'\bbeta)} 
$$
Sin embargo, podemos utilizar otras funciones de enlace. Por ejemplo, la función **Probit:**
$$
\Phi^{-1}(\pi_i)=\bx'_i\bbeta \quad \pi_i=\Phi(\bx'_i\bbeta),
$$
donde $\Phi(\cdot)$ es función acumulativa de la distribución normal estándar. La función **Log-log complementaria:**
$$
\pi_i=1-exp[-exp(\bx'_i\bbeta)] \quad log[-log(1-\pi_i)]=\bx'_i\bbeta.
$$
En la Figura \@ref(fig:linkEsc) podemos observar la estimación de la probabilidad de que el escarabajo muera utilizando diferentes funciones de enlace (logit, probit, log-log complementaria). Graficamente, la función log-log complementaria parece mostrar mejores estimaciones que la probit y la logit.


```{r linkEsc,echo=FALSE, fig.height = 4, fig.width = 6,fig.align='center',fig.cap="Estimaciones de la probabilidad de que el escarabajo muera en función de la dosis utilizando diferentes funciones de enlace: logit(negro), probit(rojo) y cloglog(verde)."}

pred.x = data.frame(logdose = seq(min(logdose),max(logdose),length.out = 50))

modEsc.logit = glm(cbind(dead,n-dead)~logdose,family=binomial(logit))
modEsc.probit = glm(cbind(dead,n-dead)~logdose,family=binomial(probit))
modEsc.cloglog = glm(cbind(dead,n-dead)~logdose,family=binomial(cloglog))

pred.logit = predict(modEsc.logit,pred.x,type='response')
pred.probit = predict(modEsc.probit,pred.x,type='response')
pred.cloglog = predict(modEsc.cloglog,pred.x,type='response')

plot(logdose,dead/n,xlim=c(1.69,1.88),ylim=c(0,1),xlab='log dosis',ylab='proporción de escarabajos muertos')
lines(pred.x$logdose,pred.logit,lwd=2)
lines(pred.x$logdose,pred.probit,col=2,lwd=2)
lines(pred.x$logdose,pred.cloglog,col=3,lwd=2)
```
Este resultado se puede comprobar utilizando criterios de información:
```{r linkEscAIC,echo=T}
AIC(modEsc.logit)
AIC(modEsc.probit)
AIC(modEsc.cloglog)
```
## Curva característica operativa del receptor(ROC)
Para evaluar el poder predictivo del modelo se puede construir una tabla de contingencia (ver Tabla \@ref(tab:tabcont)) comparando $y_i$ con la predicción $\haty_i$ a través del modelo. Para datos no agrupados, la predicción $\haty_i$ se define como:
\[
\haty_i = \begin{cases}
1 & \mbox{si } \hatpi_i > \pi_0, \\
0 & \mbox{si } \hatpi_i \leq \pi_0, \\
\end{cases}
\]
para un punto de corte $\pi_0$ definido por el investigador, por ejemplo $\pi_0 = 0.5$.

```{r tabcont, echo=FALSE, include=TRUE, results="asis"}
mathy.df <- data.frame(b0=c("$y=0$","$y=1$"), 
                       b1=c('a','b'),
                       b2=c('c','d'))

colnames(mathy.df)<-NULL

kable(mathy.df, escape=FALSE,format = "html", booktabs = T) %>%
  kable_styling(bootstrap_options = "striped",
                full_width = F) %>%add_header_above(c("","$\\hat{y}=0$","$\\hat{y}=1$"))
```

El recuento de casillas en estas tablas permite estimar la sensibilidad, 
\[
P(\haty=1|y=1) = \frac{d}{b+d},
\]
y la especificidad, $P(\haty=0|y=0)$.
\[
P(\haty=0|y=0) = \frac{a}{a+c}.
\]
Sin embargo, estos valores dependen de $\pi_0$.

**Ejemplo - Datos de peso al nacer**
Para los datos de peso al nacer, se propone el siguiente modelo:
\[
\mbox{logit} \pi_i = \beta_0+  \mbox{age}_i\beta_1+  \mbox{lwt}_i\beta_2 +  \mbox{smoke}_i\beta_3 + \mbox{ptl}_i\beta_4,
\]
donde $\pi_i$ es la probabilidad de que el recién nacido nazca con bajo peso. El ajuste del modelo es:

```{r lbwfit, echo=FALSE, include=TRUE}
mod.lbw = glm(low ~ age + lwt + smoke + ptl, data= birthwt,family=binomial)
summary(mod.lbw)
```
Estos resultados muestran que el estado de tabaquismo y el historial de partos prematuros son factores de riesgo para el bajo peso al nacer. Sin embargo, el primero no tiene un aporte significativo dentro del modelo.

Ahora vamos a evaluar el poder predictivo del modelo. Si definimos $\pi_0=0.5$, tenemos:

```{r roc1, echo=FALSE, include=TRUE, results="asis"}
obs = birthwt$low
pred = mod.lbw$fitted.values > 0.5
tab1 = table(obs,pred)

mathy.df <- data.frame(b0=c("$y=0$","$y=1$"), 
                       b1=c(tab1[1,1],tab1[2,1]),
                       b2=c(tab1[1,2],tab1[2,2]))

colnames(mathy.df)<-NULL

kable(mathy.df, escape=FALSE,format = "html", booktabs = T) %>%
  kable_styling(bootstrap_options = "striped",
                full_width = F) %>%add_header_above(c("","$\\hat{y}=0$","$\\hat{y}=1$"))

```
Por lo tanto, la sensibilidad es $10/59 = 0,169$ y la especificidad es $123/130 = 0,946$. Con este punto de corte, el modelo tiene una predictividad alta para los recién nacidos con peso adecuado (alta especificidad). Sin embargo, la probabilidad de falsos positivos es alta (baja sensibilidad). Ahora, si $\pi_0= 0,3$:

```{r, echo=FALSE, include=TRUE, results="asis"}
obs = birthwt$low
pred = mod.lbw$fitted.values > 0.3
tab1 = table(obs,pred)

mathy.df <- data.frame(b0=c("$y=0$","$y=1$"), 
                       b1=c(tab1[1,1],tab1[2,1]),
                       b2=c(tab1[1,2],tab1[2,2]))

colnames(mathy.df)<-NULL

kable(mathy.df, escape=FALSE,format = "html", booktabs = T) %>%
  kable_styling(bootstrap_options = "striped",
                full_width = F) %>%add_header_above(c("","$\\hat{y}=0$","$\\hat{y}=1$"))

```

En este caso la sensibilidad aumentó $(40/59 = 0,678)$, pero la especificidad disminuye $(79/130 = 0,607)$. 

Dado que la sensibilidad y especificidad tiene una alta dependencia del punto de corte, lo preferible calcular estas cantidades para muchos valores de $\pi_0$. En la Figura \@ref(fig:sensespc) podemos observar que a medida que aumenta $\pi_0$ la sensibilidad disminuye y la especificidad aumenta.

```{r sensespc, fig.align = 'center', fig.height = 4, fig.width = 6,echo=FALSE, fig.cap="Datos de bajo peso al nacer. Sensibilidad (linea negra) y especificidad (linea roja) para diferentes puntos de corte."}
tab.fun = function(obs,fit,pi0){
pred0 = fit > pi0
tab = table(obs,pred0)
senc = tab[2,2]/sum(tab[2,])
espc = tab[1,1]/sum(tab[1,])
c(senc,espc)
}
pi0 = seq(0.1,0.8,length.out=500)
sens.espc = mapply(function(x){tab.fun(obs,mod.lbw$fitted.values,pi0[x])},x=1:500)

plot(pi0,sens.espc[1,],lwd=2,type = 'l',xlab=expression(pi[0]),ylab='Sensibilidad y especificidad')
lines(pi0,sens.espc[2,],lwd=2,col=2)
```
La sensibilidad es la tasa de verdaderos positivos (tvp), mientras que, el complemento de la especificidad $(P(\haty = 1 | y=0))$ es la tasa de falsos positivos (tfp). El gráfico de la tasa de verdaderos positivos en función de la tasa de falsos positivos para diferentes valores de $\pi_0$, entre $0$ y $1$, lleva el nombre de curva característica operativa del receptor (ROC). Cuando $\pi_0$ es muy cercano a $1$, casi todas las predicciones son $\haty =0$; entonces tenemos (tvp,tfp)$\approx(0,0)$. Mientras que, cuando $\pi_0$ es muy cercano a $0$, casi todas las predicciones son $\haty =1$; entonces tenemos (tvp,tfp)$\approx(1,1)$. esto lo podemos ver en la Figura \@ref(fig:sensespc2).


```{r sensespc2, fig.align = 'center', fig.height = 4, fig.width = 6,echo=FALSE,fig.cap="Datos de bajo peso al nacer. Sensibilidad (linea negra) y especificidad (linea roja) para diferentes puntos de corte."}
plot(1-sens.espc[2,],sens.espc[1,],lwd=2,xlab='1 - especificidad',
     ylab='sensibilidad')
```


El area bajo la curva de la curva ROC (llamado índice de concordancia) es una medida del poder predictivo del modelo.

### Ejemplo mortalidad de escarabajos

Curva ROC para el modelo logístico:

"grafico roc escarabajos"

### Bajo peso al nacer
```{r,eval=FALSE}
 
modbw.logit = glm(low~age+lwt+ptl+smoke,family=binomial(logit),data=birthwt)
modbw.probit = glm(low~age+lwt+smoke+ptl,family=binomial(probit),data=birthwt)
# curvas roc
#library(pROC)
ROCbw.logit = roc(birthwt$low~modbw.logit$fitted.values)
ROCbw.probit = roc(birthwt$low~modbw.probit$fitted.values)


```

```{r,include=FALSE}
 
modbw.logit = glm(low~age+lwt+ptl+smoke,family=binomial(logit),data=birthwt)
modbw.probit = glm(low~age+lwt+smoke+ptl,family=binomial(probit),data=birthwt)
# curvas roc
#library(pROC)
ROCbw.logit = roc(birthwt$low~modbw.logit$fitted.values)
ROCbw.probit = roc(birthwt$low~modbw.probit$fitted.values)


```

```{r, fig.align='center', fig.cap="Curva ROC para el modelo logístico (negro) y probit (rojo)"}
plot(ROCbw.logit)
lines(ROCbw.probit,col=2)

```

modelo logístico: $AUC= 0,6884$.

modelo probit: $AUC= 0,6866$.


## Sobredispersión

En un experimento Bernoulli se asume que los $n_i$ ensayos para la observación $i,\quad y_{i1},...y_in_i$ son independientes.

Por lo tanto, tenemos que:

$$
E(y_i)=\pi_i\quad \text{y} \quad V(y_i)=\pi_i(1-\pi_i)\frac{1}{n_i}.
$$

Pero, hay casos donde las observaciones $y_{i1},...y_in_i$ están correlacionadas, es decir $cor(y_{is},y_{it})\ne0$.

Por lo general, se asume que $cor(y_{is},y_{it})=\phi$, para todo $s\ne t$ (exchangeability property). Entonces:

$$
V(y_{it})=\pi_i(1-\pi_i)\quad \text{y} \quad cor(y_{it},y_{is})=\phi\pi_i(1-\pi_i).
$$

En este caso, tenemos que:

$$
V(y_i)=V\begin{pmatrix} \sum_{j=1}^{n_i}\frac{y_{ij}}{n_i}\end{pmatrix}=\frac{1}{n_i^2} \left[ \sum_{j=1}^{n_i}V(y_{it})+2\sum\sum_{s<t}cov(y_{is},y_{it}) \right]=[1+\phi(n_i-1)]\frac{\pi_i(1-\pi_i)}{n_i}.
$$


Si:

* $\phi=0$, $y_i\sim  binomial(n_i,\pi)$.

* $\phi>0$, tenemos sobredispersión.

* $-(n_i-1)^{-1}<\phi<0$, tenemos subdispersión (menos
frecuente).

En el caso del modelo binomial, tenemos que:

$$
v(\pi_i)=\pi_i(1-\pi_i)/n_i.
$$

El estadístico de $\chi^2$ de Pearson es:

$$
X^2=\sum_{i=1}^n\frac{(y_i-\hat{\pi}_i)^2}{\pi_i(1-\pi_1)/n_i}
$$

Un indicador de posible inflación de varianza es:

$$
\hat{\phi}=\frac{X^2}{n-p}.
$$

Si no hay problemas de sobredispersión $\hat{\phi}\approx1$.

## Distribución beta-binomial

Modelo: $y|\pi\sim binomial(n,\pi)$

Donde $\pi\sim beta(\alpha_1,\alpha_2)$, esto es:

$$
f(\pi;\alpha_1,\alpha_2)=\frac{\Gamma(\alpha_1+\alpha_2)}{\Gamma(\alpha_1)\Gamma(\alpha_2)}\pi^{\alpha_1-1}(1-\pi)^{\alpha_2-1}
$$

con $\alpha_1>0$ y $\alpha_2>0$.

Asumiendo $\mu=\frac{\alpha_1}{\alpha_1+\alpha_2}$ y $\theta=1/(\alpha_1+\alpha_2)$, tenemos:

$$
E(\pi)=\mu\quad\text{y}\quad V(\pi)=\mu(1-\mu)\frac{\theta}{1+\theta}.
$$

La distribución beta-binomial se obtiene al marginalizar $y$. Esto es:

$$
f(y;n,\mu,\theta)=\int f(y|\pi)f(\pi)d\pi.
$$

La función de densidad de la distribución beta-binomial es:

$$
f(y;n,\mu,\theta)=\begin{pmatrix} n \\ y \end{pmatrix}\frac{\begin{bmatrix} \Pi_{k=0}^{y-1}(\mu+k\theta)\end{bmatrix} \begin{bmatrix} \Pi_{k=0}^{n-y-1}(1-\mu+k\theta)\end{bmatrix}}{\begin{bmatrix} \Pi_{k=0}^{n-1}(1+k\theta) \end{bmatrix}},
$$

para $y=0,1,...,n.$

Valor esperado y varianza de $y=s/n$:

$$
E(y)=\mu\quad\text{y}\quad V(y)=\begin{bmatrix} 1+(n-1)\frac{\theta}{1+\theta} \end{bmatrix}\mu(1-\mu)\frac{1}{\mu}.
$$

Por lo cual, $\phi=\theta/(1+\theta)$ es la correlación entre ensayos Bernoulli.

Binomial(15,0.3)(negro), beta-binomial(15,0.3,$\phi$=0,1)(rojo), beta-binomial(15,0.3,$\phi$=0,3)(verde)

```{r, echo=FALSE,fig.align='center', fig.cap="", out.width = '75%'}
knitr::include_graphics(here::here("figs", "DistrBetabin.jpg"))
```

### Modelo beta-binomial

Modelo:

$$
n_iy_i|\pi_i\sim binomial(n_i,\pi_i)\\
\pi_i\sim beta(\mu_i,\phi),
$$

Por lo cuál:

$$
E(y_i)=\mu_i\quad\text{y}\quad V(y_i)=[1+(n-1)\phi]\mu_i(1-\mu_i)/n_i
$$

La estimación de los parámetros $(\beta,\phi)$ se hace por máxima verosimilitud.

Dado que $\phi>0)$, el modelo beta-binomial no puede modelar datos con subdispersión.

#### Estudio de teratología

```{r,include=TRUE}
data(lirat,package = 'VGAM')
modlirat.binom = glm(cbind(R,N-R)~hb+as.factor(grp),family=binomial,data=lirat)
summary(modlirat.binom)

modlirat.betabinom =betabin(cbind(R,N-R)~as.factor(grp)+hb,data=lirat,random=~1)
modlirat.betabinom

AIC(modlirat.binom)
AIC(modlirat.betabinom)

deviance(modlirat.binom)
deviance(modlirat.betabinom)
```

```{r, echo=FALSE, include=TRUE, results="asis"}

mathy.df <- data.frame(b0=c("Binomial","Beta-Binomial"), 
                       b1=c(168.908,114.563),
                       b2=c(250.378,198.032),
                       b3=c(260.68,210.395))

colnames(mathy.df)<-c("Modelo","Deviance","AIC","BIC")

kable(mathy.df, escape=FALSE,format = "html", booktabs = T) %>%
  kable_styling(bootstrap_options = "striped",
                full_width = F)

```





















