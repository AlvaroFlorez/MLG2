#    Modelo logístico
```{r preamble7, include=FALSE}
library(MASS)
library(knitr)
library(kableExtra)
library(aod)
library(pROC)
data(birthwt)
```
## Casos de estudio

### Mortalidad de escarabajos

Número de escarabajos muertos después de cinco horas de
exposición a disulfuro de carbono gaseoso $(CS2mgl^{-1})$ en diversas concentraciones


|log.dosis|Escarabajos Total|Escarabajos Muertos|
|:--------|:----------------|:------------------|
|1.6907|59|6 |
|1.7242|60|13|
|1.7552|62|18|
|1.7842|56|28|
|1.8113|63|52|
|1.8369|59|53|
|1.8610|62|61|
|1.8839|60|60|
¿Hay una relación entre la dosis y la mortalidad de escarabajos?

```{r, fig.align='center',fig.cap="Datos escarabajos."}
logdose <- c(1.6907, 1.7242, 1.7552, 1.7842, 1.8113, 1.8369, 1.8610, 1.8839)
dead <- c(6, 13, 18, 28, 52, 53, 61, 60) # numbers dead
n <- c(59, 60, 62, 56, 63, 59, 62, 60) # binomial sample sizes
Datos=data.frame(logdose,n,dead)

plot(logdose,dead/n,xlab='log dosis',ylab='proporción de muertos',ylim=c(0,1),pch=16)
```

**Variable respuesta $y_i=\sum_{j=1}^{n_i}y_{ij}/n_{i}$:** proporción de escarabajos muertos.

**Distribución de probabilidad:** binomial:

$$
f(n_iy_i;\pi_i)=\begin{pmatrix} n_i \\ n_iy_i \end{pmatrix} \pi_i^{n_iy_i}(1-\pi_i)^{(n_i-n_iy_i)}.
$$

**Función de enlace:**

$$
log \begin{pmatrix} \frac{\pi_i}{1-\pi_i} \end{pmatrix}=\beta_0+\beta_1log\text{dosis}_i.
$$

### Bajo peso al nacer

Se busca identificar factores de riesgo asociados con el nacimiento de niños con bajo peso ($<2.5$ kgs). datos: ```data(birthwt,package= 'MASS'```)

**Muestra:**189 madres atendidas en una clínica.

**Variable respuesta:** Bajo peso al nacer (1 si peso $<$ 2.5 kgs, 0 si peso $\geq$ 2.5 kgs).

Posibles covariables:

* ```age```: edad de la madre (años).

* ```lwt```: peso de la madre antes del embarazo (libras).

* ```smoke```: estado de tabaquismo durante el embarazo (0 no, 1 si).

* ```ptl```: historia de parto prematuro (número de casos).

**Variable respuesta $y_i$:** bajo peso al nacer (0: no, 1: si)

**Distribución de probabilidad:** Bernoulli:

$$
f(y_i;\pi_i)=\pi_i^{y_i}(1-\pi_i)^{(1-y_i)}.
$$

**Función de enlace:**

$$
log\begin{pmatrix} \frac{\pi_i}{1-\pi_i} \end{pmatrix}=\beta_0+\beta_1\text{age}_i+\beta_2\text{lwt}_i+\beta_3\text{smoke}_i+\beta_4\text{ptl}_i.
$$

### Estudio de teratología

Se quiere investigar los efectos de agentes químicos en el desarrollo fetal de ratas. datos: ```data(lirat,package = 'VGAM')```.

**Muestra:** 58 ratas hembras con dietas deficientes en hierro.

**Variable respuesta:** proporción de fetos muertos.

Posibles covariables:

* ```grp```: tratamiento (1: placebo, 2-4: diferentes concentraciones de inyecciones de suplementos de hierro)

* ```hb```: nivel de hemoglobina.

```{r, fig.align='center',fig.cap="Datos teratoligía"}
data(lirat,package = 'VGAM')
par(mfrow=c(1,2))
#Proporcion de fetos muestos vs tratamiento
plot(lirat$grp,lirat$R/lirat$N,xlab="Tratamiento",ylab="Proporción de fetos muertos")
#Proporcion de fetos muestos vs Hemoglobina
plot(lirat$hb,lirat$R/lirat$N,xlab="Hemoglobina",ylab="Proporción de fetos muertos")
```

**Variable respuesta $y_i=\sum_{j=1}^{n_i}y_{ij}/n_i$:** proporción de fetos muertos por hembra.

**Distribución de probabilidad:**binomial:

$$
f(n_iy_i;\pi_i)=\begin{pmatrix} n_i \\ n_iy_i \end{pmatrix} \pi_i^{n_iy_i}(1-\pi_i)^{(n_i-n_iy_i)}.
$$

**Función de enlace:**

$$
log\begin{pmatrix} \frac{\pi_i}{1-\pi_i} \end{pmatrix}=\beta_0+\beta_1\text{grp}_{i1}+\beta_2\text{grp}_{i2}+\beta_3\text{grp}_{i3}+\beta_4\text{hb}_i.
$$

## Datos agrupados o datos no agrupados

**Datos agrupados:** Hay $n_i$ observaciones que tienen los mismos valores de las covariables $x_i$.

**Datos no agrupados:** Hay $n_i=1$ (o muy pocas) observaciones por cada $x_i$.

Las propiedades asintóticas de las inferencias para los datos no agrupados aplican cuando $n \to \infty$.

Mientras que para datos agrupados, aplican cuando $\sum_{i=1}^nn_i\to\infty$.

### Datos agrupados

Para datos agrupados, $D$ y $X^2$ sirven para evaluar si el ajuste del modelo es bueno o no.

$H_0$ indica que el modelo se ajusta bien a los datos, $H_1$ lo contrario.

Si $H_0$ es cierta (y $\sum_{i=1}^nn_i\to\infty$), entonces $D$ y $X^2$ siguen una distribución $\chi^2$ con $(n-p)$ grados de libertad.

### Datos no agrupados

Las distribuciones límite para $D$ y $X^2$  no aplican para datos no agrupados.

Tampoco para datos agrupados con $n$ grande y con algunos $n_i$ muy pequeños.

Se puede aproximar $D$ y $X^2$ agrupando $(\bx_i,\hat{\by})$ por particiones del espacio de covariables o por particiones de $\hat{\pi}$.

La falta de ajuste se puede hacer comparando el modelo propuesto contra modelos más generales.

## Modelo logístico

Modelo:

$$
n_iy_i\sim\text{binomial}(n_i,\pi_i),\quad \text{donde} \quad \pi_i=g(\bx_i\bbeta).
$$ 

Entonces: $E(y_i|\bx_i)=\pi_i$ y $V(y_i|\bx_i)=\pi_i(1-\pi_i)/n_i$.

Función de enlace logit: $log\begin{pmatrix} \frac{\pi_i}{1-\pi_i} \end{pmatrix}=\bx_i\bbeta$.

Lo que implica que:

$$
\pi_i=g^{-1}(\bx_i,\bbeta)=\frac{exp(\bx_i'\bbeta)}{1+exp(\bx_i'\bbeta)}=\frac{1}{1+exp(-\bx_i'\bbeta)} 
$$

Aunque podemos utilizar otras funciones de enlace.

### Funciones de enlace alternativas

**Probit:**

$$
\Phi^{-1}(\pi_i)=\bx'_i\bbeta \quad \pi_i=\Phi(\bx'_i\bbeta),
$$

donde $\Phi(\cdot)$ es función acumulativa de la distribución normal estándar.

**Log-log complementaria:**

$$
\pi_i=1-exp[-exp(\bx'_i\bbeta)] \quad log[-log(1-\pi_i)]=\bx'_i\bbeta.
$$

**Log-log:**

$$
\pi_i=exp[-exp(\bx'_i\bbeta)] \quad -log[-log(\pi_i)]=\bx'_i\bbeta.
$$

```{r,echo=FALSE,fig.align='center',fig.cap="Estimaciones con funciones de enlace: logit(negro), probit(rojo) y cloglog(verde)."}

pred.x = data.frame(logdose = seq(min(logdose),max(logdose),length.out = 50))

modEsc.logit = glm(cbind(dead,n-dead)~logdose,family=binomial(logit))
modEsc.probit = glm(cbind(dead,n-dead)~logdose,family=binomial(probit))
modEsc.cloglog = glm(cbind(dead,n-dead)~logdose,family=binomial(cloglog))

pred.logit = predict(modEsc.logit,pred.x,type='response')
pred.probit = predict(modEsc.probit,pred.x,type='response')
pred.cloglog = predict(modEsc.cloglog,pred.x,type='response')

plot(pred.x$logdose,xlim=c(1.69,1.88),ylim=c(0,1),xlab='log dosis',ylab='proporción de escarabajos muertos')
lines(pred.x$logdose,pred.logit)
lines(pred.x$logdose,pred.probit,col=2)
lines(pred.x$logdose,pred.cloglog,col="green")

```

```{r, echo=FALSE, include=TRUE, results="asis"}


mathy.df <- data.frame(b4=c("Intercept", "Dosis","log.lik","AIC"), 
                       b0=c("$\\beta_0$","$\\beta_1$","",""), 
B1=c(-60.72,34.27,-18.71,41.43),
B2 = c(5.18,2.91,"",""),
B3 = c(-34.94,19.73,-18.16,40.32),
B4 = c(2.65,1.49,"",""),
B5 = c(-39.57,22.04,-14.82,33.64),
B6 = c(3.24,180,"",""))

colnames(mathy.df)<-c("Effect","Parm","est.","s.e","est.","s.e","est.","s.e")

kable(mathy.df, escape=FALSE,format = "html", booktabs = T) %>%
  kable_styling(bootstrap_options = "striped",
                full_width = F) %>%
  add_header_above(c("","","logit" = 2, "porbit" = 2, "cloglog" = 2))
```

```{r}
modbw.logit = glm(low~age+lwt+ptl+smoke,family=binomial(logit),data=birthwt)
summary(modbw.logit)

modbw.probit = glm(low~age+lwt+smoke+ptl,family=binomial(probit),data=birthwt)

summary(modbw.probit)
```

## Curva característica operativa del receptor(ROC)

Para evaluar el poder predictivo del modelo se puede construir una
tabla de contingencia:

```{r, echo=FALSE, include=TRUE, results="asis"}

mathy.df <- data.frame(b4=c(0,1), 
                       b0=c("",""),
                       b1=c("",""))

colnames(mathy.df)<-c("y","0","1")

kable(mathy.df, escape=FALSE,format = "html", booktabs = T,caption = "Tabla de clasificación") %>%
  kable_styling(bootstrap_options = "striped",
                full_width = F) 
```
El recuento de casillas en estas tablas permite estimar la sensibilidad=$(\hat y=1|y=1)$ y especificidad=$(\hat y=0|y=0)$.

Para datos no agrupados, la predicción $\hat{y}=1$ cuando $\hat{\pi_i}\geq\pi_0$(por ejemplo 0,5).

Para $\pi_0$, se calcula:

* La sensibilidad $P(\hat y=1|y=1)$.

* La especificidad $P(\hat y=0|y=0)$.

Dado que estos valores dependen de $\pi_0$, se pueden calcular para todos los posibles $\pi_0$.

**Ejemplo - Datos de peso al nacer**

Por ejemplo, si $\pi_0$, tenemos:

```{r, echo=FALSE, include=TRUE, results="asis"}

mathy.df <- data.frame(b0=c("$y=0$","$y=1$"), 
                       b1=c(123,49),
                       b2=c(7,10))

colnames(mathy.df)<-c("y","0","1")

kable(mathy.df, escape=FALSE,format = "html", booktabs = T) %>%
  kable_styling(bootstrap_options = "striped",
                full_width = F) %>%add_header_above(c("","$\\hat{y}=0$","$\\hat{y}=1$"))

```

Sensibilidad: $10/59 = 0,169$ - especificidad: $123/130 = 0,946$.

Ahora, si $\pi_0= 0,3$:

```{r, echo=FALSE, include=TRUE, results="asis"}

mathy.df <- data.frame(b0=c("$y=0$","$y=1$"), 
                       b1=c(79,19),
                       b2=c(51,40))

colnames(mathy.df)<-c("y","0","1")

kable(mathy.df, escape=FALSE,format = "html", booktabs = T) %>%
  kable_styling(bootstrap_options = "striped",
                full_width = F) %>%add_header_above(c("","$\\hat{y}=0$","$\\hat{y}=1$"))

```

Sensibilidad: $40/59 = 0,678$ - especificidad: $79/130 = 0,607$.



```{r, fig.align = 'center',out.width = "75%",echo=FALSE, fig.cap="Sensibilidad (linea negra) - especificidad (linea roja)"}
knitr::include_graphics(here::here("figs", "grafsen.jpg"))
```

Gráfico de $P(\hat y=1|y=1)$ vs $P(\hat y=0|y=0)$

```{r, fig.align = 'center',out.width = "75%",echo=FALSE}
knitr::include_graphics(here::here("figs", "Sensibilidad.png"))
```


El area bajo la curva de la curva ROC (llamado índice de concordancia) es una medida del poder predictivo del modelo.

### Ejemplo mortalidad de escarabajos

Curva ROC para el modelo logístico:

"grafico roc escarabajos"

### Bajo peso al nacer
```{r,eval=FALSE}
 
modbw.logit = glm(low~age+lwt+ptl+smoke,family=binomial(logit),data=birthwt)
modbw.probit = glm(low~age+lwt+smoke+ptl,family=binomial(probit),data=birthwt)
# curvas roc
#library(pROC)
ROCbw.logit = roc(birthwt$low~modbw.logit$fitted.values)
ROCbw.probit = roc(birthwt$low~modbw.probit$fitted.values)


```

```{r,include=FALSE}
 
modbw.logit = glm(low~age+lwt+ptl+smoke,family=binomial(logit),data=birthwt)
modbw.probit = glm(low~age+lwt+smoke+ptl,family=binomial(probit),data=birthwt)
# curvas roc
#library(pROC)
ROCbw.logit = roc(birthwt$low~modbw.logit$fitted.values)
ROCbw.probit = roc(birthwt$low~modbw.probit$fitted.values)


```

```{r, fig.align='center', fig.cap="Curva ROC para el modelo logístico (negro) y probit (rojo)"}
plot(ROCbw.logit)
lines(ROCbw.probit,col=2)

```

modelo logístico: $AUC= 0,6884$.

modelo probit: $AUC= 0,6866$.


## Sobredispersión

En un experimento Bernoulli se asume que los $n_i$ ensayos para la observación $i,\quad y_{i1},...y_in_i$ son independientes.

Por lo tanto, tenemos que:

$$
E(y_i)=\pi_i\quad \text{y} \quad V(y_i)=\pi_i(1-\pi_i)\frac{1}{n_i}.
$$

Pero, hay casos donde las observaciones $y_{i1},...y_in_i$ están correlacionadas, es decir $cor(y_{is},y_{it})\ne0$.

Por lo general, se asume que $cor(y_{is},y_{it})=\phi$, para todo $s\ne t$ (exchangeability property). Entonces:

$$
V(y_{it})=\pi_i(1-\pi_i)\quad \text{y} \quad cor(y_{it},y_{is})=\phi\pi_i(1-\pi_i).
$$

En este caso, tenemos que:

$$
V(y_i)=V\begin{pmatrix} \sum_{j=1}^{n_i}\frac{y_{ij}}{n_i}\end{pmatrix}=\frac{1}{n_i^2} \left[ \sum_{j=1}^{n_i}V(y_{it})+2\sum\sum_{s<t}cov(y_{is},y_{it}) \right]=[1+\phi(n_i-1)]\frac{\pi_i(1-\pi_i)}{n_i}.
$$


Si:

* $\phi=0$, $y_i\sim  binomial(n_i,\pi)$.

* $\phi>0$, tenemos sobredispersión.

* $-(n_i-1)^{-1}<\phi<0$, tenemos subdispersión (menos
frecuente).

En el caso del modelo binomial, tenemos que:

$$
v(\pi_i)=\pi_i(1-\pi_i)/n_i.
$$

El estadístico de $\chi^2$ de Pearson es:

$$
X^2=\sum_{i=1}^n\frac{(y_i-\hat{\pi}_i)^2}{\pi_i(1-\pi_1)/n_i}
$$

Un indicador de posible inflación de varianza es:

$$
\hat{\phi}=\frac{X^2}{n-p}.
$$

Si no hay problemas de sobredispersión $\hat{\phi}\approx1$.

## Distribución beta-binomial

Modelo: $y|\pi\sim binomial(n,\pi)$

Donde $\pi\sim beta(\alpha_1,\alpha_2)$, esto es:

$$
f(\pi;\alpha_1,\alpha_2)=\frac{\Gamma(\alpha_1+\alpha_2)}{\Gamma(\alpha_1)\Gamma(\alpha_2)}\pi^{\alpha_1-1}(1-\pi)^{\alpha_2-1}
$$

con $\alpha_1>0$ y $\alpha_2>0$.

Asumiendo $\mu=\frac{\alpha_1}{\alpha_1+\alpha_2}$ y $\theta=1/(\alpha_1+\alpha_2)$, tenemos:

$$
E(\pi)=\mu\quad\text{y}\quad V(\pi)=\mu(1-\mu)\frac{\theta}{1+\theta}.
$$

La distribución beta-binomial se obtiene al marginalizar $y$. Esto es:

$$
f(y;n,\mu,\theta)=\int f(y|\pi)f(\pi)d\pi.
$$

La función de densidad de la distribución beta-binomial es:

$$
f(y;n,\mu,\theta)=\begin{pmatrix} n \\ y \end{pmatrix}\frac{\begin{bmatrix} \Pi_{k=0}^{y-1}(\mu+k\theta)\end{bmatrix} \begin{bmatrix} \Pi_{k=0}^{n-y-1}(1-\mu+k\theta)\end{bmatrix}}{\begin{bmatrix} \Pi_{k=0}^{n-1}(1+k\theta) \end{bmatrix}},
$$

para $y=0,1,...,n.$

Valor esperado y varianza de $y=s/n$:

$$
E(y)=\mu\quad\text{y}\quad V(y)=\begin{bmatrix} 1+(n-1)\frac{\theta}{1+\theta} \end{bmatrix}\mu(1-\mu)\frac{1}{\mu}.
$$

Por lo cual, $\phi=\theta/(1+\theta)$ es la correlación entre ensayos Bernoulli.

Binomial(15,0.3)(negro), beta-binomial(15,0.3,$\phi$=0,1)(rojo), beta-binomial(15,0.3,$\phi$=0,3)(verde)

```{r, echo=FALSE,fig.align='center', fig.cap="", out.width = '75%'}
knitr::include_graphics(here::here("figs", "DistrBetabin.jpg"))
```

### Modelo beta-binomial

Modelo:

$$
n_iy_i|\pi_i\sim binomial(n_i,\pi_i)\\
\pi_i\sim beta(\mu_i,\phi),
$$

Por lo cuál:

$$
E(y_i)=\mu_i\quad\text{y}\quad V(y_i)=[1+(n-1)\phi]\mu_i(1-\mu_i)/n_i
$$

La estimación de los parámetros $(\beta,\phi)$ se hace por máxima verosimilitud.

Dado que $\phi>0)$, el modelo beta-binomial no puede modelar datos con subdispersión.

#### Estudio de teratología

```{r,include=TRUE}
data(lirat,package = 'VGAM')
modlirat.binom = glm(cbind(R,N-R)~hb+as.factor(grp),family=binomial,data=lirat)
summary(modlirat.binom)

modlirat.betabinom =betabin(cbind(R,N-R)~as.factor(grp)+hb,data=lirat,random=~1)
modlirat.betabinom

AIC(modlirat.binom)
AIC(modlirat.betabinom)

deviance(modlirat.binom)
deviance(modlirat.betabinom)
```

```{r, echo=FALSE, include=TRUE, results="asis"}

mathy.df <- data.frame(b0=c("Binomial","Beta-Binomial"), 
                       b1=c(168.908,114.563),
                       b2=c(250.378,198.032),
                       b3=c(260.68,210.395))

colnames(mathy.df)<-c("Modelo","Deviance","AIC","BIC")

kable(mathy.df, escape=FALSE,format = "html", booktabs = T) %>%
  kable_styling(bootstrap_options = "striped",
                full_width = F)

```





















