#    Modelo logístico
```{r preamble7, include=FALSE}
library(MASS)
library(knitr)
library(kableExtra)
library(aod)
library(pROC)
data(birthwt)
```
## Casos de estudio

### Mortalidad de escarabajos
Vamos a trabajar con los datos del estudio sobre los escarabajos:
```{r datosEscarabajos}
logdose <- c(1.6907, 1.7242, 1.7552, 1.7842, 1.8113, 1.8369, 1.8610, 1.8839)
dead <- c(6, 13, 18, 28, 52, 53, 61, 60) 
n <- c(59, 60, 62, 56, 63, 59, 62, 60) 
Datos.esc=data.frame(logdose,n,dead)
```

### Bajo peso al nacer
Con los datos \texttt{birthwt} de la librería \texttt{MASS}, se quiere indentificar factores de riesgo asociados con el nacimiento de niños con bajo peso (es decir, un peso al nacer menor de $2.5$kgs). Se tiene información de 189 recién nacidos y sus madres atendidos en una hospital (Baystate Medical Center, Springfield, Mass en 1986). Los posibles factores que pueden afectar el bajo al peso son:

* ```age```: edad de la madre (años).

* ```lwt```: peso de la madre antes del embarazo (libras).

* ```smoke```: estado de tabaquismo durante el embarazo (0 no, 1 si).

* ```ptl```: historia de parto prematuro (número de casos).

La variable de respuesta es ```low``` (1 si peso $<$ 2.5 kgs, 0 si peso $\geq$ 2.5 kgs).

Para este caso, se puede ajustar modelo logístico. Sea $y_i=1$ si el $i$-ésimo bebé nace con bajo peso, $y_i=0$ si lo contrario. Por lo que la densidad de $y_i$ está definida como:
$$
f(y_i;\pi_i)=\pi_i^{y_i}(1-\pi_i)^{(1-y_i)},
$$
donde $\pi_i$ es la probabilidad de que el $i$-ésimo bebé nazca con bajo peso. La función de enlace es:
$$
\log\begin{pmatrix} \frac{\pi_i}{1-\pi_i} \end{pmatrix}=\beta_0+\beta_1\text{age}_i+\beta_2\text{lwt}_i+\beta_3\text{smoke}_i+\beta_4\text{ptl}_i.
$$
Sin embargo, se puede considerar alguna función de enlace diferente, como veremos adelante.
### Estudio de teratología
Los datos \texttt{lirat} de la librería \texttt{VGAM} son de un estudio para investigar los efectos de unos régimenes alimenticio  en el desarrollo fetal de ratas. En este experimento, 58 ratas hembras con dietas deficientes en hierro se dividieron en cuatro grupos.  Tres grupos recibieron inyecciones semanales de suplementos de hierro, a diferentes dosis, para normalizar sus niveles de hierro. Mientras que, el grupo restante no recibieron ningún suplemento (placebo). Luego, las ratas se preñaron, se sacrificaron 3 semanas después, y se contó el número de fetos muertos en cada camada.

En la Figura \@ref(fig:liratFig) se puede observar la relación entre el número de fetos muertos por tratamiento, y también, la relación con los niveles de hemoglobina de las ratas hembras.

```{r liratFig,  fig.height = 4, fig.width = 6, fig.align='center',fig.cap="Datos teratoligía. Relación entre la proporción de fetos muertos por camada con los tratamientos (izquierda) y los niveles de hemoglobina de la madra (derecha) "}
data(lirat,package = 'VGAM')
par(mfrow=c(1,2))
#Proporcion de fetos muestos vs tratamiento
plot(lirat$grp,lirat$R/lirat$N,xlab="Tratamiento",ylab="Proporción de fetos muertos")
#Proporcion de fetos muestos vs Hemoglobina
plot(lirat$hb,lirat$R/lirat$N,xlab="Hemoglobina",ylab="Proporción de fetos muertos")
```

Si consideramos:
\[
y_{ij} = \begin{cases}
1 & \mbox{ si el feto } j \mbox{ de la camada }i\mbox{ está muerto}, \\
0 & \mbox{ si lo contrario}, \\
 \end{cases}
\]
la variable número de fetos muertos se puede asociar a una distribución binomial:
\[
y_i = \sum_{j=1}^{n_i} y_{ij} \sim \mbox{binomial}(n_i, \pi_i),
\]
donde $n_i$ es el tamaño de la camada y $\pi_i$ es la probabilidad de que el feto muera. Dado que $\pi_i$ depende del tratamiento y de los niveles de hemoglobina de la rata hembra, se propone que:
\[
\log\begin{pmatrix} \frac{\pi_i}{1-\pi_i} \end{pmatrix}=\beta_0+\beta_1\text{grp1}_{i}+\beta_2\text{grp2}_{i}+\beta_3\text{grp3}_{i}+\beta_4\text{hb}_i,
\]
donde: $\text{grp1}_{i}=1$ si la $i$-ésima hembra pertenece al grupo 1, $\text{grp1}_{i}=0$ si lo contrario; $\text{grp2}_{i}=1$ si la $i$-ésima hembra pertenece al grupo 2, $\text{grp2}_{i}=0$ si lo contrario; $\text{grp3}_{i}=1$ si la $i$-ésima hembra pertenece al grupo 3, $\text{grp3}_{i}=0$ si lo contrario; y ``hb_i`` es el nivel de hemoglobina de la hembra $i$.

## Datos agrupados o datos no agrupados
Los datos binarios tienen dos tipos de formatos:

**Datos agrupados:** Hay $n_i$ observaciones que tienen los mismos valores de las covariables $x_i$. Aquí tenemos que para agrupación, $y_i \sim$binomial$(n_i,\pi_i)$.

**Datos no agrupados:** Hay $n_i=1$ (o muy pocas) observaciones por cada $x_i$. Es decir que, cada $y_i$ sigue una distribución Bernoulli$(\pi_i)$.

Las propiedades asintóticas de las inferencias para los datos no agrupados aplican cuando $N \to \infty$. Mientras que para datos agrupados, aplican cuando $\sum_{i=1}^nn_i\to\infty$.

### Datos agrupados
Para datos agrupados, $D$ y $X^2$ sirven para evaluar si el ajuste del modelo es bueno o no. Aquí podemos plantear las siguientes hipótesis: $H_0$ indica que el modelo se ajusta bien a los datos, $H_1$ lo contrario.

Si $H_0$ es cierta (y $\sum_{i=1}^nn_i\to\infty$), entonces $D$ y $X^2$ siguen una distribución $\chi^2$ con $(n-p)$ grados de libertad.

### Datos no agrupados
Las distribuciones límite para $D$ y $X^2$  no aplican para datos no agrupados. Tampoco para datos agrupados con $N$ grande y algunos $n_i$ muy pequeños. Se puede aproximar $D$ y $X^2$ agrupando $(\bx_i,\hat{\by})$ por particiones del espacio de covariables o por particiones de $\hat{\pi}$. En estos casos, es preferible evaluar la falta de ajuste comparando el modelo propuesto contra modelos más generales.

## Funciones de enlace
En los modelos anteriores hemos propuesto funciones de enlace logit: $log\begin{pmatrix} \frac{\pi_i}{1-\pi_i} \end{pmatrix}=\bx_i\bbeta$.Lo que implica que:

$$
\pi_i=g^{-1}(\bx_i,\bbeta)=\frac{\exp(\bx_i'\bbeta)}{1+\exp(\bx_i'\bbeta)}=\frac{1}{1+\exp(-\bx_i'\bbeta)} 
$$
Sin embargo, podemos utilizar otras funciones de enlace. Por ejemplo, la función **Probit:**
$$
\Phi^{-1}(\pi_i)=\bx'_i\bbeta \quad \pi_i=\Phi(\bx'_i\bbeta),
$$
donde $\Phi(\cdot)$ es función acumulativa de la distribución normal estándar. La función **Log-log complementaria:**
$$
\pi_i=1-\exp[-\exp(\bx'_i\bbeta)] \quad \log[-\log(1-\pi_i)]=\bx'_i\bbeta.
$$
En la Figura \@ref(fig:linkEsc) podemos observar la estimación de la probabilidad de que el escarabajo muera utilizando diferentes funciones de enlace (logit, probit, log-log complementaria). Graficamente, la función log-log complementaria parece mostrar mejores estimaciones que la probit y la logit.

```{r linkEsc,echo=FALSE, fig.height = 4, fig.width = 6,fig.align='center',fig.cap="Datos de mortalidad de escarabajos. Estimaciones de la probabilidad de que el escarabajo muera en función de la dosis utilizando diferentes funciones de enlace: logit(negro), probit(rojo) y cloglog(verde)."}

pred.x = data.frame(logdose = seq(min(logdose),max(logdose),length.out = 50))

modEsc.logit = glm(cbind(dead,n-dead)~logdose,family=binomial(logit))
modEsc.probit = glm(cbind(dead,n-dead)~logdose,family=binomial(probit))
modEsc.cloglog = glm(cbind(dead,n-dead)~logdose,family=binomial(cloglog))

pred.logit = predict(modEsc.logit,pred.x,type='response')
pred.probit = predict(modEsc.probit,pred.x,type='response')
pred.cloglog = predict(modEsc.cloglog,pred.x,type='response')

plot(logdose,dead/n,xlim=c(1.69,1.88),ylim=c(0,1),xlab='log dosis',ylab='proporción de escarabajos muertos')
lines(pred.x$logdose,pred.logit,lwd=2)
lines(pred.x$logdose,pred.probit,col=2,lwd=2)
lines(pred.x$logdose,pred.cloglog,col=3,lwd=2)
```

Este resultado se puede comprobar utilizando criterios de información:
```{r linkEscAIC,echo=T}
AIC(modEsc.logit)
AIC(modEsc.probit)
AIC(modEsc.cloglog)
```
## Curva característica operativa del receptor(ROC)
Para evaluar el poder predictivo del modelo se puede construir una tabla de contingencia (ver Tabla \@ref(tab:tabcont)) comparando $y_i$ con la predicción $\haty_i$ a través del modelo. Para datos no agrupados, la predicción $\haty_i$ se define como:
\[
\haty_i = \begin{cases}
1 & \mbox{si } \hatpi_i > \pi_0, \\
0 & \mbox{si } \hatpi_i \leq \pi_0, \\
\end{cases}
\]
para un punto de corte $\pi_0$ definido por el investigador, por ejemplo $\pi_0 = 0.5$.

```{r tabcont, echo=FALSE, include=TRUE, results="asis"}
mathy.df <- data.frame(b0=c("$y=0$","$y=1$"), 
                       b1=c('a','b'),
                       b2=c('c','d'))

colnames(mathy.df)<-NULL

kable(mathy.df, escape=FALSE,format = "html", booktabs = T) %>%
  kable_styling(bootstrap_options = "striped",
                full_width = F) %>%add_header_above(c("","$\\hat{y}=0$","$\\hat{y}=1$"))
```

El recuento de casillas en estas tablas permite estimar la sensibilidad, 
\[
P(\haty=1|y=1) = \frac{d}{b+d},
\]
y la especificidad, $P(\haty=0|y=0)$.
\[
P(\haty=0|y=0) = \frac{a}{a+c}.
\]
Sin embargo, estos valores dependen de $\pi_0$.

Ahora consideremos los datos de peso al nacer. Se propone el siguiente modelo:
\[
\mbox{logit } \pi_i = \beta_0+  \mbox{age}_i\beta_1+  \mbox{lwt}_i\beta_2 +  \mbox{smoke}_i\beta_3 + \mbox{ptl}_i\beta_4,
\]
donde $\pi_i$ es la probabilidad de que el recién nacido nazca con bajo peso. El ajuste del modelo es:

```{r lbwfit, echo=FALSE, include=TRUE}
mod.lbw = glm(low ~ age + lwt + smoke + ptl, data= birthwt,family=binomial)
summary(mod.lbw)
```
Estos resultados muestran que el estado de tabaquismo y el historial de partos prematuros son factores de riesgo para el bajo peso al nacer. Sin embargo, el primero no tiene un aporte significativo dentro del modelo.

Ahora vamos a evaluar el poder predictivo del modelo. Si definimos $\pi_0=0.5$, tenemos:

```{r roc1, echo=FALSE, include=TRUE, results="asis"}
obs = birthwt$low
pred = mod.lbw$fitted.values > 0.5
tab1 = table(obs,pred)

mathy.df <- data.frame(b0=c("$y=0$","$y=1$"), 
                       b1=c(tab1[1,1],tab1[2,1]),
                       b2=c(tab1[1,2],tab1[2,2]))

colnames(mathy.df)<-NULL

kable(mathy.df, escape=FALSE,format = "html", booktabs = T) %>%
  kable_styling(bootstrap_options = "striped",
                full_width = F) %>%add_header_above(c("","$\\hat{y}=0$","$\\hat{y}=1$"))

```
Por lo tanto, la sensibilidad es $10/59 = 0,169$ y la especificidad es $123/130 = 0.946$. Con este punto de corte, el modelo tiene una predictividad alta para los recién nacidos con peso adecuado (alta especificidad). Sin embargo, la probabilidad de falsos positivos es alta (baja sensibilidad). Ahora, si $\pi_0= 0,3$:

```{r, echo=FALSE, include=TRUE, results="asis"}
obs = birthwt$low
pred = mod.lbw$fitted.values > 0.3
tab1 = table(obs,pred)

mathy.df <- data.frame(b0=c("$y=0$","$y=1$"), 
                       b1=c(tab1[1,1],tab1[2,1]),
                       b2=c(tab1[1,2],tab1[2,2]))

colnames(mathy.df)<-NULL

kable(mathy.df, escape=FALSE,format = "html", booktabs = T) %>%
  kable_styling(bootstrap_options = "striped",
                full_width = F) %>%add_header_above(c("","$\\hat{y}=0$","$\\hat{y}=1$"))

```

En este caso la sensibilidad aumentó $(40/59 = 0,678)$, pero la especificidad disminuye $(79/130 = 0,607)$. 

Dado que la sensibilidad y especificidad tiene una alta dependencia del punto de corte, lo preferible es calcular estas cantidades para muchos valores de $\pi_0$. En la Figura \@ref(fig:sensespc) podemos observar que a medida que aumenta $\pi_0$ la sensibilidad disminuye y la especificidad aumenta.

```{r sensespc, fig.align = 'center', fig.height = 4, fig.width = 6,echo=FALSE, fig.cap="Datos de bajo peso al nacer. Sensibilidad (linea negra) y especificidad (linea roja) para diferentes puntos de corte."}
tab.fun = function(obs,fit,pi0){
pred0 = fit > pi0
tab = table(obs,pred0)
senc = tab[2,2]/sum(tab[2,])
espc = tab[1,1]/sum(tab[1,])
c(senc,espc)
}
pi0 = seq(0.1,0.8,length.out=500)
sens.espc = mapply(function(x){tab.fun(obs,mod.lbw$fitted.values,pi0[x])},x=1:500)

plot(pi0,sens.espc[1,],lwd=2,type = 'l',xlab=expression(pi[0]),ylab='Sensibilidad y especificidad')
lines(pi0,sens.espc[2,],lwd=2,col=2)
```
La sensibilidad es la tasa de verdaderos positivos (tvp), mientras que, el complemento de la especificidad $(P(\haty = 1 | y=0))$ es la tasa de falsos positivos (tfp). El gráfico de la tasa de verdaderos positivos en función de la tasa de falsos positivos para diferentes valores de $\pi_0$, entre $0$ y $1$, lleva el nombre de curva característica operativa del receptor (ROC). Cuando $\pi_0$ es muy cercano a $1$, casi todas las predicciones son $\haty =0$; entonces tenemos (tvp,tfp)$\approx(0,0)$. Mientras que, cuando $\pi_0$ es muy cercano a $0$, casi todas las predicciones son $\haty =1$; entonces tenemos (tvp,tfp)$\approx(1,1)$. esto lo podemos ver en la Figura \@ref(fig:sensespc2).

```{r sensespc2, fig.align = 'center', fig.height = 4, fig.width = 6,echo=FALSE,fig.cap="Datos de bajo peso al nacer. Sensibilidad (linea negra) y especificidad (linea roja) para diferentes puntos de corte."}
plot(1-sens.espc[2,],sens.espc[1,],lwd=2,xlab='1 - especificidad',
     ylab='sensibilidad')
```
Si el modelo realiza buenas predicciones, para un valor de especificidad dado, se espera que la sensibilidad también sea alta. Por lo tanto, el poder predictivo del modelo se puede medir a través del área bajo la curva del gráfico ROC. Esta medida es llamada índice de concordancia.


En R, las curvas ROC se puede graficar con la función `roc` de la librería `pROC` de la siguiente forma:
```{r ROClbwdata,eval=T,fig.cap="Datos de bajo peso al nacer. Curva ROC para el modelo logístico (negro) y probit (rojo)",fig.height = 4, fig.width = 6}
library(pROC)
modbw.logit = glm(low~age+lwt+ptl+smoke,family=binomial(logit),data=birthwt)
modbw.probit = glm(low~age+lwt+smoke+ptl,family=binomial(probit),data=birthwt)

ROCbw.logit = roc(birthwt$low~modbw.logit$fitted.values)
ROCbw.probit = roc(birthwt$low~modbw.probit$fitted.values)
plot(ROCbw.logit)
lines(ROCbw.probit,col=2)
```
En la Figura \@ref(fig:ROClbwdata) se puede observar que ambas funciones de enlace proporcionan el mismo poder predictivo. El índice de concordancia es de $AUC= 0,6884$ para el modelo logístico y $AUC= 0,6866$ para el modelo probit.    

Para datos agrupados, la base de datos se debe desagrupar para obtener la curva ROC. Por ejemplo para los datos de escarabajos:

```{r ROCescarabajos,eval=T,fig.cap="Datos de mortalidad de escarabajos. Curva ROC para el modelo logístico",fig.height = 4, fig.width = 6}
obs.morir = unlist(apply(Datos.esc,1,function(x){rep(c(1,0),c(x[3],x[2]-x[3]))}))
prob.morir =rep(modEsc.logit$fitted.values,Datos.esc$n)
ROCesc = roc(obs.morir~prob.morir)
plot(ROCesc,print.auc=T)
```


Datos.esc

## Sobredispersión
En un experimento Bernoulli se asume que los $n_i$ ensayos para la observación $i,\quad (y_{i1},...y_{in_i})$, son independientes. Por lo tanto, para $y_i = \sum_{j=1}^{n_i}y_{ij}/n_i$,tenemos que:

$$
E(y_i)=\pi_i \quad \text{y} \quad V(y_i)=\pi_i(1-\pi_i)\frac{1}{n_i}.
$$

Pero, hay casos donde las observaciones $(y_{i1},...y_{in_i})$ están correlacionadas, es decir $cor(y_{is},y_{it}) \ne 0$. Esto hace que $V(y_{i}) \neq V(y_i)=\pi_i(1-\pi_i)\frac{1}{n_i}$. Si asumimos que $cor(y_{is},y_{it})=\phi$, para todo $s\ne t$ (exchangeability property). Entonces:

$$
V(y_{it})=\pi_i(1-\pi_i)\quad \text{y} \quad cor(y_{it},y_{is})=\phi\pi_i(1-\pi_i).
$$

En este caso, tenemos que:

$$
V(y_i)=V\begin{pmatrix} \sum_{j=1}^{n_i}\frac{y_{ij}}{n_i}\end{pmatrix}=\frac{1}{n_i^2} \left[ \sum_{j=1}^{n_i}V(y_{it})+2\sum\sum_{s<t}cov(y_{is},y_{it}) \right]=[1+\phi(n_i-1)]\frac{\pi_i(1-\pi_i)}{n_i}.
$$
Dependiendo del valor de $\phi$, la varianza de $y_i$ puede ser mayor o menor a la esperada bajo una distribución binomial. Si $\phi_i > 0$, tenemos un problema de sobredispersión (los datos tienen una varianza superior a la que se asume bajo un modelo binomial). Mientras que, si $-(n_i-1)^{-1}<\phi<0$, hay presencia de subdispersión. El segunda caso es menos frecuenta en datos reales.

### Evalaución de sobredispersión
En el caso del modelo binomial, el estadístico de $\chi^2$ de Pearson está definido como:

$$
X^2=\sum_{i=1}^n\frac{(y_i-\widehat{\pi}_i)^2}{\widehat{\pi}_i(1-\widehat{\pi}_1)/n_i}.
$$
Si el modelo binomial proporciona buen ajuste, $X^2$ sigue (asintóticamente) una distribución $\chi^2$ con $n-p$ grados de libertad. Por lo tanto, un indicador de posible inflación de varianza es:
$$
\widehat{\phi}=\frac{X^2}{n-p}.
$$
Si hay problemas de sobredispersión, entonces $\widehat{\phi} > 1$.

## Distribución beta-binomial
El modelo beta-binomial es una alternativa para modelar datos binomial con sobredispersión. Esta distribución parte de una mezcla de una distribución binomial con una distribución beta. Sea $y^{*}$ el número de éxitos de $n$ ensayos Bernoulli. Se puede suponer la siguiente distribución de $y^{*}$:
\[
y^{*}|\pi\sim \mbox{binomial}(n,\pi), \mbox{ donde } \pi\sim \mbox{beta}(\alpha_1,\alpha_2).
\]
La función de densidad de $\pi$ es:
$$
f(\pi;\alpha_1,\alpha_2)=\frac{\Gamma(\alpha_1+\alpha_2)}{\Gamma(\alpha_1)\Gamma(\alpha_2)}\pi^{\alpha_1-1}(1-\pi)^{\alpha_2-1},
$$
con $\alpha_1>0$ y $\alpha_2>0$. Asumiendo $\mu=\frac{\alpha_1}{\alpha_1+\alpha_2}$ y $\theta=1/(\alpha_1+\alpha_2)$, tenemos:

$$
E(\pi)=\mu\quad\text{y}\quad V(\pi)=\mu(1-\mu)\frac{\theta}{1+\theta}.
$$

La distribución beta-binomial se obtiene al marginalizar $y^{*}$. Esto es:

$$
f(y^{*};n,\mu,\theta)=\int f(y^{*}|\pi)f(\pi)d\pi.
$$
Al resolver la integral anterior, encontramos la función de densidad de la distribución beta-binomial es:

$$
f(y^{*};n,\mu,\theta)=\begin{pmatrix} n \\ y^{*} \end{pmatrix}\frac{\begin{bmatrix} \Pi_{k=0}^{y^{*}-1}(\mu+k\theta)\end{bmatrix} \begin{bmatrix} \Pi_{k=0}^{n-y^{*}-1}(1-\mu+k\theta)\end{bmatrix}}{\begin{bmatrix} \Pi_{k=0}^{n-1}(1+k\theta) \end{bmatrix}},
$$

para $y^{*}=0,1,...,n.$ El valor esperado y varianza de $y = \frac{y^{*}}{n}$ son:

$$
E(y)=\mu\quad\text{y}\quad V(y)=\left[ 1+(n-1)\frac{\theta}{1+\theta} \right]\frac{\mu(1-\mu)}{n} = \left[ 1+(n-1)\phi \right]\frac{\mu(1-\mu)}{n}.
$$

Por lo cual, $\phi > 0$ es la correlación entre ensayos Bernoulli. La distribución de probabilidad de la distribución beta-binomial se puede observar en la Figura \@ref(fig:betabinomialdensidad). Aquí vemos que la dispersión de la distribución beta-binomial aumenta con el parámetro $\phi$.


```{r betabinomialdensidad, echo=FALSE,fig.align='center', fig.cap="Distribución de probabilidad de Binomial(15,0.3) (negro), beta-binomial(15,0.3,0.1) (rojo), beta-binomial(15,0.3,0.4) (verde)", fig.height = 4, fig.width = 6}
library(VGAM)
x = 0:15
y0 = dbinom(x, 15, 0.3)
y1 = dbetabinom(x, 15, 0.3, rho = 0.1)
y2 = dbetabinom(x, 15, 0.3, rho = 0.4)
plot(x,y0,type='l',xlab='y',ylab='probabilidad',lwd=2)
lines(x,y1,col=2,lwd=2)
lines(x,y2,col=3,lwd=2)
```

### Modelo beta-binomial
El modelo beta-binomial para $y_i^{*}$ se define como:
$$
y_i^{*}|\pi_i\sim \mbox{binomial}(n_i,\pi_i), \mbox{ donde } \pi_i\sim \mbox{beta}(\mu_i,\phi),
$$
donde $\mbox{logit } \mu_i = \bx_{i}'\bbeta$ (si usamos una función de enlace logit). Por lo cuál, para $y_i = \frac{y_i^{*}}{n_i}$ se tiene que:
$$
E(y_i)=\mu_i\quad\text{y}\quad V(y_i)=[1+(n-1)\phi]\mu_i(1-\mu_i)/n_i,
$$
La estimación de los parámetros $(\beta,\phi)$ se hace por máxima verosimilitud. Dado que $\phi>0)$, el modelo beta-binomial no puede modelar datos con subdispersión.

### Estudio de teratología
Para los datos del estudio de teratología se puede proponer un modelo binomial en un principio:
\[
n_i y_i \sim \mbox{binomial} (n_i, \pi_i),
\]
donde $n_i$ y $y_i$ es el tamaño y la proporción de fetos muertos de la camada $i$. Además, se tiene que:
\[
\mbox{logit }\pi_i = \beta_0 + \mbox{hb}_i \beta_1 + \mbox{treat}_{2i} \beta_2 + \mbox{treat}_{3i}\beta_3 + \mbox{treat}_{4i} \beta_4.
\]
El ajuste del modelo es:
```{r liratmod0,include=TRUE}
data(lirat,package = 'VGAM')
modlirat.binom = glm(cbind(R,N-R)~hb+as.factor(grp),family=binomial,data=lirat)
summary(modlirat.binom)
```
La evaluación de sobredispersión la podemos hacer usando la razón entre el estadístico $\chi^2$ de Pearson y los grados de libertad:
```{r liratmod0chi,include=TRUE}
X2 = sum(residuals(modlirat.binom,type='pearson')^2)
X2/53
```
Dado que está razón es aproximadamente $3$, los datos presentan sobredispersión. Por esta razón es mas conveniente proponer un modelo beta-binomial:
$$
y_i^{*}|\pi_i\sim \mbox{binomial}(n_i,\pi_i), \mbox{ donde } \pi_i\sim \mbox{beta}(\mu_i,\phi),
$$
con 
\[
\mbox{logit }\pi_i = \beta_0 + \mbox{hb}_i \beta_1 + \mbox{treat}_{2i} \beta_2 + \mbox{treat}_{3i}\beta_3 + \mbox{treat}_{4i} \beta_4.
\]
En R el modelo beta-binomial se puede estimar utilizando la función `betabin` de la librería `aod`:
```{r liratmod1,include=TRUE}
library(aod)
modlirat.betabinom =betabin(cbind(R,N-R)~hb+as.factor(grp),data=lirat,random=~1)
modlirat.betabinom
```
Las estimaciones de los coeficientes del modelo beta-binomial son similares a los del modelo binomial. Sin embargo, los errores estándar son mas grandes. Esto último es debido al efecto de la sobredispersión ($\widehat{\phi}=0.236$ indica una correlación positiva entre los fetos que pertenecen a la misma camada). Además, el efecto del tratamiento \#4 no es significativamente diferente al placebo.


Podemos evaluar sobredispersión de nuevo:
```{r liratmod1chi,include=TRUE}
X2 = sum(residuals(modlirat.betabinom,type='pearson')^2)
X2/52
```
La razón está cercana a $1$ por lo que la varianza está mejor modelada por la distribución beta-binomial. La comparación de los ajustes se puede hacer a través de criterios de información:
```{r liratcomp,include=TRUE}
AIC(modlirat.binom)
AIC(modlirat.betabinom)
```
Observando los valores del AIC podemos determinar que el modelo beta-binomial presenta mejor ajuste.