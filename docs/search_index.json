[["modelos-no-lineales.html", "Capítulo 5 Modelos no lineales 5.1 Ejemplos 5.2 Modelos no lineales", " Capítulo 5 Modelos no lineales 5.1 Ejemplos 5.1.1 Crecimiento de pavos Datos: turk0 de la librería alr4 Objetivo: evaluar la metionina como suplemento alimenticio para pavos. Se alimentó a 60 corrales de pavos con una dieta similar, complementada con una dosis de metionina diferente. Luego de un tiempo, se observó el peso ganado por corral. Las variables son: A: Cantidad de suplemento de metionina ( % de la dieta). Gain: Peso medio ganado por corral (gramos) después de 3 semanas. plot(Gain~A,data=turk0,xlab=&#39;cantidad de metionina (% dieta)&#39;,ylab=&#39;Peso ganado (gramos)&#39;) Figure 5.1: Datos pavos. Diagrama de dispersión. Para estos datos se puede proponer el siguiente modelo: \\[ E(Gain|A)=\\theta_{1}+\\theta_{2}[1-exp(-\\theta_{3}A)] \\] Si \\(A=0\\), entonces \\(E(Gain|A)=\\theta_{1}\\) (peso ganado sin suplemento). Si \\(\\theta_{3}&gt;0\\), \\(\\theta_{1}+\\theta_{2}\\) es la asíntota (máximo peso que se puede ganar). \\(\\theta_{2}\\) es el máximo crecimiento adicional debido al suplemento. \\(\\theta_{3}\\) representa la tasa de crecimiento. A valores de \\(\\theta_3\\) mas grandes, el crecimiento esperado se acerca a su máximo más rápidamente. 5.1.2 Puromicina Datos: Puromycin. Objetivo: evaluar la velocidad de una reacción enzimática de células tratadas con Puromicina. Se midió la reacción enzimática (qué tan rápido ésta cataliza la reacción que convierte un sustrato en producto) de 23 encimas (12 tratadas con Puromicina). Las variables son: conc :concentración de sustrato (ppm). rate:velocidad de reacción instantáneas (conteo/min2) state:tratado y no tratado. plot(Puromycin$conc,Puromycin$rate,col=Puromycin$state, xlab=&#39;concentración de sustrato (ppm)&#39;, ylab=&#39;velocidad de reacción&#39;) Figure 5.2: Daros Puromicina. Diagrama de dispersión:Encimas tratadas(puntos negros), Encimas no tratadas(puntos rojos) Modelo Michaelis-Menten(bioquímica): \\[ y_{i}=\\frac{x_{1}\\theta_{1}}{\\theta_{2}+x_{1}}+\\epsilon_{i}. \\] Figure 5.3: Modelo Michaelis-Menten Por lo que para estos datos se puede proponer el modelo: \\[ rate_{i}=\\frac{conc_{i}\\theta_{1}+state_{i}conc_{i}\\theta_{3}} {\\theta_{2}+state_{i}\\theta_{3}+conc_{i}}+\\epsilon_{i}. \\] Por lo que se tiene una curva diferente para las enzimas tratadas y no tratadas: Para enzimas no tratadas: \\[ E(rate_{i}|state=0)=\\frac{conc_{i}\\theta_{1}}{\\theta_{2}+conc_{i}}. \\] Para enzimas tratadas: \\[ E(rate_{i}|state=1)=\\frac{conc_{i}(\\theta_{1}+\\theta_{3})}{(\\theta_{2}+\\theta_{4})+conc_{i}}. \\] 5.2 Modelos no lineales En modelos de regresión asumimos que: \\[ y_{i}=m(x_{i},\\theta)+\\epsilon_{i}. \\] En el caso de modelos lineales: \\[ m(x_{i},\\theta)=\\Psi_{j}(x_{i},\\psi)^{&#39;}\\beta. \\] donde \\(\\Psi(\\cdot)\\) es una función de unos parámetros constantes \\(\\psi\\) (es decir, puedo asumir transformaciones sobre las covariables). \\(\\Psi_{j}(x_{i},\\psi)=x_{i}\\), tenemos: \\[ m(x_{i},\\theta)=\\beta_{0}+x_{1i}\\beta_{1}+x_{2i}\\beta_{2}+...+x_{p-1,i}\\beta_{p-1}. \\] Los modelos: \\[ y_{i}=m(x_{i},\\theta)+\\epsilon_{i}=\\theta_{1}+\\theta_{1}[1+exp(-\\theta_{3}x_{i})]+\\epsilon_{i}, \\] y \\[ y_{i}=m(x_{i},\\theta)+\\epsilon_{i}=\\frac{x_{i}\\theta_{i}}{\\theta_{2}+x_{i}}+\\epsilon_{i}, \\] son un modelo no-lineal (no es una combinación lineal de los parámetros). Si se hacen los mismos supuestos sobre los errores, esto es: \\[ \\epsilon\\sim N(\\boldsymbol 0,\\sigma^2 \\boldsymbol I) \\] se tiene que: \\(E(y|x_{i})=m(\\boldsymbol x_{i},\\boldsymbol \\theta)\\). \\(E(y|x_{i})=\\sigma^2\\). 5.2.1 Modelos no-lineales linealizables Modelo de regresión exponencial: \\[ E(y)=\\theta_{0}+\\theta_{1}exp(\\theta_{2}+x_{i}\\theta_{3}) \\] Si \\(\\theta_{0}=0\\), el modelo es linealizable: \\[ logy_{i}=(log\\theta_{1}+\\theta_{2})+x_{i}\\theta_{3}+\\epsilon_{i}^* \\] Sin embargo, hay que tener cuidado con el efecto de las transformaciones sobre los residuos. 5.2.2 Estimación de los parámetros La estimación de \\(\\boldsymbol \\theta\\) se hace minimizando la suma de cuadrados de los residuos: \\[ S(\\boldsymbol \\theta)=\\sum_{i=1}^n[y_{i}-m(\\boldsymbol x_{i},\\boldsymbol \\theta)]^2 \\] Para encontrar el mínimo, \\((1)\\) calculamos la derivada de \\(S(\\boldsymbol \\theta)\\) con respecto a \\(\\boldsymbol \\theta\\): \\[ \\frac{\\partial}{\\partial\\boldsymbol \\theta}S(\\boldsymbol \\theta)=-2\\sum_{i=1}^n[y_{i}-m(\\boldsymbol x_{i},\\boldsymbol \\theta)] \\begin{bmatrix}\\frac{\\partial }{\\partial\\boldsymbol \\theta}m(\\boldsymbol x_{i},\\boldsymbol \\theta)\\end{bmatrix} \\] \\((2)\\) igualamos a \\(0\\), y \\((3)\\) resolvemos la ecuación para \\(\\boldsymbol \\theta\\). En la mayoría de los casos, \\(\\frac{\\partial}{\\partial\\boldsymbol \\theta}S(\\boldsymbol \\theta)\\) es una función no-lineal \\(\\boldsymbol \\theta\\). Por lo tanto, no es posible encontrar una solución analítica y necesitamos encontrar la solución iterativamente. 5.2.2.1 Notación \\(\\theta_{j}^{(t)}\\): estimación de \\(\\theta_{j}\\) en la iteración \\(t\\) (\\(\\theta_{j}^{(0)}\\) valores iniciales). Vector score (gradiente): \\[ u(\\boldsymbol \\theta)=\\frac{\\partial S(\\boldsymbol \\theta)}{\\partial\\boldsymbol \\theta}=\\begin{pmatrix} \\frac{\\partial S(\\boldsymbol \\theta)}{\\partial\\boldsymbol \\theta} \\\\ \\frac{\\partial S(\\boldsymbol \\theta)}{\\partial\\boldsymbol \\theta} \\\\ \\vdots \\\\ \\frac{\\partial S(\\boldsymbol \\theta)}{\\partial\\boldsymbol \\theta} \\\\ \\end{pmatrix} \\quad u(\\hat{\\boldsymbol \\theta})=u(\\boldsymbol \\theta)|_{\\boldsymbol \\theta=\\hat{\\boldsymbol \\theta}} \\] Matriz Hessiana (Jacobiano): \\[ \\boldsymbol H(\\boldsymbol \\theta)= \\frac{\\partial^2 S(\\boldsymbol \\theta)}{\\partial\\boldsymbol \\theta^{&#39;} \\partial\\boldsymbol \\theta}=\\begin{pmatrix} \\frac{\\partial^2 S(\\boldsymbol \\theta)}{\\partial^2 \\boldsymbol \\theta_{1}} &amp; \\frac{\\partial^2 S(\\boldsymbol \\theta)}{\\partial \\boldsymbol \\theta_{1} \\partial \\boldsymbol \\theta_{2} } &amp; \\dots &amp; \\frac{\\partial^2 S(\\boldsymbol \\theta)}{\\partial \\boldsymbol \\theta_{1} \\partial \\boldsymbol \\theta_{p}} \\\\ \\frac{\\partial^2 S(\\boldsymbol \\theta)}{\\partial \\boldsymbol \\theta_{2} \\partial \\boldsymbol \\theta_{1}} &amp; \\frac{\\partial^2 S(\\boldsymbol \\theta)}{\\partial^2 \\boldsymbol \\theta_{2}} &amp; \\dots &amp; \\frac{\\partial^2 S(\\boldsymbol \\theta)}{\\partial \\boldsymbol \\theta_{2} \\partial \\boldsymbol \\theta_{p}}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial^2 S(\\boldsymbol \\theta)}{\\partial \\boldsymbol \\theta_{p} \\partial \\boldsymbol \\theta_{1}} &amp; \\frac{\\partial^2 S(\\boldsymbol \\theta)}{\\partial \\boldsymbol \\theta_{p} \\partial \\boldsymbol \\theta_{2}} &amp; \\dots &amp; \\frac{\\partial^2 S(\\boldsymbol \\theta)}{\\partial^2 \\boldsymbol \\theta_{p}} \\end{pmatrix} \\quad \\quad \\quad \\boldsymbol H(\\hat{\\boldsymbol \\theta})=\\boldsymbol H(\\boldsymbol \\theta)|_{\\boldsymbol \\theta=\\hat{\\boldsymbol \\theta}} \\] 5.2.2.2 Expansión de series de Tylor Una función \\(f(\\theta)\\) puede expandirse como una serie de Taylor: \\[ f(\\theta)=\\sum_{n=0}^\\infty \\frac{1}{n!}(\\theta-\\theta^*)^n \\frac{\\partial^nf(\\theta^*)}{\\partial\\theta^n} \\] Una aproximación de la función \\(f(\\theta)\\) en los valores alrededor del punto \\(\\theta^*\\) se puede hacer usando la series de Taylor con solo las dos primeras derivadas (orden 2): \\[ f(\\theta)\\approx f(\\theta^*)+(\\theta-\\theta^*) \\frac{\\partial f(\\theta^*)}{\\partial\\theta}+\\frac{1}{2}(\\theta-\\theta^*)^2\\frac{\\partial^2 f(\\theta^*)}{\\partial\\theta^2} \\] En caso de \\(\\boldsymbol \\theta\\) (vector), entonces: \\[ f(\\boldsymbol \\theta)\\approx f(\\boldsymbol \\theta^*)+(\\boldsymbol \\theta-\\boldsymbol \\theta^*)^{&#39;}u(\\boldsymbol \\theta^*)+\\frac{1}{2}(\\boldsymbol \\theta-\\boldsymbol \\theta^*)^{&#39;}H(\\boldsymbol \\theta^*)(\\boldsymbol \\theta-\\boldsymbol \\theta^*), \\] 5.2.3 Métodos iterativos de estimación Algunos métodos iterativos de estimación son: Gauss-Newton (approx. series de Taylor a la función de la media). Newton-Raphson (approx. series de Taylor a la función score). 5.2.3.1 Algoritmo de Gauss-Newton La idea es aproximar \\(m(x_{i},\\boldsymbol \\theta^*)\\) usando series de Taylor de orden 1 alrededor de \\(\\boldsymbol \\theta^*\\): \\[ m(x_{i},\\boldsymbol \\theta)\\approx m(x_{i},\\boldsymbol \\theta^*)+(\\boldsymbol \\theta-\\boldsymbol \\theta^*)^{&#39;}u_{i}(\\boldsymbol \\theta^*) \\] Lo que lleva a una aproximación de la suma de cuadrados de los residuos: \\[\\begin{equation} \\begin{split} S(\\boldsymbol \\theta)&amp;=\\sum_{i=1}^n[y_{i}-m(x_{i},\\boldsymbol \\theta)]^2 \\approx \\sum_{i=1}^n[y_{i}-m(x_{i},\\boldsymbol \\theta^*)+(\\boldsymbol \\theta-\\boldsymbol \\theta^*)^{&#39;}u_{i}(\\boldsymbol \\theta^*)]^2 \\\\ &amp;= \\sum_{i=1}^n[\\hat e_{i}^*+(\\boldsymbol \\theta-\\boldsymbol \\theta^*)^{&#39;}u_{i}(\\boldsymbol \\theta^*)]^2, \\end{split} \\end{equation}\\] Esta aproximación de \\(S(\\boldsymbol \\theta)\\) es equivalente a una suma de cuadrados de un modelo lineal con \\(\\hat e_{i}^*\\) (residuos de trabajo) como variable respuesta y \\(u_{i}(\\boldsymbol \\theta^*)\\) como covariables. Por lo tanto, la solución es: \\[ (\\hat{\\boldsymbol \\theta}-\\boldsymbol \\theta^*)=[U(\\boldsymbol \\theta^*)^{&#39;}U(\\boldsymbol \\theta^*)]^{-1} U(\\boldsymbol \\theta^*)^{&#39;} \\hat{e^*} \\] \\[\\begin{equation} \\hat{\\boldsymbol \\theta}=\\boldsymbol \\theta^*+[U(\\boldsymbol \\theta^*)^{&#39;}U(\\boldsymbol \\theta^*)]^{-1}U(\\boldsymbol \\theta^*)^{&#39;} \\hat{e^*} \\tag{5.1} \\end{equation}\\] donde: \\(\\hat{e_{i}^*}=(\\hat{e_{1}^*},...,\\hat{e_{n}^*})^{&#39;}\\) \\(U(\\boldsymbol \\theta^*)\\) es una matriz con la fila \\(i\\) igual a \\(u_{i}(\\boldsymbol \\theta^*)\\). A partir de estas ecuaciones se propone el algoritmo de Gauss-Newton. Seleccione unos valores iniciales \\(\\boldsymbol \\theta_{0}\\) y calcule \\(S(\\boldsymbol \\theta_{0})\\). Establezca el contador de iteraciones en \\(k=0\\) Calcule \\(U(\\boldsymbol \\theta^{(j)})\\) y \\(\\hat{e}^{(j)}\\) y encuentre \\(\\boldsymbol \\theta^{(j+1)}\\) usando (5.1): \\[\\begin{equation} \\begin{split} &amp; \\boldsymbol \\theta^{(j+1)}=\\boldsymbol \\theta^{(j)}+[U(\\boldsymbol \\theta^{(j)})^{&#39;}U(\\boldsymbol \\theta^{(j)})]^{-1}U(\\boldsymbol \\theta^{(j)})^{&#39;} \\hat{e}^{(j)}. \\end{split} \\end{equation}\\] y calcule \\(S(\\boldsymbol \\theta^{(j+1)})\\). Pare si \\(\\delta=|S(\\boldsymbol \\theta^{(j)})-S(\\boldsymbol \\theta^{(j+1)})|\\) es suficientemente pequeño (convergente). De otra forma, \\(j=j+1\\) y vaya al paso 3. Si \\(j\\) es muy grande (muchas iteraciones), se dice que hay divergencia. El algoritmo de Gauss-Newton estima los parámetros de un problema de regresión no lineal mediante una secuencia de cálculos de mínimos cuadrados lineales aproximados. La estimación de \\(\\sigma^2\\) es: \\[ \\hat{\\sigma}^2=\\frac{1}{n-p}\\sum_{i=1}^n[y_{i}-m(x_{i},\\hat{\\boldsymbol \\theta)}]^2, \\] donde \\(p\\) es la dimensión de \\(\\boldsymbol \\theta\\). 5.2.4 Estimación de los parámetros ¿Cómo selecciono los valores iniciales? El ajuste de un modelo no-lineal requiere buenos valores iniciales (cercanos a los valores de parámetros). los valores iniciales se pueden obtener a través: Conocimiento previo. Significado físico de los coeficientes. Evaluación gráfica. Linearización de los datos. Dado que la solución del algoritmo puede caer en un máximo local, es recomendable ejecutar el algoritmo para diferentes valores iniciales. 5.2.4.1 Crecimiento de pavos - Valores iniciales En el caso del peso de los pavos: \\(\\theta_{1}^0=620\\) (pesi ganado sin suplemento) \\(\\theta_{2}^0+\\theta_{1}^0=800\\) (Asíntota). Por lo tanto \\(\\theta_{2}^0=180\\) \\(\\theta_{3}^0\\) se puede obtener a partir de resolver la ecuación para un punto posible: \\[ 750=620+180[1-exp(-\\theta_{3}^00.16)] \\] Resolviendo la ecuación \\(\\theta_{3}^0\\approx8\\). mod = nls(Gain ~ th1 + th2*(1-exp(-th3*A)),data = turk0, start = list(th1=620,th2=180,th3=8),trace=F) plot(Gain~A,data=turk0,xlab=&#39;cantidad de metionina (% dieta)&#39;,ylab=&#39;Peso ganado (gramos)&#39;) th = coef(mod) x = seq(0,0.5,length.out=100) lines(x, th[1]+th[2]*(1-exp(-th[3]*x)),col=2, lwd = 2) Figure 5.4: Datos crecimiento de pavos. Ajuste del modelo para el peso medio ganado por corral en función de la cantidad de suplemento de metionina. \\[ E(Gain|A)=622.958 + 178.252 [1 - exp(-7.122A)] \\] 5.2.5 Inferencia sobre los parámetros si \\(\\epsilon \\sim N(\\boldsymbol 0,\\sigma^2 \\boldsymbol I)\\), tenemos que asintóticamente \\((n \\to \\infty)\\): \\[ \\hat{\\boldsymbol \\theta}\\sim N(\\boldsymbol \\theta^*,\\sigma^2[U(\\boldsymbol \\theta^*)U(\\boldsymbol \\theta^*)^{&#39;}]^{-1}). \\] Dado que automáticamente \\(\\boldsymbol \\theta^* \\to \\boldsymbol \\theta\\), \\(\\hat{\\boldsymbol \\theta}\\) es un estimador insesgado de \\(\\boldsymbol \\theta\\). Hay que hacer énfasis que estas son propiedades para muestras grandes, para muestras pequeñas, estas propiedades pueden ser inadecuadas. A partir de las propiedades de muestras grandes se pueden hacer inferencias sobre los coeficientes \\(\\boldsymbol \\theta\\). Por ejemplo: Pruebas de hipótesis: \\(\\qquad H_{0}:\\theta_{j}=\\theta_{0}, \\qquad H_{1}:\\theta_{j}\\ne\\theta_{0}\\) \\[ t_{0}:\\frac{\\hat{\\theta_{j}}-\\theta_{0}}{\\sqrt{V(\\hat{\\theta_{j}})}}, \\quad \\text{donde} \\quad t_{0} \\sim t_{n-p} \\] Intervalos de confianza:IC del \\((1-\\alpha)\\)% para \\(\\theta_{j}\\): \\[ \\hat{\\theta_{j}}\\pm t_{1-\\alpha/2,n-p}\\sqrt{V(\\hat{\\theta_{j}})} \\] Intervalos de confianza: IC del \\((1-\\alpha)\\)% para \\(E(Y|x_{0})\\): Sea \\(\\boldsymbol \\theta=(\\boldsymbol \\theta_{1}^{&#39;},\\boldsymbol \\theta_{2}^{&#39;})^{&#39;}.\\) Hipótesis: \\[ H_{0}:\\boldsymbol \\theta_{2}=\\boldsymbol 0\\qquad H_{1}:\\boldsymbol \\theta_{2}\\ne\\boldsymbol 0 \\] Estadístico de prueba: \\[ F_{0}=\\frac{[SS_{res}(\\boldsymbol \\theta)-SS_{res}(\\boldsymbol \\theta_{1})]/r}{MS_{res}(\\boldsymbol \\theta)}\\sim F_{r,n-p}. \\] 5.2.5.1 Crecimiento de pavos-Estimación Modelo estimado: summary(mod) ## ## Formula: Gain ~ th1 + th2 * (1 - exp(-th3 * A)) ## ## Parameters: ## Estimate Std. Error t value Pr(&gt;|t|) ## th1 622.958 5.901 105.57 &lt; 2e-16 *** ## th2 178.252 11.636 15.32 2.74e-16 *** ## th3 7.122 1.205 5.91 1.41e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 19.66 on 32 degrees of freedom ## ## Number of iterations to convergence: 4 ## Achieved convergence tolerance: 6.736e-06 Es posible considerar otros modelos de crecimiento. Por ejemplo: Modelo 2 (modelo logístico): \\[ y_{i}=\\frac{\\theta_{1}}{1+\\theta_{2}exp(-\\theta_{3}x_{i})}+\\epsilon_{i} \\] Modelo 3 modelo Weibull: \\[ y_{i}=\\theta_{1}+\\theta_{2}[1-exp(-\\theta_{3}x_{i}^{\\theta_{4}})]+\\epsilon_{i} \\] La comparación se puede hacer por criterios de información (AIC o BIC) plot(Gain~A,data=turk0,xlab=&#39;cantidad de metionina (% dieta)&#39;,ylab=&#39;Peso ganado (gramos)&#39;) mod2 = nls(Gain ~ th1/(1+th2*exp(-th3*A)),data = turk0, start = list(th1=620,th2=0.25,th3=8) ) mod3 = nls(Gain ~ th1 + th2*(1-exp(-th3*A^th4)),data = turk0, start = list(th1=800,th2=180,th3=8,th4=1) ) th2 = coef(mod2) th3 = coef(mod3) lines(x, th[1]+th[2]*(1-exp(-th[3]*x)),col=2, lwd = 2) lines(x, th2[1]/(1+th2[2]*exp(-th2[3]*x)),col=3, lwd = 2) lines(x, th3[1]+th3[2]*(1-exp(-th3[3]*x^th3[4])),col=4, lwd = 2) Figure 5.5: Datos Pavos.Modelo 1(Rojo), Modelo logístico(verde) y Modelo Weibull(Azul) AIC(mod) ## [1] 312.6872 AIC(mod2) ## [1] 312.3979 AIC(mod3) ## [1] 314.5287 5.2.5.2 Puromicina-Estimación Los valores iniciales del modelo Michaelis-Menten se puede hacer por linealización. par(mfrow=c(1,2)) plot(Puromycin$conc,Puromycin$rate,col=Puromycin$state, xlab=&#39;concentración de sustrato (ppm)&#39;, ylab=&#39;velocidad de reacción&#39;) plot(1/Puromycin$conc,1/Puromycin$rate,col=Puromycin$state, xlab=&#39;concentración de sustrato (ppm)&#39;, ylab=&#39;velocidad de reacción&#39;) Figure 5.6: Datos puromicina. Diagrama de dispersión. Datos linealizados(derecha). A través del ajuste por MCO: \\[ 1/y_{i}=\\beta_{0}+1/conc_{i}\\beta_{1}+\\epsilon_{i} \\] Se puede obtener valores iniciales. Luego de ajustar el modelo: \\[ \\theta_{1}^{(0)}=\\frac{1}{\\hat{\\beta}_{0}}=167.408 \\qquad \\theta_{2}^{(0)}=\\frac{\\hat{\\beta}_{1}}{\\hat{\\beta}_{0}}=0.039 \\] Inicialmente, se podría asumir \\(\\beta_{3}=\\beta_{4}=0.\\) Modelo estimado: Puromycin$state2 = as.double(Puromycin$state == &#39;treated&#39;) mod.puromicyn = nls(rate ~ (th1*conc + th3*conc*state2)/(th2+th4*state2+conc),data = Puromycin, start = list(th1=168,th2=0.4,th3=0,th4=0),trace=F ) summary(mod.puromicyn ) ## ## Formula: rate ~ (th1 * conc + th3 * conc * state2)/(th2 + th4 * state2 + ## conc) ## ## Parameters: ## Estimate Std. Error t value Pr(&gt;|t|) ## th1 1.603e+02 6.896e+00 23.242 2.04e-15 *** ## th2 4.771e-02 8.281e-03 5.761 1.50e-05 *** ## th3 5.240e+01 9.551e+00 5.487 2.71e-05 *** ## th4 1.641e-02 1.143e-02 1.436 0.167 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 10.4 on 19 degrees of freedom ## ## Number of iterations to convergence: 7 ## Achieved convergence tolerance: 3.018e-06 La tasa de crecimiento máxima es diferente si la enzima es tratada o no. El punto donde se logra la mitad del máximo es el mismo. x = seq(0,1.5,length.out=200) thP= coef(mod.puromicyn) plot(Puromycin$conc,Puromycin$rate,col=Puromycin$state, xlab=&#39;concentración de sustrato (ppm)&#39;, ylab=&#39;velocidad de reacción&#39;) lines(x, thP[1]*x/(thP[2]+x),col=2) lines(x, (thP[1]+thP[3])*x/(thP[2]+thP[4]+x)) 5.2.6 Método de Bootstrap Las inferencias basadas para muestras grande pueden ser inexactas y/o engañosas en muestras pequeñas. En esos casos, se puede hacer inferencias usando remuestreo (bootstrap). El bootstrap es una técnica para calcular intervalos de confianza and pruebas de hipótesis cuando el cumplimiento de los supuestos asumidos están en duda. Se quiere calcular un intervalo de confianza para la mediana (o cualquier otro parámetro) de \\(Y\\). Para esto tomamos una muestra independiente \\(\\boldsymbol y=(y_{1},...,y_{n})\\). Pasos del boostrap: Obtener una muestra aleatoria con remuestreo de \\(\\boldsymbol y:\\boldsymbol y=(y_{1}^{*},...,y_{n}^{*})\\). Calcular la mediana usando la muestra el paso 1 \\((Me_{1})\\). Repita los pasos 1 y 2 un número grande de veces \\((B)\\). un intervalo de confianza del 95% basado en percentiles muestrales 2.5% y 97.5 %. 5.2.6.1 Bootstrap en regresión Método residual resampling: Con la muestra dada: \\((x_{i},y_{i}),i=1,...,n\\) ajustar el modelo y obtener los resifuos: \\(e_{i}=y_{i}-x_{i}^{&#39;}\\hat{\\beta}.\\) Obtener una muestra aleatoria con reemplazo de los residuos \\(e^*=(e_{1}^*,...,e_{n}^*)\\). 3.Crear una variable respuesta bootstrap con \\(y_{i}^*=x_{i}^{&#39;}\\hat{\\beta}+e_{1}^*\\) y estimar \\(\\hat{\\beta}^*\\). Repetir los pasos 1-3 un número grande de veces \\((B)\\) y obtener el intervalo de confianza para \\(\\beta_{j}\\) usando los percentiles*. \\(*\\)Hay muchas modificaciones y extensiones para calcular los intervalos de confianza. set.seed(310) mod.boot = Boot(mod.puromicyn,method=&#39;residual&#39;,R=1000) ## ## Number of bootstraps was 999 out of 1000 attempted pairs(mod.boot$t,labels=c(expression(hat(theta)[1]),expression(hat(theta)[2]),expression(hat(theta)[3]), expression(hat(theta)[4]))) Estimaciones por bootstrap Linea roja: estimación por mínimos cuadrados. Lineas rojas: percentil 2.5, media y percentil 97.5. par(mfrow=c(1,4)) hist(mod.boot$t[,1],breaks = 20,xlab=expression(hat(theta)[1]),main = &#39;&#39;) abline(v=coef(mod.puromicyn)[1],lty=2,lwd=2) abline(v=mean(mod.boot$t[,1]),lty=2,lwd=2,col=2) abline(v=quantile(mod.boot$t[,1],c(0.025,0.975),na.rm = T),lty=2,lwd=2,col=2) hist(mod.boot$t[,2],breaks = 20,xlab=expression(hat(theta)[2]),main = &#39;&#39;) abline(v=coef(mod.puromicyn)[2],lty=2,lwd=2) abline(v=mean(mod.boot$t[,2]),lty=2,lwd=2,col=2) abline(v=quantile(mod.boot$t[,2],c(0.025,0.975),na.rm = T),lty=2,lwd=2,col=2) hist(mod.boot$t[,3],breaks = 20,xlab=expression(theta[3]),main = &#39;&#39;) abline(v=coef(mod.puromicyn)[3],lty=2,lwd=2) abline(v=mean(mod.boot$t[,3]),lty=2,lwd=2,col=2) abline(v=quantile(mod.boot$t[,3],c(0.025,0.975),na.rm = T),lty=2,lwd=2,col=2) hist(mod.boot$t[,4],breaks = 20,xlab=expression(theta[4]),main = &#39;&#39;) abline(v=coef(mod.puromicyn)[4],lty=2,lwd=2) abline(v=mean(mod.boot$t[,4]),lty=2,lwd=2,col=2) abline(v=quantile(mod.boot$t[,4],c(0.025,0.975),na.rm = T),lty=2,lwd=2,col=2) Intervalos del 95% de confianza usando bootstrap (corrección de sesgo): quantile(mod.boot$t[,1],c(0.025,0.975),na.rm = T) ## 2.5% 97.5% ## 150.2763 175.1425 quantile(mod.boot$t[,2],c(0.025,0.975),na.rm = T) ## 2.5% 97.5% ## 0.03538444 0.06329289 quantile(mod.boot$t[,3],c(0.025,0.975),na.rm = T) ## 2.5% 97.5% ## 34.8151 70.2094 quantile(mod.boot$t[,4],c(0.025,0.975),na.rm = T) ## 2.5% 97.5% ## -0.00663091 0.03540431 Puromicina - bootstrap \\ Todas las curvas estimadas por bootstrap. Linea roja: estimación puntual. fit.rate= function(theta,x){ cbind(theta[1]*x/(theta[2]+x), (theta[1]+theta[3])*x/(theta[2]+theta[4]+x)) } x= seq(from=0,to=1.1,length.out = 100) plot(NULL,NULL,xlim=c(0,1.1),ylim=c(0,210),xlab=&#39;concentración de sustrato (ppm)&#39;, ylab=&#39;velocidad de reacción&#39;) Fit = mapply(function(i){ pred = fit.rate(mod.boot$t[i,],x) lines(x,pred[,1],col=&#39;lightgray&#39;) lines(x,pred[,2],col=&#39;gray&#39;) },i=1:999) lines(x, thP[1]*x/(thP[2]+x),col=2) lines(x, (thP[1]+thP[3])*x/(thP[2]+thP[4]+x)) points(Puromycin$conc,Puromycin$rate,col=Puromycin$state) 5.2.6.2 Algunas consideraciones Lo ideal es que el algoritmo llegue a la solución en pocas iteraciones (esto pasa si la aproximación lineal es adecuada). *Siempre es bueno evaluar la solución con diferentes puntos iniciales. Es posible que caigamos en un máximo local. *Si el tamaño de muestra no es grande, las propiedades asintóticas pueden no ser adecuadas. Por lo tanto, es mas conveniente usar bootstrap para hacer inferencias. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
