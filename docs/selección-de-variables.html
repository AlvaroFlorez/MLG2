<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 4 Selección de variables | Notas de clase: Modelo lineal general II</title>
  <meta name="description" content="Capítulo 4 Selección de variables | Notas de clase: Modelo lineal general II" />
  <meta name="generator" content="bookdown 0.33 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 4 Selección de variables | Notas de clase: Modelo lineal general II" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 4 Selección de variables | Notas de clase: Modelo lineal general II" />
  
  
  

<meta name="author" content="Alvaro J. Flórez" />


<meta name="date" content="2023-05-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="multicolinealidad.html"/>
<link rel="next" href="modelos-no-lineales.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Notas de clase MLGII</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introducción</a></li>
<li class="chapter" data-level="1" data-path="variables-indicadoras-o-dummies.html"><a href="variables-indicadoras-o-dummies.html"><i class="fa fa-check"></i><b>1</b> Variables indicadoras (o dummies)</a>
<ul>
<li class="chapter" data-level="1.1" data-path="variables-indicadoras-o-dummies.html"><a href="variables-indicadoras-o-dummies.html#ejemplos"><i class="fa fa-check"></i><b>1.1</b> Ejemplos</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="variables-indicadoras-o-dummies.html"><a href="variables-indicadoras-o-dummies.html#datos-de-atletas-australianos"><i class="fa fa-check"></i><b>1.1.1</b> Datos de atletas australianos</a></li>
<li class="chapter" data-level="1.1.2" data-path="variables-indicadoras-o-dummies.html"><a href="variables-indicadoras-o-dummies.html#datos-de-la-onu"><i class="fa fa-check"></i><b>1.1.2</b> Datos de la ONU</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="variables-indicadoras-o-dummies.html"><a href="variables-indicadoras-o-dummies.html#variables-indicadoras"><i class="fa fa-check"></i><b>1.2</b> Variables indicadoras</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="variables-indicadoras-o-dummies.html"><a href="variables-indicadoras-o-dummies.html#modelos-con-covariables-categóricas"><i class="fa fa-check"></i><b>1.2.1</b> Modelos con covariables categóricas</a></li>
<li class="chapter" data-level="1.2.2" data-path="variables-indicadoras-o-dummies.html"><a href="variables-indicadoras-o-dummies.html#modelo-para-los-datos-de-atletas-australianos"><i class="fa fa-check"></i><b>1.2.2</b> Modelo para los datos de atletas australianos</a></li>
<li class="chapter" data-level="1.2.3" data-path="variables-indicadoras-o-dummies.html"><a href="variables-indicadoras-o-dummies.html#modelo-para-los-datos-de-la-onu"><i class="fa fa-check"></i><b>1.2.3</b> Modelo para los datos de la ONU</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="modelos-polinomiales.html"><a href="modelos-polinomiales.html"><i class="fa fa-check"></i><b>2</b> Modelos polinomiales</a>
<ul>
<li class="chapter" data-level="2.1" data-path="modelos-polinomiales.html"><a href="modelos-polinomiales.html#ejemplos-1"><i class="fa fa-check"></i><b>2.1</b> Ejemplos</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="modelos-polinomiales.html"><a href="modelos-polinomiales.html#pasteles"><i class="fa fa-check"></i><b>2.1.1</b> Pasteles</a></li>
<li class="chapter" data-level="2.1.2" data-path="modelos-polinomiales.html"><a href="modelos-polinomiales.html#datos-de-boston"><i class="fa fa-check"></i><b>2.1.2</b> Datos de Boston</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="modelos-polinomiales.html"><a href="modelos-polinomiales.html#modelos-polinomiales-1"><i class="fa fa-check"></i><b>2.2</b> Modelos polinomiales</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="modelos-polinomiales.html"><a href="modelos-polinomiales.html#interpretación-de-los-coeficientes"><i class="fa fa-check"></i><b>2.2.1</b> Interpretación de los coeficientes</a></li>
<li class="chapter" data-level="2.2.2" data-path="modelos-polinomiales.html"><a href="modelos-polinomiales.html#pasteles-1"><i class="fa fa-check"></i><b>2.2.2</b> Pasteles</a></li>
<li class="chapter" data-level="2.2.3" data-path="modelos-polinomiales.html"><a href="modelos-polinomiales.html#datos-de-boston-1"><i class="fa fa-check"></i><b>2.2.3</b> Datos de Boston</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="modelos-polinomiales.html"><a href="modelos-polinomiales.html#regresión-por-segmentos"><i class="fa fa-check"></i><b>2.3</b> Regresión por segmentos</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="modelos-polinomiales.html"><a href="modelos-polinomiales.html#ejemplo"><i class="fa fa-check"></i><b>2.3.1</b> Ejemplo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="multicolinealidad.html"><a href="multicolinealidad.html"><i class="fa fa-check"></i><b>3</b> Multicolinealidad</a>
<ul>
<li class="chapter" data-level="3.1" data-path="multicolinealidad.html"><a href="multicolinealidad.html#ejemplos-2"><i class="fa fa-check"></i><b>3.1</b> Ejemplos</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="multicolinealidad.html"><a href="multicolinealidad.html#cemento"><i class="fa fa-check"></i><b>3.1.1</b> Cemento</a></li>
<li class="chapter" data-level="3.1.2" data-path="multicolinealidad.html"><a href="multicolinealidad.html#grasa-corporal"><i class="fa fa-check"></i><b>3.1.2</b> Grasa corporal</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="multicolinealidad.html"><a href="multicolinealidad.html#multicolinealidad-1"><i class="fa fa-check"></i><b>3.2</b> Multicolinealidad</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="multicolinealidad.html"><a href="multicolinealidad.html#causas-de-la-multicolinealidad"><i class="fa fa-check"></i><b>3.2.1</b> Causas de la multicolinealidad</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="multicolinealidad.html"><a href="multicolinealidad.html#detección-de-multicolinealidad"><i class="fa fa-check"></i><b>3.3</b> Detección de multicolinealidad</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="multicolinealidad.html"><a href="multicolinealidad.html#factores-de-inflación-de-varianza"><i class="fa fa-check"></i><b>3.3.1</b> Factores de inflación de varianza</a></li>
<li class="chapter" data-level="3.3.2" data-path="multicolinealidad.html"><a href="multicolinealidad.html#valores-propios-de-boldsymbol-zboldsymbol-z"><i class="fa fa-check"></i><b>3.3.2</b> Valores propios de <span class="math inline">\(\boldsymbol Z&#39;\boldsymbol Z\)</span></a></li>
<li class="chapter" data-level="3.3.3" data-path="multicolinealidad.html"><a href="multicolinealidad.html#valores-singulares-de-boldsymbol-z"><i class="fa fa-check"></i><b>3.3.3</b> Valores singulares de <span class="math inline">\(\boldsymbol Z\)</span></a></li>
<li class="chapter" data-level="3.3.4" data-path="multicolinealidad.html"><a href="multicolinealidad.html#proporciones-de-descomposición-de-varianza"><i class="fa fa-check"></i><b>3.3.4</b> Proporciones de descomposición de varianza</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="multicolinealidad.html"><a href="multicolinealidad.html#datos-de-cemento"><i class="fa fa-check"></i><b>3.4</b> Datos de cemento</a></li>
<li class="chapter" data-level="3.5" data-path="multicolinealidad.html"><a href="multicolinealidad.html#datos-de-grasa-corporal"><i class="fa fa-check"></i><b>3.5</b> Datos de grasa corporal</a></li>
<li class="chapter" data-level="3.6" data-path="multicolinealidad.html"><a href="multicolinealidad.html#solución-al-problema-de-multicolinealidad"><i class="fa fa-check"></i><b>3.6</b> Solución al problema de multicolinealidad</a></li>
<li class="chapter" data-level="3.7" data-path="multicolinealidad.html"><a href="multicolinealidad.html#estimador-de-ridge"><i class="fa fa-check"></i><b>3.7</b> Estimador de ridge</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="multicolinealidad.html"><a href="multicolinealidad.html#datos-de-cemento-1"><i class="fa fa-check"></i><b>3.7.1</b> Datos de cemento</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="multicolinealidad.html"><a href="multicolinealidad.html#estimador-por-componentes-principales"><i class="fa fa-check"></i><b>3.8</b> Estimador por componentes principales</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="multicolinealidad.html"><a href="multicolinealidad.html#datos-de-cemento-2"><i class="fa fa-check"></i><b>3.8.1</b> Datos de cemento</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="selección-de-variables.html"><a href="selección-de-variables.html"><i class="fa fa-check"></i><b>4</b> Selección de variables</a>
<ul>
<li class="chapter" data-level="4.1" data-path="selección-de-variables.html"><a href="selección-de-variables.html#ejemplos-3"><i class="fa fa-check"></i><b>4.1</b> Ejemplos</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="selección-de-variables.html"><a href="selección-de-variables.html#unidad-quirúrgica"><i class="fa fa-check"></i><b>4.1.1</b> Unidad quirúrgica</a></li>
<li class="chapter" data-level="4.1.2" data-path="selección-de-variables.html"><a href="selección-de-variables.html#grasa-corporal-1"><i class="fa fa-check"></i><b>4.1.2</b> Grasa corporal</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="selección-de-variables.html"><a href="selección-de-variables.html#problema-de-selección-de-variables"><i class="fa fa-check"></i><b>4.2</b> Problema de selección de variables</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="selección-de-variables.html"><a href="selección-de-variables.html#qué-pasa-si-ignoramos-covariables-importantes"><i class="fa fa-check"></i><b>4.2.1</b> ¿Qué pasa si ignoramos covariables importantes?</a></li>
<li class="chapter" data-level="4.2.2" data-path="selección-de-variables.html"><a href="selección-de-variables.html#que-pasa-si-incluimos-covariables-irrelevantes"><i class="fa fa-check"></i><b>4.2.2</b> ¿Que pasa si incluimos covariables irrelevantes?</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="selección-de-variables.html"><a href="selección-de-variables.html#métodos-para-la-selección-de-variables"><i class="fa fa-check"></i><b>4.3</b> Métodos para la selección de variables</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="selección-de-variables.html"><a href="selección-de-variables.html#coeficiente-de-determinación"><i class="fa fa-check"></i><b>4.3.1</b> Coeficiente de determinación</a></li>
<li class="chapter" data-level="4.3.2" data-path="selección-de-variables.html"><a href="selección-de-variables.html#coeficiente-de-determinación-ajustado"><i class="fa fa-check"></i><b>4.3.2</b> Coeficiente de determinación ajustado</a></li>
<li class="chapter" data-level="4.3.3" data-path="selección-de-variables.html"><a href="selección-de-variables.html#c_p-de-mallows"><i class="fa fa-check"></i><b>4.3.3</b> C<span class="math inline">\(_p\)</span> de Mallows</a></li>
<li class="chapter" data-level="4.3.4" data-path="selección-de-variables.html"><a href="selección-de-variables.html#estadístico-press"><i class="fa fa-check"></i><b>4.3.4</b> Estadístico PRESS</a></li>
<li class="chapter" data-level="4.3.5" data-path="selección-de-variables.html"><a href="selección-de-variables.html#criterios-de-información"><i class="fa fa-check"></i><b>4.3.5</b> Criterios de información</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="selección-de-variables.html"><a href="selección-de-variables.html#comparación-de-los-modelos"><i class="fa fa-check"></i><b>4.4</b> Comparación de los modelos</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="selección-de-variables.html"><a href="selección-de-variables.html#todos-los-posibles-modelos"><i class="fa fa-check"></i><b>4.4.1</b> Todos los posibles modelos</a></li>
<li class="chapter" data-level="4.4.2" data-path="selección-de-variables.html"><a href="selección-de-variables.html#algorítmos-de-selección"><i class="fa fa-check"></i><b>4.4.2</b> Algorítmos de selección</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="selección-de-variables.html"><a href="selección-de-variables.html#regresión-de-lasso"><i class="fa fa-check"></i><b>4.5</b> Regresión de LASSO</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="selección-de-variables.html"><a href="selección-de-variables.html#datos-de-grasa-corporal-1"><i class="fa fa-check"></i><b>4.5.1</b> Datos de grasa corporal</a></li>
<li class="chapter" data-level="4.5.2" data-path="selección-de-variables.html"><a href="selección-de-variables.html#validación-cruzada"><i class="fa fa-check"></i><b>4.5.2</b> Validación cruzada</a></li>
<li class="chapter" data-level="4.5.3" data-path="selección-de-variables.html"><a href="selección-de-variables.html#ejemplo-grasa-corporal"><i class="fa fa-check"></i><b>4.5.3</b> Ejemplo grasa corporal</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="modelos-no-lineales.html"><a href="modelos-no-lineales.html"><i class="fa fa-check"></i><b>5</b> Modelos no lineales</a>
<ul>
<li class="chapter" data-level="5.1" data-path="modelos-no-lineales.html"><a href="modelos-no-lineales.html#ejemplos-4"><i class="fa fa-check"></i><b>5.1</b> Ejemplos</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="modelos-no-lineales.html"><a href="modelos-no-lineales.html#crecimiento-de-pavos"><i class="fa fa-check"></i><b>5.1.1</b> Crecimiento de pavos</a></li>
<li class="chapter" data-level="5.1.2" data-path="modelos-no-lineales.html"><a href="modelos-no-lineales.html#puromicina"><i class="fa fa-check"></i><b>5.1.2</b> Puromicina</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="modelos-no-lineales.html"><a href="modelos-no-lineales.html#modelos-no-lineales-1"><i class="fa fa-check"></i><b>5.2</b> Modelos no lineales</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="modelos-no-lineales.html"><a href="modelos-no-lineales.html#estimación-de-los-parámetros"><i class="fa fa-check"></i><b>5.2.1</b> Estimación de los parámetros</a></li>
<li class="chapter" data-level="5.2.2" data-path="modelos-no-lineales.html"><a href="modelos-no-lineales.html#inferencia-sobre-los-parámetros"><i class="fa fa-check"></i><b>5.2.2</b> Inferencia sobre los parámetros</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="modelos-no-lineales.html"><a href="modelos-no-lineales.html#método-de-bootstrap"><i class="fa fa-check"></i><b>5.3</b> Método de Bootstrap</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="modelos-no-lineales.html"><a href="modelos-no-lineales.html#bootstrap-en-regresión"><i class="fa fa-check"></i><b>5.3.1</b> Bootstrap en regresión</a></li>
<li class="chapter" data-level="5.3.2" data-path="modelos-no-lineales.html"><a href="modelos-no-lineales.html#algunas-consideraciones"><i class="fa fa-check"></i><b>5.3.2</b> Algunas consideraciones</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html"><i class="fa fa-check"></i><b>6</b> Modelo lineal generalizado</a>
<ul>
<li class="chapter" data-level="6.1" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#introducción-1"><i class="fa fa-check"></i><b>6.1</b> Introducción</a></li>
<li class="chapter" data-level="6.2" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#casos-de-estudio"><i class="fa fa-check"></i><b>6.2</b> Casos de estudio</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#mortalidad-de-escarabajos"><i class="fa fa-check"></i><b>6.2.1</b> Mortalidad de escarabajos</a></li>
<li class="chapter" data-level="6.2.2" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#ataques-de-epilepsia"><i class="fa fa-check"></i><b>6.2.2</b> ataques de epilepsia</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#preambulo"><i class="fa fa-check"></i><b>6.3</b> Preambulo</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#familia-exponencial"><i class="fa fa-check"></i><b>6.3.1</b> Familia exponencial</a></li>
<li class="chapter" data-level="6.3.2" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#relación-media-varianza"><i class="fa fa-check"></i><b>6.3.2</b> Relación media-varianza:</a></li>
<li class="chapter" data-level="6.3.3" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#estimador-de-máxima-verosimilitud"><i class="fa fa-check"></i><b>6.3.3</b> Estimador de máxima verosimilitud</a></li>
<li class="chapter" data-level="6.3.4" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#métodos-iterativos-de-maximización"><i class="fa fa-check"></i><b>6.3.4</b> Métodos iterativos de maximización</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#modelo-lineal-generalizado-glm"><i class="fa fa-check"></i><b>6.4</b> Modelo lineal generalizado (GLM)</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#componente-aleatorio"><i class="fa fa-check"></i><b>6.4.1</b> Componente aleatorio</a></li>
<li class="chapter" data-level="6.4.2" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#predictor-lineal"><i class="fa fa-check"></i><b>6.4.2</b> Predictor lineal</a></li>
<li class="chapter" data-level="6.4.3" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#función-de-enlace"><i class="fa fa-check"></i><b>6.4.3</b> Función de enlace</a></li>
<li class="chapter" data-level="6.4.4" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#ejemplos-de-glm"><i class="fa fa-check"></i><b>6.4.4</b> Ejemplos de GLM</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#ajuste-de-un-glm"><i class="fa fa-check"></i><b>6.5</b> Ajuste de un GLM</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#especificación-del-modelo"><i class="fa fa-check"></i><b>6.5.1</b> Especificación del modelo</a></li>
<li class="chapter" data-level="6.5.2" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#estimador-por-máxima-verosimilitud-para-boldsymbol-beta"><i class="fa fa-check"></i><b>6.5.2</b> Estimador por máxima verosimilitud para <span class="math inline">\(\boldsymbol \beta\)</span></a></li>
<li class="chapter" data-level="6.5.3" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#interpretación-de-parámetros---modelo-logístico"><i class="fa fa-check"></i><b>6.5.3</b> interpretación de parámetros - modelo logístico</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#pruebas-de-hipótesis"><i class="fa fa-check"></i><b>6.6</b> Pruebas de hipótesis</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#método-de-razón-de-verosimilitud"><i class="fa fa-check"></i><b>6.6.1</b> Método de razón de verosimilitud</a></li>
<li class="chapter" data-level="6.6.2" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#método-de-wald"><i class="fa fa-check"></i><b>6.6.2</b> Método de Wald</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#intervalos-de-confianza"><i class="fa fa-check"></i><b>6.7</b> intervalos de confianza</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#intervalo-de-confianza-para-la-media"><i class="fa fa-check"></i><b>6.7.1</b> Intervalo de confianza para la media</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#devianza"><i class="fa fa-check"></i><b>6.8</b> Devianza</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#el-estadístico-chi-cuadrado-de-pearson"><i class="fa fa-check"></i><b>6.8.1</b> El estadístico chi-cuadrado de Pearson</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#bondad-de-ajuste"><i class="fa fa-check"></i><b>6.9</b> Bondad de ajuste</a></li>
<li class="chapter" data-level="6.10" data-path="modelo-lineal-generalizado.html"><a href="modelo-lineal-generalizado.html#selección-de-variables-1"><i class="fa fa-check"></i><b>6.10</b> Selección de variables</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="modelo-logístico.html"><a href="modelo-logístico.html"><i class="fa fa-check"></i><b>7</b> Modelo logístico</a>
<ul>
<li class="chapter" data-level="7.1" data-path="modelo-logístico.html"><a href="modelo-logístico.html#casos-de-estudio-1"><i class="fa fa-check"></i><b>7.1</b> Casos de estudio</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="modelo-logístico.html"><a href="modelo-logístico.html#mortalidad-de-escarabajos-1"><i class="fa fa-check"></i><b>7.1.1</b> Mortalidad de escarabajos</a></li>
<li class="chapter" data-level="7.1.2" data-path="modelo-logístico.html"><a href="modelo-logístico.html#bajo-peso-al-nacer"><i class="fa fa-check"></i><b>7.1.2</b> Bajo peso al nacer</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="modelo-logístico.html"><a href="modelo-logístico.html#datos-agrupados-o-datos-no-agrupados"><i class="fa fa-check"></i><b>7.2</b> Datos agrupados o datos no agrupados</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="modelo-logístico.html"><a href="modelo-logístico.html#datos-agrupados"><i class="fa fa-check"></i><b>7.2.1</b> Datos agrupados</a></li>
<li class="chapter" data-level="7.2.2" data-path="modelo-logístico.html"><a href="modelo-logístico.html#datos-no-agrupados"><i class="fa fa-check"></i><b>7.2.2</b> Datos no agrupados</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="modelo-logístico.html"><a href="modelo-logístico.html#funciones-de-enlace"><i class="fa fa-check"></i><b>7.3</b> Funciones de enlace</a></li>
<li class="chapter" data-level="7.4" data-path="modelo-logístico.html"><a href="modelo-logístico.html#curva-característica-operativa-del-receptorroc"><i class="fa fa-check"></i><b>7.4</b> Curva característica operativa del receptor(ROC)</a></li>
<li class="chapter" data-level="7.5" data-path="modelo-logístico.html"><a href="modelo-logístico.html#sobredispersión"><i class="fa fa-check"></i><b>7.5</b> Sobredispersión</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="modelo-logístico.html"><a href="modelo-logístico.html#evalaución-de-sobredispersión"><i class="fa fa-check"></i><b>7.5.1</b> Evalaución de sobredispersión</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="modelo-logístico.html"><a href="modelo-logístico.html#distribución-beta-binomial"><i class="fa fa-check"></i><b>7.6</b> Distribución beta-binomial</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="modelo-logístico.html"><a href="modelo-logístico.html#modelo-beta-binomial"><i class="fa fa-check"></i><b>7.6.1</b> Modelo beta-binomial</a></li>
<li class="chapter" data-level="7.6.2" data-path="modelo-logístico.html"><a href="modelo-logístico.html#estudio-de-teratología"><i class="fa fa-check"></i><b>7.6.2</b> Estudio de teratología</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="modelo-para-conteos.html"><a href="modelo-para-conteos.html"><i class="fa fa-check"></i><b>8</b> Modelo para conteos</a>
<ul>
<li class="chapter" data-level="8.1" data-path="modelo-para-conteos.html"><a href="modelo-para-conteos.html#casos-de-estudio-2"><i class="fa fa-check"></i><b>8.1</b> Casos de estudio</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="modelo-para-conteos.html"><a href="modelo-para-conteos.html#ataques-de-epilepsia-1"><i class="fa fa-check"></i><b>8.1.1</b> Ataques de epilepsia</a></li>
<li class="chapter" data-level="8.1.2" data-path="modelo-para-conteos.html"><a href="modelo-para-conteos.html#muertes-por-enfermedades-cardiovasculares-en-doctores-del-reino-unido"><i class="fa fa-check"></i><b>8.1.2</b> Muertes por enfermedades cardiovasculares en doctores del Reino Unido</a></li>
<li class="chapter" data-level="8.1.3" data-path="modelo-para-conteos.html"><a href="modelo-para-conteos.html#número-de-cangrejos-satélites"><i class="fa fa-check"></i><b>8.1.3</b> Número de cangrejos satélites</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="modelo-para-conteos.html"><a href="modelo-para-conteos.html#modelo-poisson"><i class="fa fa-check"></i><b>8.2</b> Modelo Poisson</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="modelo-para-conteos.html"><a href="modelo-para-conteos.html#modelo-de-conteo-con-offset"><i class="fa fa-check"></i><b>8.2.1</b> Modelo de conteo con offset</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="modelo-para-conteos.html"><a href="modelo-para-conteos.html#sobredispersión-1"><i class="fa fa-check"></i><b>8.3</b> Sobredispersión</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="modelo-para-conteos.html"><a href="modelo-para-conteos.html#distribución-binomial-negativa"><i class="fa fa-check"></i><b>8.3.1</b> Distribución binomial negativa</a></li>
<li class="chapter" data-level="8.3.2" data-path="modelo-para-conteos.html"><a href="modelo-para-conteos.html#modelo-binomial-negativo-poisson-gamma"><i class="fa fa-check"></i><b>8.3.2</b> Modelo binomial negativo (Poisson-gamma)</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="modelo-para-conteos.html"><a href="modelo-para-conteos.html#inflación-de-ceros"><i class="fa fa-check"></i><b>8.4</b> Inflación de ceros</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="modelo-para-conteos.html"><a href="modelo-para-conteos.html#modelo-de-inflación-de-ceros"><i class="fa fa-check"></i><b>8.4.1</b> Modelo de inflación de ceros</a></li>
<li class="chapter" data-level="8.4.2" data-path="modelo-para-conteos.html"><a href="modelo-para-conteos.html#modelo-hurdle"><i class="fa fa-check"></i><b>8.4.2</b> Modelo Hurdle</a></li>
<li class="chapter" data-level="8.4.3" data-path="modelo-para-conteos.html"><a href="modelo-para-conteos.html#número-de-cangrejos-satélites-1"><i class="fa fa-check"></i><b>8.4.3</b> Número de cangrejos satélites</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="modelo-lineal-mixto.html"><a href="modelo-lineal-mixto.html"><i class="fa fa-check"></i><b>9</b> Modelo lineal mixto</a>
<ul>
<li class="chapter" data-level="9.1" data-path="modelo-lineal-mixto.html"><a href="modelo-lineal-mixto.html#casos-de-estudio-3"><i class="fa fa-check"></i><b>9.1</b> Casos de estudio</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="modelo-lineal-mixto.html"><a href="modelo-lineal-mixto.html#peso-al-nacer-de-corderos"><i class="fa fa-check"></i><b>9.1.1</b> Peso al nacer de corderos</a></li>
<li class="chapter" data-level="9.1.2" data-path="modelo-lineal-mixto.html"><a href="modelo-lineal-mixto.html#crecimiento-craneofacial-de-ratas"><i class="fa fa-check"></i><b>9.1.2</b> Crecimiento craneofacial de ratas</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="modelo-lineal-mixto.html"><a href="modelo-lineal-mixto.html#datos-correlacionados"><i class="fa fa-check"></i><b>9.2</b> Datos correlacionados</a></li>
<li class="chapter" data-level="9.3" data-path="modelo-lineal-mixto.html"><a href="modelo-lineal-mixto.html#modelo-lineal-mixto-1"><i class="fa fa-check"></i><b>9.3</b> Modelo lineal mixto</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notas de clase: Modelo lineal general II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="selección-de-variables" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Capítulo 4</span> Selección de variables<a href="selección-de-variables.html#selección-de-variables" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="ejemplos-3" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Ejemplos<a href="selección-de-variables.html#ejemplos-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="unidad-quirúrgica" class="section level3 hasAnchor" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Unidad quirúrgica<a href="selección-de-variables.html#unidad-quirúrgica" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Una unidad quirúrgica de un hospital está interesada en predecir la supervivencia de los pacientes sometidos a un tipo particular de operación hepática. Se dispuso de una selección aleatoria de <span class="math inline">\(108\)</span> pacientes para el análisis. De cada registro del paciente, se extrajo la siguiente información de la evaluación preoperatoria:</p>
<ul>
<li><p><code>bcs</code>: coagulación sanguínea.</p></li>
<li><p><code>pindex</code>: índice de pronóstico.</p></li>
<li><p><code>enzyme</code>: función enzimática.</p></li>
<li><p><code>liver_test</code>: función hepática.</p></li>
<li><p><code>age</code>: edad.</p></li>
<li><p><code>gender</code>: genero (0 = masculino, 1 = femenino).</p></li>
<li><p><code>alc_mod</code>: historial de consumo de alcohol (0 = Ninguno, 1 = Moderado).</p></li>
<li><p><code>alc_heavy</code>: &amp; historial de consumo de alcohol (0 = Ninguno, 1 = Fuerte).</p></li>
<li><p><code>y</code>: tiempo de supervivencia.</p></li>
</ul>
<p>El objetivo del estudio es determinar los factores que influyen sobre el tiempo de supervivencia (que se determinó posteriormente) en función de las demás variables.</p>
<p>El modelo propuesto es el siguiente:
<span class="math display">\[\begin{equation}
\begin{split}
\log y_{i} =&amp; \beta_{0}+\mbox{bcs}_{i}\beta_{1} + \mbox{pindex}_{i}\beta_{2}+ \mbox{enzyme}_{i}\beta_{3} +  \mbox{liver}_{i}\beta_{4} + \mbox{age}_{i}\beta_{5} +  \mbox{gender}_{i}\beta_{6}+ \\ &amp; \mbox{alc_mod}_{i}\beta_{7} + \mbox{alc_heavy}_{i}\beta_{8} + \varepsilon_{i}
\end{split}
\nonumber
\end{equation}\]</span></p>
<p>El ajuste del modelo es:</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="selección-de-variables.html#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(olsrr)</span>
<span id="cb71-2"><a href="selección-de-variables.html#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(surgical)</span>
<span id="cb71-3"><a href="selección-de-variables.html#cb71-3" aria-hidden="true" tabindex="-1"></a>mod.surgical.completo <span class="ot">=</span> <span class="fu">lm</span>(<span class="fu">log</span>(y)<span class="sc">~</span>.,<span class="at">data=</span>surgical)</span>
<span id="cb71-4"><a href="selección-de-variables.html#cb71-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod.surgical.completo)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(y) ~ ., data = surgical)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.35555 -0.13849 -0.05179  0.14912  0.46349 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  4.050949   0.251741  16.092  &lt; 2e-16 ***
## bcs          0.068551   0.025420   2.697  0.00982 ** 
## pindex       0.013459   0.001947   6.913 1.37e-08 ***
## enzyme_test  0.014948   0.001809   8.261 1.44e-10 ***
## liver_test   0.007931   0.046706   0.170  0.86592    
## age         -0.003567   0.002751  -1.296  0.20145    
## gender       0.084151   0.060746   1.385  0.17279    
## alc_mod      0.057313   0.067480   0.849  0.40019    
## alc_heavy    0.388190   0.088374   4.393 6.73e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.2093 on 45 degrees of freedom
## Multiple R-squared:  0.8461, Adjusted R-squared:  0.8187 
## F-statistic: 30.93 on 8 and 45 DF,  p-value: 7.823e-16</code></pre>
</div>
<div id="grasa-corporal-1" class="section level3 hasAnchor" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> Grasa corporal<a href="selección-de-variables.html#grasa-corporal-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La medición de la grasa corporal es un proceso complejo. Dado que los músculos y los huesos son más densos, el calculo de % de grasa corporal se basa, entre otros aspectos, en la medición de la densidad corporal la cuál requiere sumergir a las personas en el agua.</p>
<p>Por esta razón se quiere buscar un método más sencillo para determinar el % de grasa corporal. Para esto, se registraron la edad, el peso, la altura y <span class="math inline">\(10\)</span> medidas de la circunferencia corporal de <span class="math inline">\(252\)</span> hombres. De igual forma, a cada uno de estos hombres se les midió el % de grasa corporal de forma precisa (usando la ecuación de Brozek, medición a partir de la densidad).</p>
<p>Cómo variable respuesta se utiliza la medición por el método de Brozek, y las posibles covariables son:</p>
<ul>
<li><p><code>age</code>: edad (en años).</p></li>
<li><p><code>weight</code>: peso (en libras).</p></li>
<li><p><code>height</code>: altura (en pulgadas).</p></li>
<li><p><code>neck</code>: circunferencia del cuello (en centímetros).</p></li>
<li><p><code>chest</code>: circunferencia del pecho (en centímetros).</p></li>
<li><p><code>abdom</code>: circunferencia del abdomen (en centímetros).</p></li>
<li><p><code>hip</code>: circunferencia de la cadera (en centímetros).</p></li>
<li><p><code>thigh</code>:circunferencia del muslo (en centímetros).</p></li>
<li><p><code>knee</code>:circunferencia de la rodilla (en centímetros).</p></li>
<li><p><code>ankle</code>:circunferencia del tobillo (en centímetros).</p></li>
<li><p><code>biceps</code>: circunferencia del bíceps extendido (en centímetros).</p></li>
<li><p><code>forearm</code>: circunferencia del antebrazo (en centímetros).</p></li>
<li><p><code>wrist</code>: circunferencia de la muñeca (en centímetros).</p></li>
</ul>
<p>El modelo propuesto es el siguiente:
<span class="math display" id="eq:modeloFat">\[\begin{equation}
\mbox{brozek}_i = \beta_{0} + \mbox{age}_i\beta_1+ \mbox{weight}_i\beta_2 + \ldots + \mbox{wrist}_i\beta_{13}  + \varepsilon_i.
\tag{4.1}
\end{equation}\]</span>
El ajuste del modelo es:</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="selección-de-variables.html#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(faraway)</span>
<span id="cb73-2"><a href="selección-de-variables.html#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(fat)</span>
<span id="cb73-3"><a href="selección-de-variables.html#cb73-3" aria-hidden="true" tabindex="-1"></a>mod.fat <span class="ot">&lt;-</span> <span class="fu">lm</span>(brozek <span class="sc">~</span> age <span class="sc">+</span> weight <span class="sc">+</span> height <span class="sc">+</span> neck <span class="sc">+</span> chest <span class="sc">+</span> abdom <span class="sc">+</span></span>
<span id="cb73-4"><a href="selección-de-variables.html#cb73-4" aria-hidden="true" tabindex="-1"></a>             hip <span class="sc">+</span> thigh <span class="sc">+</span> knee <span class="sc">+</span> ankle <span class="sc">+</span> biceps <span class="sc">+</span> forearm <span class="sc">+</span> wrist, <span class="at">data=</span>fat)</span>
<span id="cb73-5"><a href="selección-de-variables.html#cb73-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod.fat)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = brozek ~ age + weight + height + neck + chest + 
##     abdom + hip + thigh + knee + ankle + biceps + forearm + wrist, 
##     data = fat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -10.264  -2.572  -0.097   2.898   9.327 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -15.29255   16.06992  -0.952  0.34225    
## age           0.05679    0.02996   1.895  0.05929 .  
## weight       -0.08031    0.04958  -1.620  0.10660    
## height       -0.06460    0.08893  -0.726  0.46830    
## neck         -0.43754    0.21533  -2.032  0.04327 *  
## chest        -0.02360    0.09184  -0.257  0.79740    
## abdom         0.88543    0.08008  11.057  &lt; 2e-16 ***
## hip          -0.19842    0.13516  -1.468  0.14341    
## thigh         0.23190    0.13372   1.734  0.08418 .  
## knee         -0.01168    0.22414  -0.052  0.95850    
## ankle         0.16354    0.20514   0.797  0.42614    
## biceps        0.15280    0.15851   0.964  0.33605    
## forearm       0.43049    0.18445   2.334  0.02044 *  
## wrist        -1.47654    0.49552  -2.980  0.00318 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.988 on 238 degrees of freedom
## Multiple R-squared:  0.749,  Adjusted R-squared:  0.7353 
## F-statistic: 54.63 on 13 and 238 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div id="problema-de-selección-de-variables" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Problema de selección de variables<a href="selección-de-variables.html#problema-de-selección-de-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En problemas de regresión se tiene un conjunto grande de potenciales covariables. Si ajustamos un modelo considerandolas todas podemos estar incluyendo covariables que son irrelevante. Por el otro lado, si no las incluimos todas es posible que estemos omitiendo covariables importantes. En ambos casos hay consecuencias negativas.</p>
<p>Para illustrar esto, considere el siguiente modelo:
<span class="math display" id="eq:modelogral">\[\begin{equation}
\begin{split}
y_{i} &amp;= \beta_{0} + \sum_{j=1}^{p-1}\beta_{j}x_{ij} + \varepsilon_{i} \\
&amp;= \beta_{0} + \sum_{j=1}^{r}\beta_{j}x_{ij} + \sum_{j=r+1}^{p-1}\beta_{j}x_{ij} + \varepsilon_{i} \\
&amp;= \boldsymbol x_{1i}&#39;\boldsymbol \beta_1 + \boldsymbol x_{2i}&#39;\boldsymbol \beta_2 + \varepsilon_i,
\end{split}
\tag{4.2}
\end{equation}\]</span>
donde <span class="math inline">\(\boldsymbol x_{1i} = (1,x_{1i},x_{2i},\ldots,x_{ri})\)</span>, <span class="math inline">\(\boldsymbol x_{2i} = (x_{r+1,i},x_{r+2,i},\ldots,x_{p-1,i})\)</span>, <span class="math inline">\(\boldsymbol \beta_1 = (\beta_0,\beta_1,\beta_2,\ldots,\beta_r)&#39;\)</span>, <span class="math inline">\(\boldsymbol \beta_2 = (\beta_{r+1},\beta_{r+2},\ldots,\beta_{p-1})&#39;\)</span>, y <span class="math inline">\(\varepsilon_i \sim N(0,\sigma^{2})\)</span>. Es decir, se hace una partición de las covariables y los coeficientes de regressión en dos componentes.</p>
<p>En forma matricial, el modelo es:
<span class="math display">\[
\boldsymbol y= \boldsymbol X_{1}\boldsymbol \beta_{1} + \boldsymbol X_{2}\boldsymbol \beta_{2}+ \boldsymbol \varepsilon,
\]</span>
donde <span class="math inline">\(\boldsymbol X_{1}\)</span> es una matriz <span class="math inline">\(n \times r\)</span> con la <span class="math inline">\(i\)</span>-ésima fila igual a <span class="math inline">\(\boldsymbol x_{1i}\)</span> y <span class="math inline">\(\boldsymbol X_{2}\)</span> es una matriz <span class="math inline">\(n \times (p-r-1)\)</span> con la <span class="math inline">\(i\)</span>-ésima fila igual a <span class="math inline">\(\boldsymbol x_{2i}\)</span>.</p>
<div id="qué-pasa-si-ignoramos-covariables-importantes" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> ¿Qué pasa si ignoramos covariables importantes?<a href="selección-de-variables.html#qué-pasa-si-ignoramos-covariables-importantes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ahora, considere que el modelo de regresión real es <a href="selección-de-variables.html#eq:modelogral">(4.2)</a>, pero decidimos estimar:
<span class="math display">\[
y_{i} = \boldsymbol x_{1i}&#39;\boldsymbol \beta_1 + \varepsilon_i.
\]</span>
Por lo tanto, estamos omitiendo las covariables <span class="math inline">\(\boldsymbol x_{2i}\)</span> del modelo (puesto que <span class="math inline">\(\boldsymbol \beta_2 \neq 0\)</span>).</p>
<p>El estimador por MCO de <span class="math inline">\(\boldsymbol \beta_1\)</span> es:
<span class="math display">\[
\widehat{\boldsymbol \beta}_{1} = (\boldsymbol X_{1}&#39;\boldsymbol X_{1})^{-1}\boldsymbol X_{1}&#39;\boldsymbol y.
\]</span>
De aquí tenemos que <span class="math inline">\(E(\widehat{\boldsymbol \beta}_{1}) = \boldsymbol \beta_{1} + (\boldsymbol X_{1}&#39;\boldsymbol X_{1})^{-1}\boldsymbol X_{1}&#39;\boldsymbol X_{2}\boldsymbol \beta_{2}\)</span>. Es decir que <span class="math inline">\(\widehat{\boldsymbol \beta}_{1}\)</span> es un estimador sesgado, a menos que <span class="math inline">\(\boldsymbol X_{1}&#39;\boldsymbol X_{2} = \boldsymbol 0\)</span> (las columnas de <span class="math inline">\(X_{1}\)</span> son ortogonales a las columnas de <span class="math inline">\(X_{2}\)</span>).</p>
<p>De igual forma, las predicciones también serán sesgadas. La predicción en el punto <span class="math inline">\(\boldsymbol x_{01}\)</span> es:
<span class="math display">\[
\widehat{y}_{0} = \boldsymbol x_{01}&#39;\widehat{\boldsymbol \beta}_{1}.
\]</span>
Su valor esperado es:
<span class="math display">\[
E(\widehat{y}_{0}) = \boldsymbol x_{01}&#39;\boldsymbol \beta_{1} + \boldsymbol x_{01}&#39;(\boldsymbol X_{1}&#39;\boldsymbol X_{1})^{-1}\boldsymbol X_{1}&#39;\boldsymbol X_{2}\boldsymbol \beta_{2} \neq \boldsymbol x_{01}&#39;\beta_{1} + \boldsymbol x_{02}&#39;\beta_{2}.
\]</span>
Por lo tanto, si omitimos variables relevantes obtenemos sesgo en las estimaciones.</p>
</div>
<div id="que-pasa-si-incluimos-covariables-irrelevantes" class="section level3 hasAnchor" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> ¿Que pasa si incluimos covariables irrelevantes?<a href="selección-de-variables.html#que-pasa-si-incluimos-covariables-irrelevantes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ahora, consideremos el caso en que <span class="math inline">\(\boldsymbol \beta_2=0\)</span>, es decir, las covariables <span class="math inline">\(\boldsymbol x_{2}\)</span> no tienen un aporte significativo en el modelo. Pero decidimos estimar el modelo completo.</p>
<p>En este caso, el estimador de <span class="math inline">\(\boldsymbol \beta\)</span> es:
<span class="math display">\[
\widehat{\boldsymbol \beta}= (\boldsymbol X&#39;\boldsymbol X)^{-1}\boldsymbol X&#39;\boldsymbol y= \begin{pmatrix}
\boldsymbol X_{1}&#39;\boldsymbol X_{1} &amp; \boldsymbol X_{1}\boldsymbol X_{2} \\ \boldsymbol X_{2}&#39;\boldsymbol X_{1} &amp; \boldsymbol X_{2}&#39;\boldsymbol X_{2}
\end{pmatrix}^{-1} \begin{pmatrix}
\boldsymbol X_{1}&#39; \\ \boldsymbol X_{2}&#39;
\end{pmatrix}\boldsymbol y.
\]</span>
El Valor esperado de <span class="math inline">\(\widehat{\boldsymbol \beta}\)</span> es:
<span class="math display">\[\begin{equation}
\begin{split}
E(\widehat{\boldsymbol \beta}) =&amp; (\boldsymbol X&#39;\boldsymbol X)^{-1}\boldsymbol X&#39;E(\boldsymbol y) = (\boldsymbol X&#39;\boldsymbol X)^{-1}\boldsymbol X&#39;\boldsymbol X_{1}\boldsymbol \beta_1 \\
= &amp; (\boldsymbol X&#39;\boldsymbol X)^{-1}\boldsymbol X&#39;(\boldsymbol X_{1} \ \boldsymbol X_{2}) \begin{pmatrix}
\boldsymbol \beta_1 \\ \boldsymbol 0
\end{pmatrix} = \begin{pmatrix}
\boldsymbol \beta_1 \\ \boldsymbol 0
\end{pmatrix}.
\end{split}
\nonumber
\end{equation}\]</span>
Es decir que <span class="math inline">\(\widehat{\boldsymbol \beta}\)</span> es un estimador insesgado.</p>
<p>La varianza de <span class="math inline">\(\widehat{\boldsymbol \beta}\)</span> es:
<span class="math display">\[\begin{equation}
\begin{split}
V(\widehat{\boldsymbol \beta}) =&amp; \sigma^{2}(\boldsymbol X&#39;\boldsymbol X)^{-1} = \sigma^{2}\begin{pmatrix}
\boldsymbol X_{1}&#39;\boldsymbol X_{1} &amp; \boldsymbol X_{1}\boldsymbol X_{2} \\ \boldsymbol X_{2}&#39;\boldsymbol X_{1} &amp; \boldsymbol X_{2}&#39;\boldsymbol X_{2}
\end{pmatrix}^{-1} \\
=&amp; \sigma^{2} \begin{pmatrix}
(\boldsymbol X_{1}&#39;\boldsymbol X_{1})^{-1} + \boldsymbol L\boldsymbol M\boldsymbol L&amp; - \boldsymbol L\boldsymbol M\\
-\boldsymbol M\boldsymbol L&#39; &amp; \boldsymbol M
\end{pmatrix},
\end{split}
\nonumber
\end{equation}\]</span>
donde <span class="math inline">\(\boldsymbol L= (\boldsymbol X_{1}&#39;\boldsymbol X_{1})^{-1}\boldsymbol X_{1}&#39;\boldsymbol X_{2}\)</span> y <span class="math inline">\(\boldsymbol M= \boldsymbol X_{2}&#39;(\boldsymbol I- \boldsymbol H_{1})\boldsymbol X_{2}\)</span>. Particularmente, para <span class="math inline">\(\widehat{\boldsymbol \beta}_1\)</span> tenemos que:
<span class="math display">\[
V(\widehat{\boldsymbol \beta}_{1}) = \sigma^{2} \left[ (\boldsymbol X_{1}&#39;\boldsymbol X_{1})^{-1} + \boldsymbol L\boldsymbol M\boldsymbol L\right].
\]</span>
Dado que <span class="math inline">\(\boldsymbol M\)</span> (y por lo tanto <span class="math inline">\(\boldsymbol L\boldsymbol M\boldsymbol L\)</span>) es positiva-definida, la varianza de <span class="math inline">\(\widehat{\boldsymbol \beta}_{1}\)</span> se infla al incluir las covariables irrelevantes al modelo. La única excepción es cuando <span class="math inline">\(\boldsymbol X_{1}\)</span> y <span class="math inline">\(\boldsymbol X_{2}\)</span> son ortogonales (<span class="math inline">\(\boldsymbol X_{1}&#39;\boldsymbol X_{2} = \boldsymbol 0\)</span>).</p>
<p>De igual forma, las predicciones en el punto <span class="math inline">\(\boldsymbol x_{0}&#39; = (\boldsymbol x_{01}&#39; \ \boldsymbol x_{02}&#39;)\)</span> son insesgadas:
<span class="math display">\[
E(\widehat{y}_{0}) = E(\boldsymbol x_{0}&#39;\widehat{\boldsymbol \beta}) = (\boldsymbol x_{01}&#39; \ \boldsymbol x_{02}&#39;)\begin{pmatrix}
\boldsymbol \beta_{1} \\ \boldsymbol 0
\end{pmatrix} = \boldsymbol x_{01}&#39;\boldsymbol \beta_{1}.
\]</span>
Pero su varianza también se infla debido a incluir las covariables irrelevantes:
<span class="math display">\[
V(\widehat{y}_{0}) = \sigma^{2} \boldsymbol x_{0}&#39;(\boldsymbol X&#39;\boldsymbol X)^{-1}\boldsymbol x_{0}.
\]</span></p>
<p>En conclusión:</p>
<ul>
<li><p>Cuando omitimos covariables relevantes, obtenemos sesgos en las estimaciones.</p></li>
<li><p>Cuando incluimos covariables irrelevantes, se inflan las varianzas de las estimaciones. Adicionalmente, incluir más covariables puede llevar a problemas de multicolinealidad.</p></li>
</ul>
</div>
</div>
<div id="métodos-para-la-selección-de-variables" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Métodos para la selección de variables<a href="selección-de-variables.html#métodos-para-la-selección-de-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Si tenemos <span class="math inline">\((p-1)\)</span> covariables, entonces tenemos <span class="math inline">\((p-1)^2\)</span> potenciales modelos. Por lo que podemos ajustar todos los posibles modelos y hacer una comparación entre ellos usando algunos criterios de decisión.</p>
<p>Existen varios criterios para determinar que modelo es “mejor” que otro y este debe escogerse teniendo en cuenta cuál es el objetivo que se tiene al ajustar el modelo (descripción de la relación, predicción, control, etc.). Algunos de estos críterios son:</p>
<ul>
<li>Coeficiente de determinación (<span class="math inline">\(R^{2}\)</span> y <span class="math inline">\(R^{2}_{adj}\)</span>).</li>
<li>Estadístico <span class="math inline">\(C_{p}\)</span> de Mallows.</li>
<li>Estadístico PRESS y el <span class="math inline">\(R^{2}\)</span> de predicción.</li>
<li>Criterios de información (AIC y BIC).</li>
</ul>
<div id="coeficiente-de-determinación" class="section level3 hasAnchor" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Coeficiente de determinación<a href="selección-de-variables.html#coeficiente-de-determinación" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Esté indicador está definido como:
<span class="math display">\[
R^{2} = \frac{SS_{\mbox{reg}}}{SS_{\mbox{T}}} = 1 - \frac{SS_{\mbox{res}}}{SS_{\mbox{T}}}.
\]</span>
El <span class="math inline">\(R^{2}\)</span> cuantifica la cantidad de variabilidad de la variable respuesta que es explicada por el modelo. Se tiene que <span class="math inline">\(0 \leq R^{2} \leq 1\)</span>. Valores más cercanos a <span class="math inline">\(1\)</span> implican que el modelo explica gran parte de la variabilidad de <span class="math inline">\(y\)</span>.</p>
<p>Hay que tener en cuenta que el <span class="math inline">\(R^{2}\)</span> siempre crece a medida que se adicionan más covariables al modelo. Por lo tanto, se puede puede agregar regresores hasta el punto en que una covariable adicional no propociona un aumento considerable en el <span class="math inline">\(R^{2}\)</span>.</p>
</div>
<div id="coeficiente-de-determinación-ajustado" class="section level3 hasAnchor" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Coeficiente de determinación ajustado<a href="selección-de-variables.html#coeficiente-de-determinación-ajustado" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para evitar el incoviente del <span class="math inline">\(R^{2}\)</span>, se puede utlizar el el coeficiente de determinación ajustado definido como:
<span class="math display">\[
R^{2}_{adj} = 1 - \frac{n-1}{n-p}\frac{SS_{\mbox{res}}}{SS_{\mbox{T}}} = 1- \frac{MS_{\mbox{res}}}{SS_{\mbox{T}}/(n-1)} = 1- \frac{n-1}{n-p}(1-R^{2}).
\]</span>
El <span class="math inline">\(R^{2}_{adj}\)</span> no necesariamente aumenta al adicionar nuevos términos al modelo. Este solo aumenta si hay una disminución del <span class="math inline">\(MS_{\mbox{res}}\)</span>.</p>
</div>
<div id="c_p-de-mallows" class="section level3 hasAnchor" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> C<span class="math inline">\(_p\)</span> de Mallows<a href="selección-de-variables.html#c_p-de-mallows" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Mallows propone un criterio basado en el error cuadrático medio (ECM) de <span class="math inline">\(\widehat{y}_i\)</span>, esto es:
<span class="math display">\[
E[\widehat{y}_{i}- E(y_{i})]^2 = [E(y_{i}) - E(\widehat{y}_{i})]^2 + V(\widehat{y}_{i}),
\]</span>
donde <span class="math inline">\(E(y_{i})\)</span> es el valor esperado de la respuesta (‘modelo real’), y <span class="math inline">\(E(\widehat{y}_{i})\)</span> es el valor esperado de la respuesta basado en el modelo propuesto (basado en <span class="math inline">\(p\)</span> covariables).</p>
<p>El ECM total estandarizado está definido como:
<span class="math display">\[\begin{equation}
\begin{split}
\Gamma_{p} =&amp; \frac{1}{\sigma^{2}}\left\{\sum_{i=1}^{n}[E(y_{i}) - E(\widehat{y}_{i})]^2 + \sum_{i=1}^{n}  V(\widehat{y}_{i}) \right\} \\
=&amp;  \frac{1}{\sigma^{2}}\left\{SS_{B}(p)  + \sum_{i=1}^{n}  V(\widehat{y}_{i}) \right\} = \frac{1}{\sigma^{2}}\left\{SS_{B}(p)  + p\sigma^{2} \right\} \\
=&amp; \frac{1}{\sigma^{2}}\left\{ E[SS_{\mbox{res}}(p)] - (n-p)\sigma^{2} + p\sigma^{2} \right\} \\ =&amp; \frac{E[SS_{\mbox{res}}(p)]}{\sigma^{2}} - n + 2p.
\end{split}
\nonumber
\end{equation}\]</span></p>
<p>Reemplazando <span class="math inline">\(E[SS_{\mbox{res}}(p)]\)</span> por <span class="math inline">\(SS_{\mbox{res}}(p)\)</span>, y asumiendo que <span class="math inline">\(MS_{\mbox{res}}(p^{*})\)</span> (calculado usando el modelo completo) es un buen estimador de <span class="math inline">\(\sigma^{2}\)</span>:
<span class="math display">\[
C_{p} = \frac{SS_{\mbox{res}}(p)}{MS_{\mbox{res}}(p^{*})} - n + 2p.
\]</span>
Por lo tanto, para el modelo completo <span class="math inline">\(C_{p} = p^{*}\)</span>. Si <span class="math inline">\(E[SS_{\mbox{res}}(p)] = (n-p)\sigma^{2}\)</span> (asumiendo que <span class="math inline">\(SS_{B}(p)=0\)</span>), tenemos que:
<span class="math display">\[
E[C_{p}| \mbox{Sesgo}=0] = \frac{(n-p)\sigma^{2}}{\sigma^{2}} - n +2p = p.
\]</span>
Si el modelo propuesto es insesgado se espera que el <span class="math inline">\(C_p\)</span> esté cercano a <span class="math inline">\(p\)</span>. Aunque se espera que el <span class="math inline">\(C_p=p\)</span>, es deseable que <span class="math inline">\(C_p &lt; p\)</span>. Por lo tanto, modelos con valores pequeños de <span class="math inline">\(C_p\)</span> son mejores.</p>
</div>
<div id="estadístico-press" class="section level3 hasAnchor" number="4.3.4">
<h3><span class="header-section-number">4.3.4</span> Estadístico PRESS<a href="selección-de-variables.html#estadístico-press" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El estadístico PRESS (prediction error sum of squares) está definido como:
<span class="math display">\[
\mbox{PRESS} = \sum_{i=1}^{n} (y_{i} - \widehat{y}_{(i)})^{2} = \sum_{i=1}^{n} \left( \frac{e_{i}}{1-h_{ii}} \right)^{2}.
\]</span>
Para comparar modelos, menor valor del PRESS indica que el modelo es mejor para hacer predicciones.</p>
<p>A partir del PRESS se puede calcular el <span class="math inline">\(R^{2}\)</span> de predicción:
<span class="math display">\[
R^{2}_{pred} = 1 - \frac{PRESS}{SST}.
\]</span>
Basado en este criterio, mayor es el valor de <span class="math inline">\(R^{2}_{pred}\)</span> mejor es el modelo para hacer predicciones. La ventaja del PRESS y <span class="math inline">\(R_{pred}^{2}\)</span> es que evitan el sobreajuste dado que se calculan utilizando observaciones no incluidas en la estimación del modelo.</p>
</div>
<div id="criterios-de-información" class="section level3 hasAnchor" number="4.3.5">
<h3><span class="header-section-number">4.3.5</span> Criterios de información<a href="selección-de-variables.html#criterios-de-información" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La idea es comparar modelos estimados teniendo en cuenta la bondad de ajuste del modelo (verosimilitud, <span class="math inline">\(L\)</span>) y su complejidad (número de parámetros). El criterio de información de Akaike está definido como:
<span class="math display">\[
\mbox{AIC} = -2\log (L) + 2p.
\]</span>
El criterio de información bayesiano (o de Schwarz - SBC):
<span class="math display">\[
\mbox{BIC} = -2\log (L) + p\log n.
\]</span>
Es preferible modelos con valores menores de AIC o BIC. Dado que la penalización del BIC es mayor (si <span class="math inline">\(n &gt; 7\)</span>), este indicador tiende a preferir modelos con menor número de covariables.</p>
<p>Recordemos que la log-verosimilitud es:
<span class="math display">\[
\log L(\boldsymbol \beta,\sigma^{2}) = - \frac{n}{2}\log (2\pi) - n\log(\sigma) - \frac{1}{2\sigma^{2}}(\boldsymbol y- \boldsymbol X\boldsymbol \beta)&#39;(\boldsymbol y-\boldsymbol X\boldsymbol \beta).
\]</span>
El estimador por máxima verosimilitud de <span class="math inline">\(\sigma^{2}\)</span> es <span class="math inline">\(\widehat{\sigma}=SS_{\mbox{res}}/n\)</span>. Por lo tanto, el máximo valor de la log-verosimilitud es:
<span class="math display">\[
\log L(\widehat{\boldsymbol \beta},\widehat{\sigma}^{2}) = -\frac{n}{2}\log (2\pi) - \frac{n}{2}\log\widehat{\sigma}^{2} - \frac{1}{2\widehat{\sigma}^{2}}SS_{\mbox{res}}= -\frac{n}{2}\log (SS_{\mbox{res}}/n) + \mbox{constante}.
\]</span>
Por lo tanto:
<span class="math display">\[
AIC \propto n\log(SS_{\mbox{res}}/n) + 2p \mbox{ y } BIC \propto n\log(SS_{\mbox{res}}/n) + p\log n.
\]</span>
Hay varias adaptaciones de estos criterios de información definiendo diferentes penalizaciones.</p>
</div>
</div>
<div id="comparación-de-los-modelos" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Comparación de los modelos<a href="selección-de-variables.html#comparación-de-los-modelos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="todos-los-posibles-modelos" class="section level3 hasAnchor" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> Todos los posibles modelos<a href="selección-de-variables.html#todos-los-posibles-modelos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Con la función <code>ols_step_all_possible()</code> de la librería <code>olsrr</code> es posible ajustar todos posibles modelos y determinar el mejor bajo diferentes criterios. Otra alternativa es la función <code>regsubsets()</code> de la librería <code>leaps</code>. Está función es más rápida (se basa en un algoritmo más eficiente), pero no es user-friendly.</p>
<div id="datos-de-unidad-quirúrgica" class="section level4 hasAnchor" number="4.4.1.1">
<h4><span class="header-section-number">4.4.1.1</span> Datos de unidad quirúrgica<a href="selección-de-variables.html#datos-de-unidad-quirúrgica" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A través de la función <code>ols_step_all_possible</code> podemos ajustar los <span class="math inline">\(255\)</span> modelos que se pueden ajustar usando las ocho posibles covariables:</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="selección-de-variables.html#cb75-1" aria-hidden="true" tabindex="-1"></a>surgical.all.mods<span class="ot">=</span><span class="fu">ols_step_all_possible</span>(mod.surgical.completo)</span></code></pre></div>
<p>Además de ajustar los modelos, se calculan varios criterios (<span class="math inline">\(R^{2}\)</span>,<span class="math inline">\(R^{2}_{adj}\)</span>, <span class="math inline">\(R^{2}_{pred}\)</span>,AIC,BIC,…) para cada uno de ellos.</p>
<p>Puesto que son muchos modelos, podemos organizar los resultados de tal forma que obtengamos los mejores modelos basándonos en cada uno de los criterios. Por ejemplo, los 5 mejores ajustes según el <span class="math inline">\(R^{2}_{adj}\)</span> son:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="selección-de-variables.html#cb76-1" aria-hidden="true" tabindex="-1"></a>R2adj.order <span class="ot">=</span> <span class="fu">order</span>(surgical.all.mods<span class="sc">$</span>adjr,<span class="at">decreasing =</span> T)</span>
<span id="cb76-2"><a href="selección-de-variables.html#cb76-2" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.frame</span>(surgical.all.mods)[R2adj.order[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>],<span class="fu">c</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">8</span>,<span class="dv">10</span>)]</span></code></pre></div>
<pre><code>##     n                                             predictors   rsquare      adjr   predrsq       cp
## 226 6            bcs pindex enzyme_test age gender alc_heavy 0.8434664 0.8234834 0.7836037 5.772458
## 251 7    bcs pindex enzyme_test age gender alc_mod alc_heavy 0.8460095 0.8225761 0.7806940 7.028837
## 171 5                bcs pindex enzyme_test gender alc_heavy 0.8374622 0.8205312 0.7827597 5.528174
## 248 7 bcs pindex enzyme_test liver_test age gender alc_heavy 0.8436412 0.8198474 0.7749807 7.721367
## 169 5                   bcs pindex enzyme_test age alc_heavy 0.8358522 0.8187535 0.7862369 5.998959
##           aic       sbc
## 226 -8.612898  7.298974
## 251 -7.497389 10.403468
## 171 -8.580332  5.342556
## 248 -6.673207 11.227649
## 169 -8.048073  5.874815</code></pre>
<p>Basándonos en este criterio el mejor ajuste se obtiene considerando las covariables <code>bcs</code>, <code>pindex</code>, <code>enzyme_test</code>, <code>age</code>, <code>gender</code>, y <code>alc_heavy</code>. Es decir, eliminando las covariables función hepática y consumo de alcohol moderado. Note que no todos los demás críterios sugieren el mismo modelo. Si eliminamos las covariables <code>gender</code> obtenemos un modelo con un <span class="math inline">\(R^{2}_{pred}\)</span> más alto.</p>
<p>Ahora, si nos apoyamos en el AIC, los mejores 5 ajustes son:</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="selección-de-variables.html#cb78-1" aria-hidden="true" tabindex="-1"></a>AIC.order <span class="ot">=</span> <span class="fu">order</span>(surgical.all.mods<span class="sc">$</span>aic,<span class="at">decreasing =</span> F)</span>
<span id="cb78-2"><a href="selección-de-variables.html#cb78-2" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.frame</span>(surgical.all.mods)[AIC.order[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>],<span class="fu">c</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">8</span>,<span class="dv">10</span>)]</span></code></pre></div>
<pre><code>##     n                                          predictors   rsquare      adjr   predrsq       cp       aic
## 226 6         bcs pindex enzyme_test age gender alc_heavy 0.8434664 0.8234834 0.7836037 5.772458 -8.612898
## 171 5             bcs pindex enzyme_test gender alc_heavy 0.8374622 0.8205312 0.7827597 5.528174 -8.580332
## 97  4                    bcs pindex enzyme_test alc_heavy 0.8299187 0.8160345 0.7862922 5.733992 -8.130569
## 169 5                bcs pindex enzyme_test age alc_heavy 0.8358522 0.8187535 0.7862369 5.998959 -8.048073
## 251 7 bcs pindex enzyme_test age gender alc_mod alc_heavy 0.8460095 0.8225761 0.7806940 7.028837 -7.497389
##           sbc
## 226  7.298974
## 171  5.342556
## 97   3.803335
## 169  5.874815
## 251 10.403468</code></pre>
<p>Con este críterio se escoge el mismo modelo que con el <span class="math inline">\(R^{2}_{adj}\)</span>. Sin embargo, podemos observar que el BIC sugiere eliminar la covariable asociada a la edad.</p>
<p>En la Figura <a href="#fig:surgicalAll"><strong>??</strong></a> muestra los <span class="math inline">\(R^{2}\)</span>,<span class="math inline">\(R^{2}_{adj}\)</span>, <span class="math inline">\(R^{2}_{pred}\)</span>,C<span class="math inline">\(_p\)</span>, AIC y BIC (SBC) para todos los posibles ajustes. Note que, dentro de cada subgrupo de modelos (determinado por el número de covariables), los criterios eligen los modelos en el mismo orden. La diferencia está en el número de covariables a elegir. Generalmente, el BIC prefiere modelos más parsimoniosos. Esto no ocurre con criterios de validación cruzada, como el PRESS o <span class="math inline">\(R^{2}_{pred}\)</span>.</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="selección-de-variables.html#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb80-2"><a href="selección-de-variables.html#cb80-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(surgical.all.mods)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:surgicalAll-1"></span>
<img src="MLG2_files/figure-html/surgicalAll-1.png" alt="Valores de los criterios de selección calculados para cada uno de todos los posibles modelos." width="672" />
<p class="caption">
Figure 4.1: Valores de los criterios de selección calculados para cada uno de todos los posibles modelos.
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:surgicalAll-2"></span>
<img src="MLG2_files/figure-html/surgicalAll-2.png" alt="Valores de los criterios de selección calculados para cada uno de todos los posibles modelos." width="672" />
<p class="caption">
Figure 4.2: Valores de los criterios de selección calculados para cada uno de todos los posibles modelos.
</p>
</div>
<p>Teniendo en cuenta esto, con la función <code>ols_step_best_subset()</code> selecciona el mejor modelo para cada subconjunto de número de covariables basándose en los diferentes criterios:</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="selección-de-variables.html#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ols_step_best_subset</span>(mod.surgical.completo)</span></code></pre></div>
<pre><code>##                            Best Subsets Regression                           
## -----------------------------------------------------------------------------
## Model Index    Predictors
## -----------------------------------------------------------------------------
##      1         enzyme_test                                                    
##      2         pindex enzyme_test                                             
##      3         pindex enzyme_test alc_heavy                                   
##      4         bcs pindex enzyme_test alc_heavy                               
##      5         bcs pindex enzyme_test gender alc_heavy                        
##      6         bcs pindex enzyme_test age gender alc_heavy                    
##      7         bcs pindex enzyme_test age gender alc_mod alc_heavy            
##      8         bcs pindex enzyme_test liver_test age gender alc_mod alc_heavy 
## -----------------------------------------------------------------------------
## 
##                                                    Subsets Regression Summary                                                   
## --------------------------------------------------------------------------------------------------------------------------------
##                        Adj.        Pred                                                                                          
## Model    R-Square    R-Square    R-Square      C(p)        AIC        SBIC         SBC       MSEP      FPE       HSP       APC  
## --------------------------------------------------------------------------------------------------------------------------------
##   1        0.4273      0.4162      0.3496    117.4783    51.4343    -105.4395    57.4013    7.6160    0.1463    0.0028    0.6168 
##   2        0.6632      0.6500      0.6044     50.4918    24.7668    -131.5971    32.7228    4.5684    0.0893    0.0017    0.3765 
##   3        0.7780      0.7647      0.7291     18.9015     4.2432    -150.4023    14.1881    3.0718    0.0610    0.0012    0.2575 
##   4        0.8299      0.8160      0.7863      5.7340    -8.1306    -160.5329     3.8033    2.4030    0.0486     9e-04    0.2048 
##   5        0.8375      0.8205      0.7828      5.5282    -8.5803    -160.2288     5.3426    2.3453    0.0482     9e-04    0.2032 
##   6        0.8435      0.8235      0.7836      5.7725    -8.6129    -159.4064     7.2990    2.3077    0.0482     9e-04    0.2032 
##   7        0.8460      0.8226      0.7807      7.0288    -7.4974    -157.6344    10.4035    2.3207    0.0492    0.0010    0.2076 
##   8        0.8461      0.8187      0.7711      9.0000    -5.5320    -155.2573    14.3579    2.3719    0.0511    0.0010    0.2154 
## --------------------------------------------------------------------------------------------------------------------------------
## AIC: Akaike Information Criteria 
##  SBIC: Sawa&#39;s Bayesian Information Criteria 
##  SBC: Schwarz Bayesian Criteria 
##  MSEP: Estimated error of prediction, assuming multivariate normality 
##  FPE: Final Prediction Error 
##  HSP: Hocking&#39;s Sp 
##  APC: Amemiya Prediction Criteria</code></pre>
<p>A partir de estos resultados, y con la ayuda de expertos en el tema, se puede hacer una selección del mejor modelo para hacer las predicciónes.</p>
</div>
</div>
<div id="algorítmos-de-selección" class="section level3 hasAnchor" number="4.4.2">
<h3><span class="header-section-number">4.4.2</span> Algorítmos de selección<a href="selección-de-variables.html#algorítmos-de-selección" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para el proceso de selección, la mejor opción es evaluar todos los posibles modelos. Sin embargo, en la presencia de muchas posibles covariables este proceso puede requerir una carga computacional muy alta. Por esta razón, se han desarrollado varios algoritmos para evaluar solo un subconjunto de modelos agregando o eliminando covariables una a la vez.</p>
<div id="selección-hacia-delante-forward-selection" class="section level4 hasAnchor" number="4.4.2.1">
<h4><span class="header-section-number">4.4.2.1</span> Selección hacia delante (forward selection)<a href="selección-de-variables.html#selección-hacia-delante-forward-selection" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Este algoritmo parte del modelo sin ninguna covariable (es decir, solo el intercepto) y el ajuste ``óptimo’’ se encuentra ingresando covariables una a la vez basándose en algún criterio (por ejemplo AIC).</p>
<p>La primera covariable se escoge luego de ajustar los <span class="math inline">\((p-1)\)</span> modelos simples con cada uno de los regresores. Por ejemplo, seleccionado la covariable que proporciona el mejor AIC.</p>
<p>Luego se ajustan los modelos combinando la covariable previamente seleccionada con cada una de los restantes <span class="math inline">\((p-2)\)</span> regresores. Si el mejor ajuste con dos covariables proporcina un menor AIC que en el paso anterior, continuamos seleccionando la tercer covariable de la misma forma.</p>
<p>El algoritmo continua seleccionando covariables hasta que se satisface un criterio de parada (por ejemplo, hasta que el AIC aumente).</p>
</div>
<div id="selección-hacia-atrás-backward-selection" class="section level4 hasAnchor" number="4.4.2.2">
<h4><span class="header-section-number">4.4.2.2</span> Selección hacia atrás (backward selection)<a href="selección-de-variables.html#selección-hacia-atrás-backward-selection" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Aquí se empieza evaluando el modelo con todas las covariables candidatas y se van eliminando covariables una a una hasta que un criterio de parada se satisface (por ejemplo, hasta que el AIC aumenta).</p>
</div>
<div id="selección-por-segmentos-stepwise-selection" class="section level4 hasAnchor" number="4.4.2.3">
<h4><span class="header-section-number">4.4.2.3</span> Selección por segmentos (stepwise selection)<a href="selección-de-variables.html#selección-por-segmentos-stepwise-selection" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Aquí se siguen los mismos pasos que la selección hacia delante. Pero en cada paso se evalúan de nuevo los candidatos que ya habían ingresado en el modelo. Por lo tanto, una covariable que ya esté en el modelo puede ser eliminada en algún paso posterior.</p>
</div>
<div id="unidad-quirúrgica-1" class="section level4 hasAnchor" number="4.4.2.4">
<h4><span class="header-section-number">4.4.2.4</span> Unidad quirúrgica<a href="selección-de-variables.html#unidad-quirúrgica-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Consideremos el modelo anterior adicionando las interacciones de las covariables continuas con las categóricas:
<span class="math display">\[\begin{equation}
\begin{split}
\log y_{i} =&amp; \beta_{0}+\mbox{bcs}_{i}\beta_{1} + \mbox{pindex}_{i}\beta_{2}+ \mbox{enzyme}_{i}\beta_{3} +  \mbox{liver}_{i}\beta_{4} + \mbox{age}_{i}\beta_{5} +  \mbox{gender}_{i}\beta_{6}+ \mbox{alc_mod}_{i}\beta_{7} + \\ &amp;  \mbox{alc_heavy}_{i}\beta_{8} \mbox{bcs}_{i}\mbox{gender}_{i}\beta_{9} + \mbox{pindex}_{i}\mbox{gender}_{i}\beta_{10} + \mbox{enzyme}_{i}\mbox{gender}_{i}\beta_{11} + \mbox{liver}_{i}\mbox{gender}_{i}\beta_{12}  + \\ &amp; \mbox{age}_{i}\mbox{gender}_{i}\beta_{13} + \mbox{bcs}_{i}\mbox{alc_mod}_{i}\beta_{14} + \mbox{pindex}_{i}\mbox{alc_mod}_{i}\beta_{15} + \mbox{enzyme}_{i}\mbox{alc_mod}_{i}\beta_{16} +  \\ &amp; \mbox{liver}_{i}\mbox{alc_mod}_{i}\beta_{17} + \mbox{age}_{i}\mbox{alc_mod}_{i}\beta_{18} + \mbox{bcs}_{i}\mbox{alc_heavy}_{i}\beta_{19} + \mbox{pindex}_{i}\mbox{alc_heavy}_{i}\beta_{20} + \\ &amp; \mbox{enzyme}_{i}\mbox{alc_heavy}_{i}\beta_{21} + \mbox{liver}_{i}\mbox{alc_heavy}_{i}\beta_{22} + \mbox{age}_{i}\mbox{alc_heavy}_{i}\beta_{23} + \varepsilon_{i}.
\end{split}
\nonumber
\end{equation}\]</span>
En este caso tenemos <span class="math inline">\(2^{23}=8&#39;388,608\)</span> posibles modelos. Lo que hace que sea difícil ajustarlos todos (aunque es posible usando la librería <code>leaps</code>). Por lo tanto, vamos a utilizar los algortimos de selección.</p>
<p><strong>Selección hacia delante</strong>. Podemos utilizar la función <code>ols_step_forward_aic</code> de la librería <code>olsrr</code>:</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="selección-de-variables.html#cb83-1" aria-hidden="true" tabindex="-1"></a>mod.surgical.completo2 <span class="ot">=</span> <span class="fu">lm</span>(<span class="fu">log</span>(y)<span class="sc">~</span>bcs<span class="sc">*</span>gender<span class="sc">+</span>pindex<span class="sc">*</span>gender<span class="sc">+</span>enzyme_test<span class="sc">*</span>gender<span class="sc">+</span>liver_test<span class="sc">*</span>gender<span class="sc">+</span>age<span class="sc">*</span>gender<span class="sc">+</span> bcs<span class="sc">*</span>alc_mod<span class="sc">+</span>pindex<span class="sc">*</span>alc_mod<span class="sc">+</span>enzyme_test<span class="sc">*</span>alc_mod<span class="sc">+</span>liver_test<span class="sc">*</span>alc_mod<span class="sc">+</span>age<span class="sc">*</span>alc_mod<span class="sc">+</span>bcs<span class="sc">*</span>alc_heavy<span class="sc">+</span>pindex<span class="sc">*</span>alc_heavy<span class="sc">+</span>enzyme_test<span class="sc">*</span>alc_heavy<span class="sc">+</span>liver_test<span class="sc">*</span>alc_heavy<span class="sc">+</span>age<span class="sc">*</span>alc_heavy,<span class="at">data=</span>surgical)</span>
<span id="cb83-2"><a href="selección-de-variables.html#cb83-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ols_step_forward_aic</span>(mod.surgical.completo2,<span class="at">details =</span> F)</span></code></pre></div>
<pre><code>## 
##                            Selection Summary                             
## ------------------------------------------------------------------------
## Variable                AIC      Sum Sq     RSS      R-Sq      Adj. R-Sq 
## ------------------------------------------------------------------------
## enzyme_test            51.434     5.471    7.334    0.42725      0.41624 
## pindex                 24.767     8.492    4.313    0.66318      0.64997 
## bcs:alc_heavy          -3.014    10.320    2.485    0.80596      0.79432 
## bcs                    -9.430    10.678    2.126    0.83396      0.82041 
## gender:pindex         -10.781    10.806    1.998    0.84395      0.82770 
## gender:enzyme_test    -19.676    11.171    1.633    0.87246      0.85618 
## gender                -23.040    11.326    1.479    0.88452      0.86695 
## age                   -24.081    11.407    1.398    0.89085      0.87144 
## ------------------------------------------------------------------------</code></pre>
<p>Con el argumento <code>details = T</code> se puede ver la selección con más detalle. Usando este algoritmo el modelo óptimo es:
<span class="math display">\[\begin{equation}
\begin{split}
\log y_{i} =&amp; \beta_{0} + \mbox{bcs}_{i}\beta_{1} + \mbox{pindex}_{i}\beta_{2} + \mbox{enzyme}_{i}\beta_{3} + \mbox{age}_{i}\beta_{4} + \mbox{gender}_{i}\beta_{5} + \\
&amp;\mbox{gender}_{i}\mbox{pindex}_{i}\beta_{6} + \mbox{gender}_{i}\mbox{enzyme}_{i}\beta_{7} + \mbox{bcs}_{i}\mbox{alc_heavy}_{i}\beta_{8} + \varepsilon_{i}.
\end{split}
\nonumber
\end{equation}\]</span></p>
<p><strong>Selección hacia atrás</strong>. Podemos utilizar la función <code>ols_step_backward_aic</code> de la librería <code>olsrr</code>:</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="selección-de-variables.html#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ols_step_backward_aic</span>(mod.surgical.completo2,<span class="at">details =</span> F)</span></code></pre></div>
<pre><code>## 
## 
##                         Backward Elimination Summary                         
## ---------------------------------------------------------------------------
## Variable                   AIC       RSS     Sum Sq     R-Sq      Adj. R-Sq 
## ---------------------------------------------------------------------------
## Full Model                -9.135    1.058    11.747    0.91740      0.85408 
## age:alc_heavy            -11.134    1.058    11.747    0.91740      0.85878 
## alc_heavy                -13.133    1.058    11.747    0.91740      0.86319 
## bcs:alc_mod              -15.057    1.059    11.745    0.91728      0.86715 
## age:alc_mod              -16.852    1.063    11.741    0.91697      0.87057 
## gender:pindex            -18.639    1.067    11.737    0.91664      0.87377 
## alc_mod                  -19.980    1.080    11.724    0.91562      0.87577 
## enzyme_test:alc_heavy    -20.698    1.106    11.698    0.91359      0.87622 
## liver_test:alc_heavy     -20.988    1.142    11.662    0.91081      0.87560 
## pindex:alc_heavy         -22.223    1.158    11.646    0.90954      0.87706 
## pindex:alc_mod           -22.957    1.186    11.619    0.90739      0.87729 
## bcs:gender               -22.981    1.230    11.575    0.90394      0.87583 
## gender:age               -23.038    1.275    11.529    0.90042      0.87434 
## gender:liver_test        -23.549    1.311    11.494    0.89764      0.87383 
## age                      -23.745    1.355    11.449    0.89416      0.87251 
## ---------------------------------------------------------------------------</code></pre>
<p>Por lo tanto, el modelo seleccionado es:
<span class="math display">\[\begin{equation}
\begin{split}
\log y_{i} =&amp; \beta_{0} + \mbox{bcs}_{i}\beta_{1} + \mbox{pindex}_{i}\beta_{2} + \mbox{enzyme}_{i}\beta_{3} + \mbox{gender}_{i}\beta_{4} + \mbox{liver}_{i}\beta_{5} + \\
&amp; \mbox{gender}_{i}\mbox{enzyme}_{i}\beta_{6} + \mbox{enzyme}_{i}\mbox{alc_mod}_{i}\beta_{7} + \mbox{liver}_{i}\mbox{alc_mod}_{i}\beta_{8} + \mbox{liver}_{i}\mbox{gender}_{i}\beta_{9} + \varepsilon_{i}.
\end{split}
\nonumber
\end{equation}\]</span>
Con este algoritmo no se considera la edad del paciente pero si la función hepática y otras interacciones.</p>
<p><strong>Selección por segmentos</strong>. Aquí tenemos la función <code>ols_step_both_aic</code> de la librería <code>olsrr</code>:</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="selección-de-variables.html#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ols_step_both_aic</span>(mod.surgical.completo2,<span class="at">details =</span> F)</span></code></pre></div>
<pre><code>## 
## 
##                                    Stepwise Summary                                   
## ------------------------------------------------------------------------------------
## Variable               Method       AIC       RSS     Sum Sq     R-Sq      Adj. R-Sq 
## ------------------------------------------------------------------------------------
## enzyme_test           addition     51.434    7.334     5.471    0.42725      0.41624 
## pindex                addition     24.767    4.313     8.492    0.66318      0.64997 
## bcs:alc_heavy         addition     -3.014    2.485    10.320    0.80596      0.79432 
## bcs                   addition     -9.430    2.126    10.678    0.83396      0.82041 
## gender:pindex         addition    -10.781    1.998    10.806    0.84395      0.82770 
## gender:enzyme_test    addition    -19.676    1.633    11.171    0.87246      0.85618 
## gender                addition    -23.040    1.479    11.326    0.88452      0.86695 
## gender:pindex         removal     -23.631    1.518    11.287    0.88147      0.86634 
## age                   addition    -25.088    1.424    11.381    0.88882      0.87190 
## ------------------------------------------------------------------------------------</code></pre>
<p>Note que este método sigue los mismos pasos que la selección hacia delante hasta el paso 8 donde se elimina la interacción entre el índice de pronostico y el genero. Por lo que aquí obtenemos el siguiente modelo:</p>
<p><span class="math display">\[\begin{equation}
\begin{split}
\log y_{i} =&amp; \beta_{0} + \mbox{bcs}_{i}\beta_{1} + \mbox{pindex}_{i}\beta_{2} + \mbox{enzyme}_{i}\beta_{3} + \mbox{age}_{i}\beta_{4} + \mbox{gender}_{i}\beta_{5} + \\
&amp; \mbox{gender}_{i}\mbox{enzyme}_{i}\beta_{6} + \mbox{bcs}_{i}\mbox{alc_heavy}_{i}\beta_{7} + \varepsilon_{i}.
\end{split}
\nonumber
\end{equation}\]</span></p>
<p>Dado que los algoritmos hacen la busqueda del modelo “óptimo” evaluando diferentes subconjuntos de covariables, se obtuvieron diferentes ajustes. Si observamos el AIC de las tres opciones, el modelo obtenido con el algoritmo stepwise presenta el mejor resultado.</p>
</div>
</div>
</div>
<div id="regresión-de-lasso" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> Regresión de LASSO<a href="selección-de-variables.html#regresión-de-lasso" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Otra alternativa para encontrar las variables relevantes es a través del estimador de LASSO (Least Absolute Selection and Shrinkage Operator). Este es un método de regularización que se implementa se tiene cientos de covariables disponibles y se cree que pocas tienen un aporte relevante (<em>sparsity principle</em>). Por ejemplo, en estudios de genetica se tienen miles de genes disponibles pero solo unos pocos son activos para una mutación de interés.</p>
<p>Aquí se asume el modelo de regresión usual, donde:
<span class="math display">\[
E(y | \boldsymbol x) = \boldsymbol x&#39;\boldsymbol \beta, \mbox{ y } V(y | \boldsymbol x) = \sigma^2,
\]</span>
pero muchos de los elementos de <span class="math inline">\(\boldsymbol \beta\)</span> son iguales a cero. El objetivo del estimador de LASSO seleccionar los coeficientes que tienen valores diferentes de cero. Esto se obtiene minimizando la siguiente expresión:</p>
<p><span class="math display" id="eq:SSLASSO">\[\begin{equation}
S_{lasso}(\beta)= \sum_{i=1}^{n}(y_{i}-x_{i}&#39;\boldsymbol \beta)^{2}+ \lambda\sum_{j=1}^{p-1}|\beta_{j}|,
\tag{4.3}
\end{equation}\]</span>
con <span class="math inline">\(\lambda \geq 0\)</span>. Note que <a href="selección-de-variables.html#eq:SSLASSO">(4.3)</a> es la suma de cuadrados del estimador por MCO más una penalización (dada por <span class="math inline">\(\lambda\)</span>) a la suma del valor absoluto de los coeficientes (exceptuando el intercepto). Si <span class="math inline">\(\lambda=0\)</span>, se obtiene el estimador por MCO. A medida que <span class="math inline">\(\lambda\)</span> aumenta la penalización tendrá mas peso sobre la estimación de los coeficientes. Por lo que si este parámetro es suficientemente grande, todas las estimaciones serán iguales a cero (con excepción del intercepto). También se puede probar que, cuando <span class="math inline">\(\lambda \rightarrow \infty\)</span>, la varianza de <span class="math inline">\(\widehat{\boldsymbol \beta}_{LASSO}\)</span> disminuye, pero el sesgo aumenta.</p>
<p>De forma de equivalente, el estimador de LASSO minimiza:</p>
<p><span class="math display">\[
\sum_{i=1}^{n}(y_{i}-x_{i}^{′}\boldsymbol \beta)^{2} \quad \mbox{ sujeto a } \quad
\sum_{j=1}^{p-1}|\beta_{j} | \leq t.
\]</span></p>
<p>Mientras que, en la regresión de ridge minimiza:</p>
<p><span class="math display">\[
\sum_{i=1}^{n}(y_{i}-x_{i}^{′}\boldsymbol \beta)^{2} \quad \mbox{ sujeto a } \quad
\sum_{j=1}^{p-1}\beta_{j}^2\leq t.
\]</span></p>
<p>La Figura <a href="selección-de-variables.html#fig:LASSOrest">4.3</a> muestra como intervienen las restricciones del estimador de LASSO (izquierda) y ridge (derecha) en un modelo con dos covariables. Los contornos muestras la suma de cuadrado de los errores, mientras que, las restricciones están dadas por el diamante <span class="math inline">\((|\beta_1|+|\beta_2| \leq t)\)</span> y la circunferencia <span class="math inline">\((\beta_1^2+\beta_2^2 \leq t)\)</span> rojas para el estimador LASSO y ridge, respectivamente. La solución de ambos estimadores se encuentra en el punto donde el contorno elíptico intercepta la región de la restricción. Para la regresión LASSO, si la solución ocurre en una esquina, entonces la estimación del parámetro es igual a cero.</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="selección-de-variables.html#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mnormt)</span>
<span id="cb89-2"><a href="selección-de-variables.html#cb89-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">4</span>,<span class="at">length.out=</span><span class="dv">200</span>)</span>
<span id="cb89-3"><a href="selección-de-variables.html#cb89-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">5</span>,<span class="at">length.out=</span><span class="dv">200</span>)</span>
<span id="cb89-4"><a href="selección-de-variables.html#cb89-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-5"><a href="selección-de-variables.html#cb89-5" aria-hidden="true" tabindex="-1"></a>mu    <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">1.5</span>, <span class="dv">3</span>)</span>
<span id="cb89-6"><a href="selección-de-variables.html#cb89-6" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="fl">0.6</span>, <span class="fl">0.6</span>, <span class="dv">1</span>), <span class="at">nrow =</span> <span class="dv">2</span>)</span>
<span id="cb89-7"><a href="selección-de-variables.html#cb89-7" aria-hidden="true" tabindex="-1"></a>f     <span class="ot">&lt;-</span> <span class="cf">function</span>(x, y) <span class="fu">dmnorm</span>(<span class="fu">cbind</span>(x, y), mu, sigma)</span>
<span id="cb89-8"><a href="selección-de-variables.html#cb89-8" aria-hidden="true" tabindex="-1"></a>z     <span class="ot">&lt;-</span> <span class="fu">outer</span>(x, y, f)</span>
<span id="cb89-9"><a href="selección-de-variables.html#cb89-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-10"><a href="selección-de-variables.html#cb89-10" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb89-11"><a href="selección-de-variables.html#cb89-11" aria-hidden="true" tabindex="-1"></a><span class="fu">contour</span>(x, y, z,<span class="at">nlevels=</span><span class="dv">4</span>,<span class="at">drawlabels=</span>F,<span class="at">xaxt=</span><span class="st">&#39;n&#39;</span>,<span class="at">yaxt=</span><span class="st">&#39;n&#39;</span>,<span class="at">asp=</span><span class="dv">1</span>,<span class="at">xlab=</span><span class="fu">expression</span>(beta[<span class="dv">1</span>]),<span class="at">ylab=</span><span class="fu">expression</span>(beta[<span class="dv">2</span>]))</span>
<span id="cb89-12"><a href="selección-de-variables.html#cb89-12" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="dv">0</span>)</span>
<span id="cb89-13"><a href="selección-de-variables.html#cb89-13" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="dv">0</span>)</span>
<span id="cb89-14"><a href="selección-de-variables.html#cb89-14" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> <span class="fl">1.511</span></span>
<span id="cb89-15"><a href="selección-de-variables.html#cb89-15" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(a<span class="sc">*</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="sc">-</span><span class="dv">1</span>),a<span class="sc">*</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="sc">-</span><span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>),<span class="at">col=</span><span class="dv">2</span>)</span>
<span id="cb89-16"><a href="selección-de-variables.html#cb89-16" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">1.5</span>,<span class="dv">3</span>,<span class="at">label=</span><span class="fu">expression</span>(<span class="fu">hat</span>(beta)[mco]),<span class="at">cex=</span><span class="fl">0.8</span>)</span>
<span id="cb89-17"><a href="selección-de-variables.html#cb89-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-18"><a href="selección-de-variables.html#cb89-18" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="dv">0</span>,a,<span class="at">label=</span><span class="st">&#39;t&#39;</span>,<span class="at">cex=</span><span class="fl">0.7</span>,<span class="at">pos=</span><span class="dv">2</span>)</span>
<span id="cb89-19"><a href="selección-de-variables.html#cb89-19" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(a,<span class="dv">0</span>,<span class="at">label=</span><span class="st">&#39;t&#39;</span>,<span class="at">cex=</span><span class="fl">0.7</span>,<span class="at">pos=</span><span class="dv">3</span>)</span>
<span id="cb89-20"><a href="selección-de-variables.html#cb89-20" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="at">x=</span><span class="dv">0</span>, <span class="at">y=</span>a,<span class="at">pch=</span><span class="dv">19</span>,<span class="at">col=</span><span class="dv">2</span>)</span>
<span id="cb89-21"><a href="selección-de-variables.html#cb89-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-22"><a href="selección-de-variables.html#cb89-22" aria-hidden="true" tabindex="-1"></a><span class="fu">contour</span>(x, y, z,<span class="at">nlevels=</span><span class="dv">4</span>,<span class="at">drawlabels=</span>F,<span class="at">asp=</span><span class="dv">1</span>,<span class="at">xaxt=</span><span class="st">&#39;n&#39;</span>,<span class="at">yaxt=</span><span class="st">&#39;n&#39;</span>,<span class="at">xlab=</span><span class="fu">expression</span>(beta[<span class="dv">1</span>]),<span class="at">ylab=</span><span class="fu">expression</span>(beta[<span class="dv">2</span>]))</span>
<span id="cb89-23"><a href="selección-de-variables.html#cb89-23" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">1.5</span>,<span class="dv">3</span>,<span class="at">label=</span><span class="fu">expression</span>(<span class="fu">hat</span>(beta)[mco]),<span class="at">cex=</span><span class="fl">0.8</span>)</span>
<span id="cb89-24"><a href="selección-de-variables.html#cb89-24" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="dv">0</span>)</span>
<span id="cb89-25"><a href="selección-de-variables.html#cb89-25" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="dv">0</span>)</span>
<span id="cb89-26"><a href="selección-de-variables.html#cb89-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-27"><a href="selección-de-variables.html#cb89-27" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> <span class="fl">1.391</span></span>
<span id="cb89-28"><a href="selección-de-variables.html#cb89-28" aria-hidden="true" tabindex="-1"></a><span class="fu">draw.circle</span>(<span class="dv">0</span>, <span class="dv">0</span>, a,<span class="at">border=</span><span class="dv">2</span>)</span>
<span id="cb89-29"><a href="selección-de-variables.html#cb89-29" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="at">x=</span><span class="fl">0.3</span>, <span class="at">y=</span><span class="fl">1.35</span>,<span class="at">pch=</span><span class="dv">19</span>,<span class="at">col=</span><span class="dv">2</span>)</span>
<span id="cb89-30"><a href="selección-de-variables.html#cb89-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-31"><a href="selección-de-variables.html#cb89-31" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="dv">0</span>,a,<span class="at">label=</span><span class="st">&#39;t&#39;</span>,<span class="at">cex=</span><span class="fl">0.7</span>,<span class="at">pos=</span><span class="fl">2.5</span>)</span>
<span id="cb89-32"><a href="selección-de-variables.html#cb89-32" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(a,<span class="dv">0</span>,<span class="at">label=</span><span class="st">&#39;t&#39;</span>,<span class="at">cex=</span><span class="fl">0.7</span>,<span class="at">pos=</span><span class="dv">4</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:LASSOrest"></span>
<img src="MLG2_files/figure-html/LASSOrest-1.png" alt="Estimación del estimador de LASSO (izquierda) y ridge (derecha). Las elipses rojas son los contornos de la suma de cuadrados de los errores. Mientras que, la región roja son las restricciones para cada estimador)." width="864" />
<p class="caption">
Figure 4.3: Estimación del estimador de LASSO (izquierda) y ridge (derecha). Las elipses rojas son los contornos de la suma de cuadrados de los errores. Mientras que, la región roja son las restricciones para cada estimador).
</p>
</div>
<p>Dado que <a href="selección-de-variables.html#eq:SSLASSO">(4.3)</a> es una función no lineal en <span class="math inline">\(y\)</span>, no hay solución análitica para <span class="math inline">\(\widehat{\boldsymbol \beta}_{LASSO}\)</span>. Sin embargo, pero hay algoritmos eficientes para su estimación. De igual forma, se recomienda escalar las variables para remover el efecto de las unidades de medida.</p>
<p>En R, la estimación del modelo por medio del estimador de LASSO se hace por medio de la función <code>glmnet</code> de la librería <code>glmnet</code>.</p>
<div id="datos-de-grasa-corporal-1" class="section level3 hasAnchor" number="4.5.1">
<h3><span class="header-section-number">4.5.1</span> Datos de grasa corporal<a href="selección-de-variables.html#datos-de-grasa-corporal-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La estimación de los coeficientes de regresión del modelo <a href="selección-de-variables.html#eq:modeloFat">(4.1)</a> por medio del estimador de LASSO para diferentes valores de <span class="math inline">\(\lambda\)</span> se puede observar en la Figura <a href="selección-de-variables.html#fig:Vgrasalasso">4.4</a>. Se puede observar que a medida que <span class="math inline">\(\lambda\)</span> aumenta, mas coeficientes de regresión son iguales a cero.</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="selección-de-variables.html#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co">#se debe especificar alpha=1</span></span>
<span id="cb90-2"><a href="selección-de-variables.html#cb90-2" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">model.matrix</span>(mod.fat)[,<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb90-3"><a href="selección-de-variables.html#cb90-3" aria-hidden="true" tabindex="-1"></a>lasso.mod <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X, fat<span class="sc">$</span>brozek, <span class="at">alpha =</span> <span class="dv">1</span>,<span class="at">nlambda =</span> <span class="dv">100</span>)</span>
<span id="cb90-4"><a href="selección-de-variables.html#cb90-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lasso.mod,<span class="at">xvar=</span><span class="st">&#39;lambda&#39;</span>,<span class="at">label=</span>T,<span class="at">lwd=</span><span class="dv">2</span>,<span class="at">ylab=</span><span class="st">&#39;coeficientes de regresión&#39;</span>)</span>
<span id="cb90-5"><a href="selección-de-variables.html#cb90-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="dv">0</span>,<span class="at">lty=</span><span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Vgrasalasso"></span>
<img src="MLG2_files/figure-html/Vgrasalasso-1.png" alt="Datos de grasa corporal. Estimación de los coeficientes de regresión vs el logaritmo de $\lambda$" width="768" />
<p class="caption">
Figure 4.4: Datos de grasa corporal. Estimación de los coeficientes de regresión vs el logaritmo de <span class="math inline">\(\lambda\)</span>
</p>
</div>
<p>La pregunta sería que valor de <span class="math inline">\(lambda\)</span> se debe seleccionar para determinar los coeficientes que son diferentes de cero. Una alternativa que tenemos para ello es por medio de validación cruzada.</p>
</div>
<div id="validación-cruzada" class="section level3 hasAnchor" number="4.5.2">
<h3><span class="header-section-number">4.5.2</span> Validación cruzada<a href="selección-de-variables.html#validación-cruzada" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La validación cruzada (CV) es un método general para evaluar que tan bueno es un modelo para predecir observaciones futuras de la población objetivo del estudio. La idea es dividir la muestra en dos grupos:</p>
<ul>
<li><strong>Entrenamiento:</strong> se usa para ajusta el modelo.</li>
<li><strong>Validación:</strong> se utiliza para validar el modelo ajustado.</li>
</ul>
<p>Para no perder información, en la CV se realiza en <span class="math inline">\(K\)</span> interaciones dividiendo los datos en <span class="math inline">\(K\)</span> subconjuntos. En cada iteración, uno de los subconjutos es utilizado como datos de validación y el resto de subgrupos <span class="math inline">\((K-1)\)</span> como datos de entrenamiento.</p>
<p>Para cada división,<span class="math inline">\(k = 1, . . . , K\)</span> , y para cada valor de <span class="math inline">\(\lambda\)</span>, se estima el modelo basado en la <strong>muestra de entrenamiento</strong>. Mientras que con cada <strong>muestra de validación</strong>, y para cada valor de <span class="math inline">\(\lambda\)</span>, se utiliza para calcular el error cuadrático medio:</p>
<p><span class="math display">\[
EMC_{k}(\lambda) = \sum_{i=1}^{n_k} \frac{[y_{i}^{(k)}-\boldsymbol x_{i}^{(k)}\widehat{\boldsymbol \beta}_{lasso}^{(k)}(\lambda)]^2}{n}           
\]</span></p>
<p>donde <span class="math inline">\(y_{i}^{(k)}\)</span> son las observaciones de la muestra de validación <span class="math inline">\(k\)</span>, y <span class="math inline">\(\widehat{\boldsymbol \beta}_{lasso}^{(k)}(\lambda)\)</span> es la estimación utilizando la muestra de entrenamiento <span class="math inline">\(k\)</span>. Finalmente, para cada <span class="math inline">\(\lambda\)</span>, se calcula:
<span class="math display">\[
CV(\lambda) = \frac{1}{K}\sum_{i=1}^{K}EMC_{k}(\lambda)              
\]</span>
y la desviación estándar:
<span class="math display">\[
SD(\lambda) = \sqrt{\sum_{i=1}^{K} \frac{[EMC_{k}(\lambda)-CV(\lambda)]^2}{K-1}}              
\]</span>
Luego, el valor de <span class="math inline">\(\lambda\)</span> seleccionado corresponde al valor que minimiza <span class="math inline">\(CV(\lambda)\)</span>:
<span class="math display">\[
\hat{\lambda}_{cv}=arg\quad mín_{\lambda}-CV(\lambda)
\]</span>
También, se puede aplicar la regla de una desviación estándar:</p>
<p><span class="math display">\[
\hat{\lambda}_{cv1sd}=máx \{\lambda:CV(\hat{\lambda})&lt;CV(\hat{\lambda}_{cv})+SD(\hat{\lambda}_{cv})\}
\]</span>
El segundo método es preferible dado que tiene en cuenta la variabilidad debida a la selección de las submuestras.</p>
</div>
<div id="ejemplo-grasa-corporal" class="section level3 hasAnchor" number="4.5.3">
<h3><span class="header-section-number">4.5.3</span> Ejemplo grasa corporal<a href="selección-de-variables.html#ejemplo-grasa-corporal" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La estimación de <span class="math inline">\(\lambda\)</span> por medio de CV se puede hacer con la función <code>cv.glmnet</code> determinando del número de subconjuntos con el argumento <code>nfolds</code>. Por ejemplo, si consideramos <span class="math inline">\(K=10\)</span>, se obtienen los siguientes resultados:</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="selección-de-variables.html#cb91-1" aria-hidden="true" tabindex="-1"></a>lasso.cv <span class="ot">&lt;-</span><span class="fu">cv.glmnet</span>(X, fat<span class="sc">$</span>brozek, <span class="at">nfolds =</span> <span class="dv">10</span>, <span class="at">alpha =</span> <span class="dv">1</span>,<span class="at">nlambda =</span> <span class="dv">100</span>)</span>
<span id="cb91-2"><a href="selección-de-variables.html#cb91-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lasso.cv)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:kgrasa"></span>
<img src="MLG2_files/figure-html/kgrasa-1.png" alt="Datos de grasa corporal. Valiación cruzada (puntos rojos) para diferentes valores de $\lambda$. Las lineas cortadas verticales representan los valores seleccionados para $\lambda$ por mínimo valores de CV y la regla de una desviación estándar." width="672" />
<p class="caption">
Figure 4.5: Datos de grasa corporal. Valiación cruzada (puntos rojos) para diferentes valores de <span class="math inline">\(\lambda\)</span>. Las lineas cortadas verticales representan los valores seleccionados para <span class="math inline">\(\lambda\)</span> por mínimo valores de CV y la regla de una desviación estándar.
</p>
</div>
<p>Las covariables seleccionadas al utlizar el estimador de LASSO con el <span class="math inline">\(\lambda\)</span> óptimo (regla una desviación estándar) son:</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="selección-de-variables.html#cb92-1" aria-hidden="true" tabindex="-1"></a>est <span class="ot">=</span> <span class="fu">glmnet</span>(X, fat<span class="sc">$</span>brozek, <span class="at">alpha =</span> <span class="dv">1</span>,<span class="at">lambda =</span> lasso.cv<span class="sc">$</span>lambda<span class="fl">.1</span>se)</span>
<span id="cb92-2"><a href="selección-de-variables.html#cb92-2" aria-hidden="true" tabindex="-1"></a>est<span class="sc">$</span>beta</span></code></pre></div>
<pre><code>## 13 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                  s0
## age      0.03109358
## weight   .         
## height  -0.14026654
## neck     .         
## chest    .         
## abdom    0.57022182
## hip      .         
## thigh    .         
## knee     .         
## ankle    .         
## biceps   .         
## forearm  .         
## wrist   -0.60977822</code></pre>
<p>La selección de variables por medio del estimador LASSO son <code>age</code>, <code>height</code>,<code>abdom</code> y <code>wrist</code>. Ahora ajustamos el modelo con estas variables por medio de MCO:</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="selección-de-variables.html#cb94-1" aria-hidden="true" tabindex="-1"></a>mod.lasso <span class="ot">=</span> <span class="fu">lm</span>(brozek <span class="sc">~</span> age<span class="sc">+</span>height<span class="sc">+</span>abdom<span class="sc">+</span>wrist,<span class="at">data=</span>fat)</span>
<span id="cb94-2"><a href="selección-de-variables.html#cb94-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod.lasso)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = brozek ~ age + height + abdom + wrist, data = fat)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -16.2571  -2.8824  -0.2919   3.0419   9.3464 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.24853    6.27849   0.040   0.9685    
## age          0.06707    0.02196   3.055   0.0025 ** 
## height      -0.16461    0.07821  -2.105   0.0363 *  
## abdom        0.67569    0.03120  21.654  &lt; 2e-16 ***
## wrist       -1.93709    0.38343  -5.052 8.51e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.118 on 247 degrees of freedom
## Multiple R-squared:  0.7223, Adjusted R-squared:  0.7178 
## F-statistic: 160.6 on 4 and 247 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Las covariables seleciondas en este modelo son todas significativas. Además, <span class="math inline">\(R^2=0.7223\)</span> y <span class="math inline">\(R^2_{adj}=0.7178\)</span>. Comparado con el modelo completeo, estás cantidades han disminuido ligeramente.</p>
<p>La Tabla <a href="selección-de-variables.html#tab:tablaEstFat1">4.1</a> muestra las estimaciones de los modelos ajustados utilizando diferentes métodos de selección de variables. En los tres modelos coinciden con la inclusión de la circunferencia del abdomen y de la muñeca. Las variables peso y estatura se encuentran en algunos de estos modelos, pero no de forma simultanea. Esto sugiere que proporcionan la misma información y no es necesario incluirlas juntas. Finalmente, se puede observar en la Tabla <a href="selección-de-variables.html#tab:tablaEstFat2">4.2</a> que los tres modelos proporcionan similar ajuste.</p>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:tablaEstFat1">Table 4.1: </span>datos de grasa corporal. Estimación de coeficientes de los modelos seleccionados
</caption>
<thead>
<tr>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="10">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Método de selección
</div>
</th>
</tr>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
AIC y PRESS
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
BIC
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
LASSO
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
Est
</th>
<th style="text-align:left;">
er. std.
</th>
<th style="text-align:left;">
valor-p
</th>
<th style="text-align:left;">
Est
</th>
<th style="text-align:left;">
er. std.
</th>
<th style="text-align:left;">
valor-p
</th>
<th style="text-align:left;">
Est
</th>
<th style="text-align:left;">
er. std.
</th>
<th style="text-align:left;">
valor-p
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
int.
</td>
<td style="text-align:left;">
-20.062
</td>
<td style="text-align:left;">
10.8465
</td>
<td style="text-align:left;">
0.0656
</td>
<td style="text-align:left;">
-31.297
</td>
<td style="text-align:left;">
6.7089
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
0.249
</td>
<td style="text-align:left;">
6.2785
</td>
<td style="text-align:left;">
0.9685
</td>
</tr>
<tr>
<td style="text-align:left;">
age
</td>
<td style="text-align:left;">
0.059
</td>
<td style="text-align:left;">
0.0285
</td>
<td style="text-align:left;">
0.0388
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
0.067
</td>
<td style="text-align:left;">
0.022
</td>
<td style="text-align:left;">
0.0025
</td>
</tr>
<tr>
<td style="text-align:left;">
weight
</td>
<td style="text-align:left;">
-0.084
</td>
<td style="text-align:left;">
0.037
</td>
<td style="text-align:left;">
0.0237
</td>
<td style="text-align:left;">
0.126
</td>
<td style="text-align:left;">
0.0229
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
height
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
-0.165
</td>
<td style="text-align:left;">
0.0782
</td>
<td style="text-align:left;">
0.0363
</td>
</tr>
<tr>
<td style="text-align:left;">
neck
</td>
<td style="text-align:left;">
-0.432
</td>
<td style="text-align:left;">
0.208
</td>
<td style="text-align:left;">
0.0389
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
abdom
</td>
<td style="text-align:left;">
0.877
</td>
<td style="text-align:left;">
0.0666
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
0.921
</td>
<td style="text-align:left;">
0.0519
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
0.676
</td>
<td style="text-align:left;">
0.0312
</td>
<td style="text-align:left;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
hip
</td>
<td style="text-align:left;">
-0.186
</td>
<td style="text-align:left;">
0.1282
</td>
<td style="text-align:left;">
0.1473
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
thigh
</td>
<td style="text-align:left;">
0.286
</td>
<td style="text-align:left;">
0.1195
</td>
<td style="text-align:left;">
0.1473
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
forearm
</td>
<td style="text-align:left;">
0.4825
</td>
<td style="text-align:left;">
0.1725
</td>
<td style="text-align:left;">
0.0056
</td>
<td style="text-align:left;">
0.446
</td>
<td style="text-align:left;">
0.1682
</td>
<td style="text-align:left;">
0.0085
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
wrist
</td>
<td style="text-align:left;">
-1.4049
</td>
<td style="text-align:left;">
0.4717
</td>
<td style="text-align:left;">
0.0032
</td>
<td style="text-align:left;">
-1.392
</td>
<td style="text-align:left;">
0.4099
</td>
<td style="text-align:left;">
8e-04
</td>
<td style="text-align:left;">
-1.937
</td>
<td style="text-align:left;">
0.3834
</td>
<td style="text-align:left;">
0
</td>
</tr>
</tbody>
</table>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:tablaEstFat2">Table 4.2: </span>datos de grasa corporal. Valores de los criterios de selección para los modelos seleccionados.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Modelo
</th>
<th style="text-align:right;">
<span class="math inline">\(R^2\)</span>
</th>
<th style="text-align:right;">
PRESS
</th>
<th style="text-align:right;">
AIC
</th>
<th style="text-align:right;">
BIC
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
AIC y PRESS
</td>
<td style="text-align:right;">
0.7467
</td>
<td style="text-align:right;">
4139.682
</td>
<td style="text-align:right;">
1420.225
</td>
<td style="text-align:right;">
1455.520
</td>
</tr>
<tr>
<td style="text-align:left;">
BIC
</td>
<td style="text-align:right;">
0.7351
</td>
<td style="text-align:right;">
4209.140
</td>
<td style="text-align:right;">
1423.471
</td>
<td style="text-align:right;">
1444.647
</td>
</tr>
<tr>
<td style="text-align:left;">
LASSO
</td>
<td style="text-align:right;">
0.7223
</td>
<td style="text-align:right;">
4447.052
</td>
<td style="text-align:right;">
1435.389
</td>
<td style="text-align:right;">
1456.566
</td>
</tr>
</tbody>
</table>
<p>La selección del modelo más adecuado no solo debe depender de un análisis estadístico, sino también de la opinión de expertos en el tema.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multicolinealidad.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="modelos-no-lineales.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/AlvaroFlorez/MLG2/edit/master/04-SeleccionVariables.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/AlvaroFlorez/MLG2/blob/master/04-SeleccionVariables.Rmd",
"text": null
},
"download": ["MLG2.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
