# Modelos no lineales
```{r preamble5, include=FALSE}
library(alr4)
library(nlstools)
library(car)
data(turk0)
data(Puromycin)
```
## Ejemplos
### Crecimiento de pavos
Considere los datos de crecimiento de pavos (`data(turk0)`) de la librería `alr4`. A 60 corrales de pavos se les alimentó con una dieta similar, complementada con dosis de metionina diferente. Luego de un tiempo determnado, se observó el peso ganado por cada corral.

Las variables son:

- **```A```:** Cantidad de suplemento de metionina ( % de la dieta).
- **```Gain```:**  Peso medio ganado por corral (gramos) después de 3 semanas.

El objetivo del estudio es evaluar la metionina como suplemento alimenticio para pavos. En la Figura \@ref(fig:plotpavos) podemos observar que hay una relación positiva, a mayor cantidad de metionina, mayor peso ganado. Sin embargo, la relación no es lineal. Por lo que sería necesario hacer transformaciones sobre las variables o considerar modelos polinomiales para ajustar un modelo lineal a los datos. Otra alternativa es considerar modelos no lineales.


```{r plotpavos, include=TRUE,fig.align='center', fig.height = 5, fig.width = 8, fig.cap ="Datos pavos. Relación entre el peso ganado por corral y el % de metionina en la dieta."}
plot(Gain~A,data=turk0,xlab='cantidad de metionina (% dieta)',ylab='Peso ganado por corral (gramos)')
```
Para estos datos se puede considerar el siguiente modelo de crecimiento:
\[
E(Gain|A)=\theta_{1}+\theta_{2}[1-exp(-\theta_{3}A)]
\]
Dado que este modelo no es una combinación lineal de los parámetros, $\btheta = (\theta_1,\theta_2,\theta_3)$, se considera como un modelo lineal. Este modelo es comunmente utilizado para ajustar crecimiento dado que sus parámetros tienen interpretación: 

- Si $A=0$, entonces $E(Gain|A)=\theta_{1}$. Es decir, $\theta_{1}$ determina el peso ganado medio sin suplemento de metionina.
- Si $\theta_{3}>0$, $\theta_{1}+\theta_{2}$ es la asíntota. Es decir, la ganancia máxima de peso que se puede lograr.
- $\theta_{2}$ es el máximo crecimiento adicional debido al suplemento.
- $\theta_{3}$ representa la tasa de crecimiento. A valores de $\theta_3$ mas grandes, el crecimiento esperado se acerca a su máximo más rápidamente.

### Puromicina
Los datos `Puromycin` de la librería `datasets` contienen información de la reacción enzimática (qué tan rápido ésta cataliza la reacción que 
convierte un sustrato en producto) de 23 encimas, donde 12 de ellas fueron tratadas con Puromicina (un antibiótico). Las variables son:

- ```conc``` :concentración de sustrato (ppm).
- ```rate```:velocidad de reacción instantáneas (conteo/min2)
- ```state```:tratado y no tratado.

El objetivo es evaluar la velocidad de reacción y el efecto de la Puromicina. La relación de la velocidad de reacción en función de la concentración de sustraro se puede observar en la Figura \@ref(fig:plotpurom).

```{r plotpurom, include=TRUE,fig.align='center', fig.height = 5, fig.width = 8, fig.cap = "Daros Puromicina. Diagrama de dispersión: Relación entre la velocidad de reacción y la concentración de sustrato. Encimas tratadas(puntos negros), Encimas no tratadas(puntos rojos)"}
plot(Puromycin$conc,Puromycin$rate,col=Puromycin$state,
     xlab='concentración de sustrato (ppm)',
     ylab='velocidad de reacción')
```

Aquí vamos a considerar el modelo Michaelis-Menten (modelo comunmente utilizado en bioquímica):

\[
y_{i}=\frac{x_{1}\theta_{1}}{\theta_{2}+x_{1}}+\varepsilon_{i}.
\]
En este caso, $\theta_1$ es la asíntota. Es decir la velocidad de reacción máxima. Mientras que $\theta_2$ determina la concentración en la cual se obtiene la mitad de la velocidad máxima. Esto lo podemos observar en la Figura \@ref(fig:modMichMen).

```{r modMichMen, fig.align = 'center',out.width = "75%",echo=FALSE, fig.cap="Modelo Michaelis-Menten"}
knitr::include_graphics(here::here("figs", "Michaelis.jpg"))
```
Dado que se tienen células tratadas y no tratadas, se propone el siguiente modelo:
\[
rate_{i}=\frac{conc_{i}\theta_{1}+state_{i}conc_{i}\theta_{3}}
{\theta_{2}+state_{i}\theta_{3}+conc_{i}}+\varepsilon_{i}.
\]
Por lo que se tiene una curva diferente para las enzimas tratadas y no tratadas:

- Para enzimas no tratadas:

\[
E(rate_{i}|state=0)=\frac{conc_{i}\theta_{1}}{\theta_{2}+conc_{i}}.
\]

- Para enzimas tratadas:
\[
E(rate_{i}|state=1)=\frac{conc_{i}(\theta_{1}+\theta_{3})}{(\theta_{2}+\theta_{4})+conc_{i}}.
\]
Por lo que, $\theta_3$ determina la velocidad máxima entre las células tratadas y no las no tratadas. De igual forma, $\theta_{4}$ indica la diferencia en la concentración en la cual se obtiene la mitad de la velocidad máxima.

## Modelos no lineales
De forma general, en los modelos de regresión asumimos que:

\[
y_{i}=m(\bx_{i},\btheta)+\varepsilon_{i},
\]
donde $\varepsilon_{i} \sim N(0, \sigma^2)$ y $cov(\varepsilon_{i},\varepsilon_{j}) = 0$, para todo $i \neq j$. Particularmente, en el caso de modelos lineales, se asume que:
\[
m(x_{i},\theta)=\bx_i^{*'}\bbeta = \beta_{0}+x_{1i}^{*}\beta_{1}+x_{2i}^{*}\beta_{2}+\ldots +x_{p-1,i}^{*}\beta_{p-1},
\]
donde $x_j^{*}$ representa cualquier transformación de las covariables originales, por ejemplo, $x_j^{*}= \log x_j$ o $x_j^{*}= x_j^{2}$. Estos modelos se consideran lineales porque son combinaciones lineales de los parámetros $\bbeta$.

Modelos de la forma:
\[
y_{i}=m(x_{i},\theta)+\varepsilon_{i}=\theta_{1}+\theta_{1}[1+exp(-\theta_{3}x_{i})]+\varepsilon_{i},
\]
o
\[
y_{i}=m(x_{i},\theta)+\varepsilon_{i}=\frac{x_{i}\theta_{i}}{\theta_{2}+x_{i}}+\varepsilon_{i},
\]
son ejemplos de modelos no lineales. Es decir, no son combinación lineal de los parámetros.

### Modelos no-lineales linealizables
Dentro de los modelos no lineales se encuentran algunos que pueden ser linealizables a través de transformaciones sobre las variables. Por ejemplo, el modelo de regresión exponencial:
\[
E(y)=\theta_{0}+\theta_{1}\exp(\theta_{2}+x_{i}\theta_{3}),
\]

Si $\theta_{0}=0$, es linealizable:
\[
\log y_{i}=(\log\theta_{1}+\theta_{2})+x_{i}\theta_{3}+\varepsilon_{i}^* = \beta_0+x_{i}\beta_1+\varepsilon_{i}^*
\]

### Estimación de los parámetros
Al igual que en los modelos lineales, la estimación de $\btheta$ se hace minimizando la suma de cuadrados de los residuos:
\[
S(\btheta)=\sum_{i=1}^n[y_{i}-m(\bx_{i},\btheta)]^2.
\]
Por lo que, para encontrar el mínimo, $(1)$ calculamos la derivada de $S(\btheta)$ con respecto a $\btheta$:
\[
\frac{\partial}{\partial\btheta}S(\btheta)=-2\sum_{i=1}^n[y_{i}-m(\bx_{i},\btheta)]
\begin{bmatrix}\frac{\partial }{\partial\btheta}m(\bx_{i},\btheta)\end{bmatrix}
\]
$(2)$ igualamos a $0$, y $(3)$ resolvemos la ecuación para $\btheta$. Sin embargo, en la mayoría de los casos, $\frac{\partial}{\partial\btheta}S(\btheta)$ es una función no-lineal $\btheta$. Por lo que no es posible encontrar una solución analítica y necesitamos encontrar la solución de forma **iterativa**.

Las técnicas iterativas de estimación de los parámetros están basadas en expansiones de **series de Taylor**. Cualquier función $f(\theta)$ puede expandirse como una serie de Taylor de la forma:
$$
f(\theta)=\sum_{n=0}^\infty \frac{1}{n!}(\theta-\theta^*)^n \frac{\partial^nf(\theta^*)}{\partial\theta^n}.
$$
Una aproximación de la función $f(\theta)$ en los valores alrededor del punto $\theta^*$ se puede hacer usando series de Taylor de orden dos:
$$
f(\theta)\approx f(\theta^*)+(\theta-\theta^*) \frac{\partial f(\theta^*)}{\partial\theta}+\frac{1}{2}(\theta-\theta^*)^2\frac{\partial^2 f(\theta^*)}{\partial\theta^2}.
$$
En caso de que $\btheta$ (vector de parámetros), la aproximación por series de Taylor de orden dos es:
$$
f(\btheta)\approx f(\btheta^*)+(\btheta-\btheta^*)^{'}u(\btheta^*)+\frac{1}{2}(\btheta-\btheta^*)^{'}H(\btheta^*)(\btheta-\btheta^*),
$$
donde:
$$
u(\btheta)=\frac{\partial S(\btheta)}{\partial\btheta}=\begin{pmatrix} 
\frac{\partial S(\btheta)}{\partial\theta_1} \\ 
\frac{\partial S(\btheta)}{\partial\theta_2} \\
\vdots \\
\frac{\partial S(\btheta)}{\partial\theta_p} \\
\end{pmatrix}
\qquad
u(\hatbtheta)=u(\btheta)|_{\btheta=\hatbtheta},
$$
es el vector Score, y
$$
\bH(\btheta)=  \frac{\partial^2 S(\btheta)}{\partial\btheta^{'} \partial\btheta}=\begin{pmatrix} \frac{\partial^2 S(\btheta)}{\partial^2 \theta_{1}} & \frac{\partial^2 S(\btheta)}{\partial \theta_{1} \partial \theta_{2} } & \dots & \frac{\partial^2 S(\btheta)}{\partial \theta_{1} \partial \theta_{p}} \\
\frac{\partial^2 S(\btheta)}{\partial \theta_{2} \partial \theta_{1}} & \frac{\partial^2 S(\btheta)}{\partial^2 \theta_{2}} & \dots & \frac{\partial^2 S(\btheta)}{\partial \theta_{2} \partial \theta_{p}}\\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial^2 S(\btheta)}{\partial \theta_{p} \partial \theta_{1}} & \frac{\partial^2 S(\btheta)}{\partial \theta_{p} \partial \theta_{2}} & \dots & \frac{\partial^2 S(\btheta)}{\partial^2 \theta_{p}}
\end{pmatrix} \quad \quad \quad \bH(\hatbtheta)=\bH(\btheta)|_{\btheta=\hatbtheta},
$$
es la matriz Hessiana.

Algunos métodos iterativos de estimación son: Gauss-Newton (approx. series de Taylor a la función de la media) y Newton-Raphson (approx. series de Taylor a la función score). En este caso vamos a optar por el primero.

La idea es aproximar $m(x_{i},\btheta^*)$ usando series de Taylor de orden uno alrededor de $\btheta^*$, esto es:

\begin{equation}
m(x_{i},\btheta)\approx m(x_{i},\btheta^*)+(\btheta-\btheta^*)^{'}u_{i}(\btheta^*).
(\#eq:modeloFat)
\end{equation}

Note que \@ref(eq:modeloFat) tiene la forma de un modelo lineal, donde $u_{i}(\btheta^*)$ juega el papel de vector de covariables. La diferencia radica en que $u_{i}(\btheta^*)$ puede depender de los parámetros.

La aproximación de la suma de cuadrados de los residuos es:
\begin{equation}
\begin{split}
S(\btheta)&=\sum_{i=1}^n[y_{i}-m(x_{i},\btheta)]^2 \approx \sum_{i=1}^n[y_{i}-m(x_{i},\btheta^*)+(\btheta-\btheta^*)^{'}u_{i}(\btheta^*)]^2 \\
&= \sum_{i=1}^n[\widehat e_{i}^*+(\btheta-\btheta^*)^{'}u_{i}(\btheta^*)]^2.
\end{split}
\nonumber
\end{equation}

Esta aproximación de $S(\btheta)$ es equivalente a una suma de cuadrados de un modelo lineal con $\widehat e_{i}^*$ (llamados residuos de trabajo) como variable respuesta y $u_{i}(\btheta^*)$ como vector de covariables. Por lo tanto, la solución es:
$$
(\hatbtheta-\btheta^*)=[U(\btheta^*)^{'}U(\btheta^*)]^{-1}U(\btheta^*)^{'} \widehat e^*,
$$
\begin{equation}
\hat{\btheta}=\btheta^*+[U(\btheta^*)^{'}U(\btheta^*)]^{-1}U(\btheta^*)^{'} \widehat e^*,
(\#eq:AlgorGN)
\end{equation}

donde:$\widehat e_{i}^*=(\widehat e_{1}^*,\ldots,\widehat e_{n}^*)^{'}$, $U(\btheta^*)$ es una matriz con la fila $i$ igual a $u_{i}(\btheta^*)$.

A partir de estas ecuaciones se propone el **algoritmo de Gauss-Newton**.

1. Seleccione unos valores iniciales $\btheta_{0}$  y calcule $S(\btheta_{0})$.
2. Establezca el contador de iteraciones en $j=0$
3. Calcule $U(\btheta^{(j)})$ y $\widehat e^{(j)}$ y encuentre $\btheta^{(j+1)}$ usando \@ref(eq:AlgorGN):
\begin{equation}
\begin{split}
& \btheta^{(j+1)}=\btheta^{(j)}+[U(\btheta^{(j)})^{'}U(\btheta^{(j)})]^{-1}U(\btheta^{(j)})^{'} \widehat e^{(j)},
\end{split}
\end{equation}
y calcule $S(\btheta^{(j+1)})$.  

4. Pare si $\delta=|S(\btheta^{(j)})-S(\btheta^{(j+1)})|$ es suficientemente pequeño (convergente). De otra forma, $j=j+1$ y vaya al paso 3.

Si $j$ es muy grande (muchas iteraciones), se dice que hay divergencia.

La estimación de $\sigma^2$ es:

$$
\widehat{\sigma}^2=\frac{1}{n-p}\sum_{i=1}^n[y_{i}-m(\bx_{i},\hatbtheta)]^2,
$$

donde $p$ es la dimensión de $\btheta$.

Todos los métodos iterativos de selección requieren de la selección de valores iniciales. Para evitar problemas de divergencia, es preferible escoger valores que estén cercanos a los parámetros. Esto se puede lograr basándose en conocimiento previo del problema, significado físico de los coeficientes, evaluación gráfica o linealización de los datos. Otro aspecto que se debe tener en cuenta es que este tipo de algoritmos pueden caer en un máximo local. Por lo que es recomendable ejecutar el algoritmo para diferentes valores iniciales.

En el caso del peso de los pavos, se pueden utilizar los siguientes valores iniciales:

- $\theta_{1}^0=620$ (promedio del peso ganado sin suplemento).

- $\theta_{2}^0+\theta_{1}^0=800$ (valor cercano al máximo peso obtenido). Por lo tanto $\theta_{2}^0=180$ 

- $\theta_{3}^0$ se puede obtener resolviendo la siguiente ecuación $E(y) = \theta_1^{0}+\theta_2^{0}[1-exp(-\theta_{3} A)]$ para un posible punto. Por ejemplo, si $A=0.16$, un valor posible para $E(y)$ es 750. Por lo que:
$$
750=620+180[1-\exp(-\theta_{3}^00.16)].
$$
Resolviendo la ecuación $\theta_{3}^0\approx8$.

En R, la estimación del modelo lineal se hace usando la función ´nls()´. Para el caso de crecimiento de los pavos:

```{r modpavoscrec, echo=T,warning=FALSE,message = FALSE}

mod.turk = nls(Gain ~ th1 + th2*(1-exp(-th3*A)),data = turk0,
          start = list(th1=620,th2=180,th3=8),trace=F)
mod.turk
```
Por lo que la estimación de la media del peso ganado por corral es:
$$
E(\mbox{Gain}|A)=622.958 + 178.252 [1 - \exp(-7.122A)]    
$$
La figura \@ref(fig:plotpavoscrec) muestra el ajuste de forma gráfica. 
```{r plotpavoscrec, echo=T, include=T,fig.height = 4, fig.width = 6,fig.align = "center", fig.cap = "Datos crecimiento de pavos. Ajuste del modelo para el peso medio ganado por corral en función de la cantidad de suplemento de metionina.",warning=FALSE,message = FALSE}
plot(Gain~A,data=turk0,xlab='cantidad de metionina (% dieta)',ylab='Peso ganado (gramos)')
th.turk = coef(mod.turk)
x = seq(0,0.5,length.out=100)
lines(x, th.turk[1]+th.turk[2]*(1-exp(-th.turk[3]*x)),col=2, lwd = 2)
```

### Inferencia sobre los parámetros
Las propiedades del $\hatbtheta$ se basan en teoría asintótica, es decir que son válidas si se tiene muestras grandes. Si $\varepsilon \sim N(\bZERO,\sigma^2 \bI)$, tenemos que asintóticamente $(n \to \infty)$:

$$
\hatbtheta\sim N\left(\btheta,\sigma^2\left[U(\btheta^*)U(\btheta^*)'\right]^{-1}\right).
$$
Esto quiere decir que, $\hatbtheta$ es un estimador asintoticamente insesgado de $\btheta$ y se distribuye de forma normal. Además, se puede probar que es un estimador eficiente (mínima varianza). 

A partir de estos resultados se pueden hacer inferencias sobre los coeficientes $\btheta$. Por ejemplo, pruebas de hipótesis sobre algún coeficiente del modelo:
$$
\qquad H_{0}:\theta_{j}=\theta_{0}, \qquad H_{1}:\theta_{j}\ne\theta_{0},
$$
se puede hacer a través del siguiente estadístico de prueba:
$$
t_{0}:\frac{\widehat{\theta_{j}}-\theta_{0}}{\sqrt{V(\widehat{\theta_{j}})}}, \quad \text{donde} \quad t_{0} \sim t_{n-p}.
$$
También, pruebas de hipótesis para subconjuntos de parámetros:
$$
H_{0}:\btheta_{2}=\bZERO \qquad H_{1}:\btheta_{2}\ne\bZERO,
$$
donde $\btheta=(\btheta_{1}^{'},\btheta_{2}^{'})^{'}$. En este caso, el estadístico de prueba es:
$$
F_{0}=\frac{[SS_{res}(\btheta)-SS_{res}(\btheta_{1})]/r}{MS_{res}(\btheta)}\sim F_{r,n-p}.
$$
De igual forma, intervalos de confianza del del $(1-\alpha)$% para $\theta_{j}$:

$$
\hat{\theta_{j}}\pm t_{1-\alpha/2,n-p}\sqrt{V(\hat{\theta_{j}})} ,
$$
o intervalos de confianza del del $(1-\alpha)$% para $E(Y|x_{0})$.Con la función ``confint`` de R se pueden obtener los IC de los coeficientes a través de los perfiles de verosimilitud.

Hay que hacer énfasis que estas son propiedades para muestras grandes, para muestras pequeñas, estas propiedades pueden ser inadecuadas y se puede recurrir a otras alternativas, como el **bootstrap**.

Para el modelo de crecimiento de los pavos, tenemos que:
```{r tablapavos,include=TRUE}
summary(mod.turk)
```
A partir de este ajuste se puede concluir que el peso medio obtenido sin suplemento es de $622$. Mientras que la ganancia máxima que se obtiene con el suplemento es de $178$ (significativemente mayor de cero). Los intervalos de confianza para $\btheta$ se obtienen de la siguiente forma:
```{r Confintpavos,include=TRUE}
confint(mod.turk)
```
Aquí podemos ver que, por ejemplo, la ganancia máxima que se puede obtener con el suplemento está entre $156$ y $204$ gramos con un nivel de confianza del 95\%. 

Para calcular los intervalos de confianza para la media podemos utilizar la función ``predFit`` de la librería ``investr``. La Figura \@ref(fig:Confintpavos2) muestra el intervalo del 95\% del peso ganado medio en función del \% de metionina en la dieta.
```{r Confintpavos2,include=TRUE,fig.height = 4, fig.width = 10,fig.align = "center", fig.cap='Datos pavos. Intervalo del 95% de confianza para la media del peso ganado en función de la dieta.'}
library(investr)
predx = data.frame(A=seq(from=0,to=0.5,length.out=100))

predGain = predFit(mod.turk,predx,interval='confidence')

plot(Gain~A,data=turk0,xlab='cantidad de metionina (% dieta)',ylab='Peso ganado (gramos)')
th = coef(mod.turk)
x = seq(0,0.5,length.out=100)
lines(x, th.turk[1]+th.turk[2]*(1-exp(-th.turk[3]*x)),col=2, lwd = 2)
lines(predx$A,predGain[,2],col=2,lty=2,lwd=2)
lines(predx$A,predGain[,3],col=2,lty=2,lwd=2)
```

Es posible considerar otros modelos de crecimiento para este conjunto de datos. Algunos de estos son:

- Modelo logístico:

$$
y_{i}=\frac{\theta_{1}}{1+\theta_{2}\exp(-\theta_{3}x_{i})}+\varepsilon_{i},
$$
- Modelo Weibull:

$$
y_{i}=\theta_{1}+\theta_{2}[1-\exp(-\theta_{3}x_{i}^{\theta_{4}})]+\varepsilon_{i}.
$$
Para compararlos, podemos ajustarlos y verificar cuál de los tres proporciona mejor ajuste usando criterios de información (AIC o BIC). En la Figura \@ref{fig:tresmodelospavos}, y a través del BIC, podemos ver que los tres modelos proporcionan casi el mismo ajuste. Así que, cualquiera puede ser usado para hacer inferencias y sacar conclusiones.

```{r tresmodelospavos, include=TRUE, fig.align='center', fig.cap="Datos crecimiento de pavos. Ajuste del modelo de crecimiento propuesto (rojo), modelo logístico (verde) y Modelo Weibull (azul)."}

plot(Gain~A,data=turk0,xlab='cantidad de metionina (% dieta)',ylab='Peso ganado (gramos)')

mod2 = nls(Gain ~ th1/(1+th2*exp(-th3*A)),data = turk0,
           start = list(th1=620,th2=0.25,th3=8) )

mod3 = nls(Gain ~ th1 + th2*(1-exp(-th3*A^th4)),data = turk0,
           start = list(th1=800,th2=180,th3=8,th4=1) )
           
th2 = coef(mod2)         
th3 = coef(mod3)
lines(x, th[1]+th[2]*(1-exp(-th[3]*x)),col=2, lwd = 2)
lines(x, th2[1]/(1+th2[2]*exp(-th2[3]*x)),col=3, lwd = 2)
lines(x, th3[1]+th3[2]*(1-exp(-th3[3]*x^th3[4])),col=4, lwd = 2)

BIC(mod.turk)
BIC(mod2)
BIC(mod3)

```

#### Puromicina-Estimación
Los valores iniciales del modelo Michaelis-Menten se puede hacer por linealización. Tenemos que:
\[
m(\bx,\btheta) = \frac{\theta_1 x}{x + \theta_2},
\]
es linealizable aplicando la inversa a ambos lados de la ecuación:
\[
\frac{1}{m(\bx,\btheta)} = \frac{x + \theta_2}{\theta_1 x} = \frac{1}{\theta_1} + \frac{1}{x}\frac{\theta_2}{\theta_1}.
\]
En la Figura \@ref(fig:linealpuromicina) podemos ver que aplicando inversas a ambas variables se obtiene una relación aproximadamente lineal.

```{r linealpuromicina, echo=FALSE, include=TRUE, fig.align='center', fig.cap="Datos puromicina. Diagrama de dispersión. Datos linealizados(derecha)."} 
par(mfrow=c(1,2))
plot(Puromycin$conc,Puromycin$rate,col=Puromycin$state, xlab='concentración de sustrato (ppm)', ylab='velocidad de reacción')

plot(1/Puromycin$conc,1/Puromycin$rate,col=Puromycin$state, xlab='inversa de la concentración de sustrato (ppm)', ylab='inversa de la velocidad de reacción')
```
A través del ajuste por MCO para:

$$
1/y_{i}=\beta_{0}+1/\mbox{conc}_{i}\beta_{1}+\varepsilon_{i},
$$
se puede obtener valores iniciales. Luego de ajustar el modelo se obtiene que:

$$
\theta_{1}^{(0)}=\frac{1}{\hat{\beta}_{0}}=167.408 \qquad \theta_{2}^{(0)}=\frac{\hat{\beta}_{1}}{\hat{\beta}_{0}}=0.039
$$
Inicialmente, se podríamos asumir que $\beta_{3}^{(0)}=\beta_{4}^{(0)}=0$ (es decir, no hay diferencias entre las células tratadas y no tratadas). Usando la función ´nls()´ de R obtenemos los siguientes resultados:
```{r tablapuromicina, include=TRUE}

Puromycin$state2 = as.double(Puromycin$state == 'treated')
mod.puromicyn = nls(rate ~ (th1*conc + th3*conc*state2)/(th2+th4*state2+conc),data = Puromycin,
          start = list(th1=168,th2=0.4,th3=0,th4=0),trace=F )
summary(mod.puromicyn )

```
Con estos resultados podemos concluir que la tasa de crecimiento máxima es diferente si la enzima es tratada o no ($\theta_3$ es significativamente diferente de cero). Sin embargo, el punto en que se alcanza la mitad del máximo es el mismos ($\theta_4$ no es significativamente diferente de cero). El ajuste se puede observar de forma gráfica en la Figura \@ref(fig:puromicinaplotl). Las líneas horizontales muestran la diferencia entre las asíntotas entre las céludas tratadas y las no tratadas. Mientras que, las líneas verticales la concentración donde se obtiene la mitad de la velocidad de reacción máxima.

```{r puromicinaplotl, echo=FALSE, fig.align='center', fig.cap="Datos puromicina. Enzimas tratadas(negro), enzimas no tratadas(rojo). "}
x = seq(0,1.5,length.out=200)
thP= coef(mod.puromicyn)
plot(Puromycin$conc,Puromycin$rate,col=Puromycin$state,ylim=c(0,215),
     xlab='concentración de sustrato (ppm)',
     ylab='velocidad de reacción')

lines(x, thP[1]*x/(thP[2]+x),col=2)
lines(x, (thP[1]+thP[3])*x/(thP[2]+thP[4]+x))
abline(h=thP[1],lty=2,col=2)
abline(h=thP[1]+thP[3],lty=2)

lines(c(thP[2],thP[2]), c(0,thP[1]/2),lty=2,col=2)
lines(c(thP[2]+thP[4],thP[2]+thP[4]), c(0,(thP[1]+thP[3])/2),lty=2)

```

## Método de Bootstrap
Los métodos de inferencia que se muestran anteriormente se basan en la distribución asintótica de los estimadores. Por lo que pueden ser inexactas y/o engañosas si tenemos muestras pequeñas. En esos casos, una alternativa preferible es usar ténicas de remuestreo (**bootstrap**).

El bootstrap es una técnica que se puede usar para calcular intervalos de confianza and pruebas de hipótesis cuando el cumplimiento de los supuestos asumidos en el modelo están en duda. Por ejemplo, si se quiere calcular un intervalo de confianza para la mediana (o cualquier otro parámetro) de $Y$. Para esto tomamos una muestra
independiente $\by=(y_{1},...,y_{n})$.

Pasos del boostrap:

1. Obtener una muestra aleatoria con remuestreo de $\by=(y_{1}^{*},...,y_{n}^{*})$.
2. Calcular la mediana usando la muestra el paso 1 $(Me_{1})$.
3. Repita los pasos 1 y 2 un número grande de veces $(B)$.
4. un intervalo de confianza del 95% basado en percentiles muestrales 2.5% y 97.5 %.

### Bootstrap en regresión
Para un modelo de regresión, el remuestreo se hace sobre los observaciones, considerando la respuesta y las covariables, $(y_i,\bx_i)$, o sobre los residuos del ajuste por MCO. El segundo método es llamado residual resampling y se realiza de las siguiente forma:

1. Con la muestra dada: $(x_{i},y_{i}),i=1,...,n$ ajustar el modelo y obtener los residuos: $e_{i}=y_{i}-x_{i}^{'}\hat{\beta}.$

2. Obtener una muestra aleatoria con reemplazo de los residuos $e^*=(e_{1}^*,...,e_{n}^*)$.

3.Crear una variable respuesta bootstrap con $y_{i}^*=x_{i}^{'}\hat{\beta}+e_{1}^*$ y estimar $\hat{\beta}^*$. 

4. Repetir los pasos 1-3 un número grande de veces $(B)$ y obtener
el intervalo de confianza para $\beta_{j}$ usando los percentiles*.

$*$Hay muchas modificaciones y extensiones para calcular los intervalos de confianza.


Para los datos de la Puromicina, el bootstrap en R se puede implementar utilizando la función `Boot` de la librería `car`:

```{r bootpuro}
set.seed(310)
mod.boot = Boot(mod.puromicyn,method='residual',R=1000)
mod.boot
```
En el objeto `mod.boot` se pueden observar todas las estimaciones calculadas en los $1000$ remuestreos. Por ejemplo, la relaciones entre las estimaciones se pueden observar a través de un diagrama de dispersión (Figura \@ref(fig:bootgraf)). Aquí vemos una correlaciones altas en algunas de las estimaciones.

```{r bootgraf, include=TRUE, fig.align='center', fig.cap="Datos puromicina. Diagrama de dispersión para las estimaciones de los coeficientes del modelo por bootstrap."}
pairs(mod.boot$t,labels=c(expression(hat(theta)[1]),expression(hat(theta)[2]),expression(hat(theta)[3]),
                          expression(hat(theta)[4])))
```
Igualmente, la distribución muestral de los estimadores de los coeficientes se pueden obtener a partir de histogramas (ver Figura \@ref(fig:bootgrafconf)). Estas parecen aproximarse a distribuciones normales, sin embargo, hay leves asimetrías en $\hattheta_1$ y $\hattheta_2$.
 

```{r bootgrafconf, include=TRUE, fig.align='center', fig.cap="Datos puromicina. Histograma de las estimaciones de los coeficientes del modelo por bootstrap. Linea negra: estimación por mínimos cuadrados.Lineas rojas: percentil 2.5, media y percentil 97.5."}
par(mfrow=c(1,4))
hist(mod.boot$t[,1],breaks = 20,xlab=expression(hat(theta)[1]),main = '')
abline(v=coef(mod.puromicyn)[1],lty=2,lwd=2)
abline(v=mean(mod.boot$t[,1]),lty=2,lwd=2,col=2)
abline(v=quantile(mod.boot$t[,1],c(0.025,0.975),na.rm = T),lty=2,lwd=2,col=2)

hist(mod.boot$t[,2],breaks = 20,xlab=expression(hat(theta)[2]),main = '')
abline(v=coef(mod.puromicyn)[2],lty=2,lwd=2)
abline(v=mean(mod.boot$t[,2]),lty=2,lwd=2,col=2)
abline(v=quantile(mod.boot$t[,2],c(0.025,0.975),na.rm = T),lty=2,lwd=2,col=2)

hist(mod.boot$t[,3],breaks = 20,xlab=expression(theta[3]),main = '')
abline(v=coef(mod.puromicyn)[3],lty=2,lwd=2)
abline(v=mean(mod.boot$t[,3]),lty=2,lwd=2,col=2)
abline(v=quantile(mod.boot$t[,3],c(0.025,0.975),na.rm = T),lty=2,lwd=2,col=2)

hist(mod.boot$t[,4],breaks = 20,xlab=expression(theta[4]),main = '')
abline(v=coef(mod.puromicyn)[4],lty=2,lwd=2)
abline(v=mean(mod.boot$t[,4]),lty=2,lwd=2,col=2)
abline(v=quantile(mod.boot$t[,4],c(0.025,0.975),na.rm = T),lty=2,lwd=2,col=2)

```
Finalmente, los intervalos del 95% de confianza usando bootstrap se pueden obtener a partir de los percentiles 2.5\% y 97.5\% de las distribuciones remuestreadas:
```{r bootgrafintC, include=TRUE}
quantile(mod.boot$t[,1],c(0.025,0.975),na.rm = T)
quantile(mod.boot$t[,2],c(0.025,0.975),na.rm = T)
quantile(mod.boot$t[,3],c(0.025,0.975),na.rm = T)
quantile(mod.boot$t[,4],c(0.025,0.975),na.rm = T)
```

En la Figura \@ref(fig:bootgrafpred) se pueden observar todas las estimaciones de la media obtenidas a partir de los 1000 remuestreos. Se puede observar que en todos los casos, la máxima velocidad de obtuvo para las células tratadas.

```{r bootgrafpred, include=TRUE, fig.align='center', fig.cap="Datos puromicina. Curvas medias estimadas por bootstrap. La estimación puntual de la media para las enzimas tratadas es la línea negro y para las enzimas no tratadas es la línea roja."}
fit.rate= function(theta,x){
  cbind(theta[1]*x/(theta[2]+x),
        (theta[1]+theta[3])*x/(theta[2]+theta[4]+x))
}
x= seq(from=0,to=1.1,length.out = 100)

plot(NULL,NULL,xlim=c(0,1.1),ylim=c(0,210),xlab='concentración de sustrato (ppm)',
     ylab='velocidad de reacción')
Fit = mapply(function(i){
  pred = fit.rate(mod.boot$t[i,],x)
  lines(x,pred[,1],col='lightgray')
  lines(x,pred[,2],col='gray')
},i=1:999)
lines(x, thP[1]*x/(thP[2]+x),col=2)
lines(x, (thP[1]+thP[3])*x/(thP[2]+thP[4]+x))
points(Puromycin$conc,Puromycin$rate,col=Puromycin$state)

```

### Algunas consideraciones
Finalmente, algunas consideraciones que se debe de tener a la hora de estimar un modelo no lineal:

* Lo ideal es que el algoritmo llegue a la solución en pocas iteraciones. Esto pasa si la aproximación lineal es adecuada.

* Siempre es bueno evaluar la solución con diferentes puntos iniciales. Es posible que caigamos en un máximo local.

* Si el tamaño de muestra no es grande, las propiedades asintóticas pueden no ser adecuadas. Por lo tanto, es mas conveniente usar bootstrap para hacer inferencias.








